{
  "hash": "7ee0b4507677774d5289fd562c917944",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Appendix B: SAS Code Examples for Statistical Foundations\"\nappendix: true\nformat: html\nexecute:\n  engine: knitr  # avoid jupyter\n  eval: false    # reinforce global no-eval behavior\n---\n\n\n\n\n\nQuick Navigation:\n\n- [1. Data Import & Summary Statistics](#data-import-summary)\n- [2. Visualization & Assumption Checks](#viz-assumption-checks)\n- [3. Permutation Test](#permutation-test)\n- [4. *t*-Tests and Power Analysis](#t-tests-power)\n- [5. ANOVA and Extra Sum of Squares](#anova-extra-ss)\n- [6. Non-Parametric Tests](#nonparam-tests)\n- [7. Correlation & Simple Regression](#correlation-simple-regression)\n- [8. Residual Analysis](#residual-analysis)\n\n\n::: {.appendix}\n\n## 1. Data Import & Summary Statistics {#data-import-summary}\n\n> Most SAS procedures require your dataset to be sorted by group for grouped analysis or plotting.\n> You can either import data from a file or create a dataset manually for small examples.\n\n### 1A. Import or Create a Dataset\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* OPTION 1: Import a CSV from your SAS Studio home directory */\n\n%web_drop_table(WORK.mydata);\n\nfilename reffile '/home/your-username/path-to-your-data.csv';\n\nproc import datafile=reffile\n    dbms=csv\n    out=WORK.mydata\n    replace;\n    getnames=yes;\nrun;\n\n/* View structure and preview the dataset */\nproc contents data=WORK.mydata;\nrun;\n\n%web_open_table(WORK.mydata);\n    \n    \n/* OPTION 2: Manually create a small dataset column-wise (each row = one observation) */\n\ndata mydata;\n    input variable1 variable2;\n    datalines;\n    1 A\n    2 B\n    3 C\n    4 D\n    5 E\n    ;\nrun;\n\nproc print data = mydata;\nrun;\n\n\n/* OPTION 3: Create a row-wise dataset (data entered horizontally using @@) */\ndata mydata;\n    input variable @@;\n    datalines;\n    1 2 3 4 5 6\n    ;\nrun;\n    \nproc print data = mydata;\nrun;\n    \n```\n:::\n\n\n\n\n\n### 1B. Summary View & Sorting\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Preview the data */\nproc print data = dataset;\nrun;\n\n/* Sort data by explanatory variable (required for some procedures) */\nproc sort data = dataset;\n    by explanatory;\nrun;\n\n```\n:::\n\n\n\n\n\n### 1C. Summary Statistics\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Summary stats: n, mean, sd, min, max */\nproc means data = dataset;\n    var response;\nrun;\n\n/* Medians by group */\nproc means data = dataset median;\n    class explanatory;\n    var response;\nrun;\n\n/* Manual p-value from t-statistic (two-sided) */\ndata mypval;\n    pv = 2 * (1 - cdf(\"t\", tstat, df));\nrun;\nproc print data = mypval;\nrun;\n\n```\n:::\n\n\n\n\n\n### 1D. Log Transformation & Filtering\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Create a log-transformed version of response */\ndata ldataset;\n    set dataset;\n    logResponse = log(response);\nrun;\n\n/* Remove outlier (e.g., filter response < 1200) */\ndata datasetNoOutlier;\n    set dataset;\n    where response < 1200;\nrun;\n\n/* Scatter plot without outlier */\nproc sgplot data = datasetNoOutlier;\n    scatter x = explanatory y = response;\nrun;\n\n```\n:::\n\n\n\n\n\n### 1E. Categorical Recoding & Viewing Subsets\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Create ordinal version of categorical variable */\n\ndata educMultiGrp;\n    set educMultiGrp;\n    if Educ = '<12' then EO = 1;\n    else if Educ = '12' then EO = 2;\n    else if Educ = '13-15' then EO = 3;\n    else if Educ = '16' then EO = 4;\n    else if Educ = '>16' then EO = 5;\nrun;\n\n/* Create a column to collapse levels */\ndata educMultiGrp;\n    set educMultiGrp;\n    if Educ = \"<12\" then Combine = \"<12\";\n    else if Educ = \"12\" then Combine = \"12\";\n    else if Educ = \"13-15\" then Combine = \"13-15\";\n    else if Educ in (\"16\", \">16\") then Combine = \"16+\";\nrun;\n\n/* View first 50 rows of a dataset */\nproc print data = lIncome5Grps(obs=50);\nrun;\n\n```\n:::\n\n\n\n\n\n\n## 2. Visualization & Assumption Checks {#viz-assumption-checks}\n\n> Use `proc univariate`, `proc sgplot`, and `proc ttest` to visualize distributions and assess assumptions of normality and variance.  \n> Many visualizations require sorting your dataset by the grouping variable.\n\n### 2A. Univariate Plots (No Grouping)\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Histogram and QQ plot (ungrouped) */\nproc univariate data = dataset;\n    var response;\n    histogram response;\n    qqplot response;\nrun;\n\n/* Boxplot (ungrouped) */\nproc sgplot data = dataset;\n    vbox response;\nrun;\n\n/* Scatterplot of response vs explanatory */\nproc sgplot data = dataset;\n    scatter x = explanatory y = response;\n    * title \"Scatterplot of \";\nrun;\n\n/* Turn off the title */\ntitle;\nrun;\n\n```\n:::\n\n\n\n\n\n### 2B. Histograms and QQ Plots by Group\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Sort by grouping variable (required for BY statement) */\nproc sort data = dataset;\n    by explanatory;\nrun;\nproc print data = dataset;\nrun;\n\n/* Histograms grouped by explanatory */\nproc univariate data = dataset;\n    by explanatory;\n    histogram response;\nrun;\n\n/* QQ plots grouped by explanatory */\nproc univariate data = dataset;\n    * title \"QQ Plot by \";\n    by explanatory;\n    qqplot response / normal(mu=est sigma=est);\nrun;\n\n\nproc sgplot data = dataset;\n\t* title \"Histogram by \";\n    by explanatory;\n    histogram response / transparency=0.5;\n    density response; * with a normal distribution curve;\nrun;\n\n```\n:::\n\n\n\n\n\n### 2C. Boxplots and Density Plots by Group\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Boxplot by group */\nproc sgplot data=dataset;\n    * title \"Boxplot of\";\n    vbox response / category=explanatory;\nrun;\n\n/* Histogram with overlaid normal curve by group */\nproc sgplot data = dataset;\n    by explanatory;\n    histogram response / transparency = 0.5;\n    density response;  /* Normal curve */\nrun;\n\n```\n:::\n\n\n\n\n\n### 2D. Visualizations from proc ttest\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* `proc ttest` also generates histogram, QQ plot, and boxplot (grouped) */\nproc ttest data = dataset;\n    class explanatory;\n    var response;\nrun;\n\n```\n:::\n\n\n\n\n\n### 2E. Custom Histogram with Set Bin Width\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Adjust histogram range and bin width */\nproc univariate data = dataset noprint;\n    by explanatory;\n    histogram response / endpoints = 0 to 1000 by 50 normal; /* Adjust as needed */\n    inset n mean std / pos = ne;\nrun;\n\n```\n:::\n\n\n\n\n\n\n## 3. Permutation Test {#permutation-test}\n\n### 3A. Observed Difference in Means\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Use proc ttest to compute observed difference between groups */\nproc ttest data = dataset;\n    class group;\n    var response;\nrun;\n\n```\n:::\n\n\n\n\n\n### 3B. Generate Permutations with proc iml\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Shuffle response values across group labels using IML */\n\n/* Borrowed code from internet: randomizes observations and creates a matrix with one row per permutation */\n\n/* NOTE: Replace `dataset`, `group` and `response` with your actual variable names */\n\nproc iml;\n    use dataset;\n    read all var {group response} into x;  /* Make sure to specify class variable first */\n    \n      nPerms = 10000;                 /* Number of permutations */\n    permuted = t(ranperm(x[,2], nPerms));  /* Create permuted response matrix */\n    combined = x[,1] || permuted;   /* Combine original group column with each permuted column */\n\n    create newds from combined;\n    append from combined;\nquit;\n\n```\n:::\n\n\n\n\n\n### 3C. Build Permutation Distribution\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Use proc ttest to calculate mean differences for each permutation */\n\nods output off;\nods exclude all;   /* Suppress output */\n  \n/* The ods output line below is optional if you want to capture confidence intervals */\n/* ods output conflimits=diff; */\n\nproc ttest data = newds plots = none;\n    class col1;\n    var col2 - col10001;\nrun;\n\nods output on;\nods exclude none;\n\n```\n:::\n\n\n\n\n\n### 3D. Plot Permutation Histogram & Calculate *p*-value\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n                                                                    \n/* Plot the distribution of permuted mean differences (Pooled method only) */\nproc univariate data = diff;\n    where method = \"Pooled\";\n    var mean;\n    histogram mean;\nrun;\n\n/* Count number of permuted differences as or more extreme than observed */\n/* Replace `obsDiff` with your observed test statistic from 3A */\n/* Adjust for one-tailed or two-tailed test accordingly */\ndata numdiffs;\n    set diff;\n    where method = \"Pooled\";\n    if abs(mean) >= abs(obsDiff);\nrun;\n\n/* Print matching rows (just for visual check) */\nproc print data = numdiffs;\n    where method = \"Pooled\";\nrun;    \n\n/* Manual Step:\n   - Check the number of rows in `numdiffs` (from the log or output)\n   - Divide that by the total number of permutations (e.g., 10000)\n   - This gives your p-value */\n\n```\n:::\n\n\n\n\n\n\n## 4. *t*-Tests and Power Analysis {#t-tests-power}\n\n> This section includes basic *t*-test syntax, F-tests for equal variances, and power analysis using `proc power`.\n\n### 4A. Basic *t*-Tests and Critical Values\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Compute critical t-value for two-sided test at α = 0.05 */\ndata criticalvalue;\n    critval = quantile(\"T\", 0.975, df);\nrun;\nproc print data = criticalvalue;\nrun;\n\n/* One-sample t-test (H0: mean = muUnderNull) */\n/* * proc ttest outputs histogram, boxplot and qqplot */\nproc ttest data = dataset h0 = muUnderNull sides = 2 alpha = 0.05;\n    var response;\nrun;\n\n/* Paired t-test (H0: mean difference = 0, computed as Group2 - Group1) */\nproc ttest data = dataset;\n    paired explanatory2*explanatory1;\nrun;\n\n/* Two-sample t-test (equal variance and Welch's handled together) */\n/* Pooled uses pooled st.dev. and Satterthwaite uses Welch's */\nproc ttest data = dataset h0 = 0 sides = 2 alpha = 0.05;\n    class explanatory;\n    var response;\nrun;\n\n```\n:::\n\n\n\n\n\n### 4B. Equality of Variances Tests\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* F-test for equality of variances is run automatically as part of proc ttest */\n/* The F-test (default in proc ttest) assumes normal distributions. It's useful as secondary evidence for variance equality if visuals are inconclusive. Null: population variances are equal. */\n\n/* Brown-Forsythe test does not require normality assumptions */\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / hovtest = bf;  /* Brown-Forsythe test */\nrun;  \n\n```\n:::\n\n\n\n\n\n### 4C. Power Analysis (One- and Two-Sample)\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Power for one-sample t-test */\nproc power;\n    onesamplemeans\n        sides = 1\n        alpha = 0.05\n        nullmean = 0\n        mean = xbar\n        stddev = s\n        ntotal = n\n        power = .;\nrun;\n\n/* Power for two-sample t-test */\nproc power;\n    twosamplemeans\n        sides = 1\n        alpha = 0.05\n        meandiff = effectSize\n        stddev = s\n        npergroup = n1\n        power = .; /* specify a dot or omit this line to solve for the unknown parameter */\n\nrun;\n\n/* Example: specify total sample size and mean for each using `nullmean and meandiff` */\nproc power;\n    twosamplemeans\n        sides = 1\n        alpha = 0.05\n        nulldiff = 0\n        meandiff = 3\n        stddev = 4.5\n        ntotal = 47;  /* e.g. 24 in group 1, 23 in group 2 */\nrun;\n\n```\n:::\n\n\n\n\n\n### 4D. Power Curve Plots\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Power vs. sample size (one-sample) */\nods graphics on;\n\nproc power;\n    onesamplemeans\n        sides = 1\n        alpha = 0.05\n        nullmean = 0\n        ntotal = 60 80\n        mean = 0.07\n        stddev = 0.2\n        power = .;\n    plot x = n min = 60 max = 80;\nrun;\n\nods graphics off;\n\n/* Power vs. effect size (two-sample) */\nods graphics on;\n\nproc power;\n    twosamplemeans\n        sides = 1\n        alpha = 0.05\n        nulldiff = 0\n        meandiff = 3 to 5 by 0.1\n        ntotal = 47\n        stddev = 4.5\n        power = .;\n    plot x = effect min = 3 max = 5;\nrun;\n\nods graphics off;\n\t\t\n```\n:::\n\n\n\n\n\n\n## 5. ANOVA and Extra Sum of Squares {#anova-extra-ss}\n\n> This section includes one-way ANOVA, multiple comparisons, linear contrasts, and extra sum of squares tests for nested or grouped comparisons.\n\n### 5A. One-Way ANOVA with Variance Checks\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* One-way ANOVA: for EMM and SMM (full), tests if any group means differ (i.e. any pair has difference of means) */\n/* Brown-Forsythe test is included to check equal variance assumption (does not require normality) */\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / hovtest = bf;  /* Brown-Forsythe test (homogeneity of variance) */\nrun;\n\n/* Manually compute F critical value */\ndata critical_value;\n    set calculations;\n    critical_value = finv(1 - alpha, dfn, dfd);  /* right-tailed (1-alpha) */\nrun;\n\n```\n:::\n\n\n\n\n\n### 5B. Multiple Comparisons (Tukey + Pairwise Tests)\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Example: pairwise t-tests with Tukey adjustment and confidence intervals */\nproc glm data = playersHeight;\n    class Sport;\n    model Height = Sport;\n    means Sport / hovtest = bf;\n    lsmeans Sport / pdiff adjust = tukey cl;\nrun;\n\n/* Optionally show differences both directions (A–B and B–A) */\nproc glm data = playersHeight;\n    class Sport;\n    model Height = Sport;\n    means Sport / hovtest = bf tukey cldiff;\nrun;\n\n/* The cl option provides CIs for the means, \n while cldiff provides CIs for the differences between means. */\n\n```\n:::\n\n\n\n\n\n### 5C. Linear Contrasts\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Test linear contrasts using CONTRAST and ESTIMATE */\n/* CONTRAST is used to test hypotheses (gives SS, F-statistic), while ESTIMATE provides point estimate and SE (used to construct confidence intervals). */\n/* These compare one group mean to a linear combination of others */\n\n/* didn't state order = data so groups are in alphabetical order;\norder = data; keeps the data in the order it came in: proc glm data = Handicap order = data;\ncontrast gives you the sum of squares\nestimate gives you the estimate of the gamma */  \n  \nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory;\n\n    /* Grp1 vs sum or average of others (assuming 5 groups) */\n    contrast 'Grp1 vs Sum of Other 4 Groups' explanatory 4 -1 -1 -1 -1;\n    estimate 'Grp1 vs Sum of Other 4 Groups' explanatory 4 -1 -1 -1 -1;\n    estimate 'Grp1 vs Avg of Other 4 Groups' explanatory 4 -1 -1 -1 -1 / divisor = 4;\n\n    /* Grp1 vs Grp2 */\n    contrast 'Grp1 vs Grp2' explanatory 1 -1 0 0 0;\n    estimate 'Estimate Grp1 vs Grp2' explanatory 1 -1 0 0 0;\nrun;  \n  \n\n/* To compute a 95% CI manually for the difference in averages of above (point estimate +- multiplier * standard error): critical t-value (multiplier for 95% CI) */\ndata quantile;\n    quant = quantile(\"t\", 0.975, df); * where df=n-groups;\nrun;\nproc print data = quantile;\nrun;\n\n```\n:::\n\n\n\n\n\n### 5D. Bonferroni Adjustment for Selected Comparisons\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Simultaneous CIs for selected differences (e.g. μ2–μ3, μ2–μ5, μ3–μ5) */\n/* k=3 (comparing 3 pairs) */\n\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory;\n    lsmeans explanatory / pdiff cl;\n\n    /* ESTIMATE used to extract estimate and SEs for CI construction */\n    estimate 'mu2 - mu3' explanatory 0 1 -1 0 0;\n    estimate 'mu2 - mu5' explanatory 0 1 0 0 -1;\n    estimate 'mu3 - mu5' explanatory 0 0 1 0 -1;\nrun;\n\n\n/* to get 95% CI for the difference in averages of above\npoint estimate +- multiplier * standard error */\n/* Bonferroni multiplier: 1 - α/(2k) for two-tailed test with k comparisons; df=n-totalgrps */\ndata quantile;\n    quant = quantile(\"t\", 1 - 0.05/6, df);  /* adjust denominator for # comparisons and tails */\nrun;\nproc print data = quantile;\nrun;\n\n```\n:::\n\n\n\n\n\n### 5E. Summary: Choosing a Multiple Comparison Adjustment\n\n- When deciding multiple comparison correction:\n  - Were the comparisons planned before looking at the data or unplanned? If planned, no need to make multiple comparison correction. Can use LSD.\n  - Are the groups being compared to a single control or reference group? If so, use Dunnett’s.\n  - Are the groups normally distributed with equal standard deviation? If so, use Tukey-Kramer.\n  - If we are doing some or all unplanned pairwise comparisons, without a reference/control group and without the assumption of normality or equal variance, use Bonferroni.\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Commands for various multiple comparison methods */\n\n* LSD (Least Significant Difference, use when comparisons are planned) with CI half-width;\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / lsd;  * means returns the half-width;\n    lsmeans explanatory / pdiff cl;\nrun;\n\n* Dunnett (compare each group to a control/reference group);\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / dunnett('Control');\n    lsmeans explanatory / pdiff = control('Control') adjust = dunnett cl;\nrun;  \n/* Calculate the half-widths: HalfWidth = (UpperCL - LowerCL) / 2 */\n\n* Tukey-Kramer (assumes normality + equal variance; unplanned all-pairwise) with CI half-width;\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / tukey;\n    lsmeans explanatory / pdiff adjust = tukey cl;\nrun;\n\n* Bonferroni (safest if assumptions are not met or comparisons are partially unplanned) with CI half-width;\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / bon;\n    lsmeans explanatory / pdiff adjust = bon cl;\nrun;\n\n* View all options together (Jaren’s code);\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / lsd tukey dunnett bon scheffe;\nrun;\n\n```\n:::\n\n\n\n\n\n### 5F. Extra Sum of Squares F-Test\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Conduct an anova (explanatory=group) */\nproc glm data = data;\nclass explanatory;\nmodel response = explanatory;\nrun;\n\n/* Extra-sum-of-squares */\n/* Compare full and reduced models using BYOA-style calculations */\ndata calculations;\n    alpha = 0.05;  \n    dftotal = 2580;\n    dfd = 2579;\n    dfn = dftotal - dfd;\n    ssred = 2234.10;\n    ssfull = 2232.12;\n    ssmodel = ssred - ssfull;\n    mse = ssfull / dfd;\n    msmodel = ssmodel / dfn;\n    fstat = msmodel / mse;\nrun;\n\n/* Compute critical F and p-value for the above hypothesis test. */\ndata critical_value;\n    set calculations;\n    critical_value = finv(1 - alpha, dfn, dfd); *1-alpha for right-tail;\nrun;\n\ndata f_test;\n    set critical_value;\n    p_value = 1 - probf(fstat, dfn, dfd); *1-probf for right-tail;\nrun;\nproc print data = f_test;\nrun;\n\n/* another way to get p-value */\ndata quantile;\n    myquant = 1-CDF('F', fstat, dfn, dfd)\nrun;\nproc print data = quantile;\nrun;\n\n/* You can check against a contrast if relevant */\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory;\n    contrast 'Contrast Grp1 vs. Grp2' explanatory 0 0 0 1 -1 0;\n    estimate 'Estimate Grp1 vs. Grp2' explanatory 0 0 0 1 -1 0;\nrun;\n\n```\n:::\n\n\n\n\n\n### 5G. Welch’s ANOVA (Unequal Variances)\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Appropriate for normal distributions with unequal variance */\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / welch;\nrun;\n\n/* Critical F-value calculation */\ndata critical_value;\n    critical_value = finv(1-0.05, 4, 706.2); /* 1-alpha for right-tail */\nrun;\nproc print data = critical_value;\nrun;\n\n```\n:::\n\n\n\n\n\n\n## 6. Non-Parametric Tests {#nonparam-tests}\n\n> Note: The permutation test (Section 3) is also a non-parametric method.\n\n### 6A. Wilcoxon Rank-Sum Test (Mann–Whitney U Test)\n\n> Used for inference on the median of two independent samples. \n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Exact Wilcoxon Rank-Sum Test (with Hodges-Lehmann CI) */\n/* Best for small samples. Computationally intensive for large samples. */\nproc npar1way data = dataset wilcoxon;\n    class explanatory;\n    var response;\n    exact HL wilcoxon;\nrun;\n\n/* For one-sided alpha = 0.05, specify alpha = 0.10 to match CI to one-sided test */\n/* HL = Hodges-Lehmann estimator of the median difference for confidence intervals. */\nproc npar1way data = dataset wilcoxon alpha = 0.10;\n    class explanatory;\n    var response;\n    exact HL wilcoxon;\nrun;\n\n\n/* Rank-Sum Test: NORMAL Approximation\nthe larger the sample size, you can use the z approximation\nthe smaller, the more conservative, choose the t approximation */\n/* Normal approximation for large samples */\n/* z-approximation used when sample size is large. Choose t-approximation for smaller samples or to be more conservative. */\nproc npar1way data = dataset wilcoxon;\n    class explanatory;\n    var response;\nrun;\n\n/* CI using normal approximation with HL estimator (asymptotic CI version) */\n/* To get the CI to match a one-sided alpha = 0.5, set alpha = 0.1 */\nproc npar1way data = dataset wilcoxon HL alpha = 0.10;\n    class explanatory;\n    var response;\nrun;\n\n/* One-sided critical value from normal (Z) distribution */\ndata critval;\n    cv = quantile(\"normal\", 0.95); alpha for left, 1-alpha for right;\nrun;\nproc print data = critval;\nrun;\n\n```\n:::\n\n\n\n\n\n### 6B. Wilcoxon Signed-Rank Test (Paired Samples)\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Create difference column for paired data */\ndata dataset;\n    set dataset;\n    diff = before - after;\nrun;\n\nproc print data = dataset;\nrun;\n\n/* Run Wilcoxon Signed-Rank test using diff */\n/* This seems to give an incorrect output for S, but close for 2-sided p-value */\nproc univariate data = dataset;\n    var diff;\nrun;\n\n/* Critical value for normal approximation (one-sided z-distribution) */\ndata critval;\n    cv = quantile(\"normal\", 0.95);  /* alpha for left, 1-alpha for right */\nrun;\nproc print data = critval;\nrun;\n\n* This is extra code for the by hand calculations;\n* Calculate the absolute differences and rank them;\ndata ranked;\n    set dataset;\n    abs_diff = abs(diff);\nrun;\n\n```\n:::\n\n\n\n\n\n### 6C. Manual Z-Approximation for Signed-Rank\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Step 1: Calculate absolute differences */\ndata ranked;\n    set dataset;\n    abs_diff = abs(diff);\nrun;\n\n/* Step 2: Rank the absolute differences */\nproc rank data=ranked out=ranked ties=mean;\n    var abs_diff;\n    ranks rank_abs_diff;\nrun;\n\n/* Step 3: Identify and sum ranks for positive differences */\ndata stats;\n    set ranked;\n    if diff > 0 then S = rank_abs_diff;\n    else S = 0;\nrun;\n\nproc means data = stats sum noprint;\n    var S;\n    output out=sums sum(S)=sum_S n=n_obs;\nrun;\n\n/* Step 4: Calculate expected mean, standard deviation, and Z-statistic */\ndata final;\n    set sums;\n    mean_S = n_obs * (n_obs + 1) / 4;\n    sd_S = sqrt(n_obs * (n_obs + 1) * (2 * n_obs + 1) / 24);\n    Z_statistic = (sum_S - 0.5 - mean_S) / sd_S;\nrun;\n\nproc print data = final;\n    var sum_S mean_S sd_S Z_statistic;\nrun;\n\n/* Step 5: Compute p-value for one-sided test */\ndata pvalue;\n    set final; /* not sure if this line is needed */\n    pv = 1 - probnorm(Z_statistic);\nrun;\n\nproc print data = pvalue;\nrun;\n\n```\n:::\n\n\n\n\n\n### 6D. Kruskal–Wallis Test (For Inference on the Median of 3+ Groups)\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Appropriate when normality or equal variance assumptions are violated,\n   or when sample sizes are small (CLT not reliable). \n   Works by ranking all data and running ANOVA on the ranks.\n   If following up with group comparisons, use rank-sum tests. */\n/* Test statistic: χ² (chi-square). For very small n, request exact p-values with the EXACT option \n   (avoids large-sample χ² approximation).*/\nproc npar1way data = dataset wilcoxon;\n    class explanatory;\n    var response;\nrun;\n\n```\n:::\n\n\n\n\n\n\n## 7. Correlation & Simple Regression {#correlation-simple-regression}\n\n> This section includes Pearson correlation, simple linear regression, and options for confidence and prediction intervals.\n\n### 7A. Pearson Correlation\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Pearson's R Correlation Coefficient */\n\n/* Scatterplot of response vs. explanatory */\nproc sgscatter data = dataset;\n    plot response * explanatory / markerattrs = (symbol = circlefilled);\n    title \"Scatterplot: Response vs. Explanatory\";\nrun;\n\n/* T-Critical value (two-sided t-test) */\ndata criticalvalue;\n    critval = quantile(\"T\", 0.975, df = n - 2);\nrun;\nproc print data = criticalvalue;\nrun;\n\n/* Correlation coefficient and p-value */\nproc corr data = dataset;\n    var response explanatory; /* not sure if this line is needed */\nrun;\n\n```\n:::\n\n\n\n\n\n### 7B. Simple Linear Regression: Coefficients and Fit\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Linear regression: parameter estimates and summary stats */\nproc reg data = dataset;\n    model response = explanatory;\nrun;\n\n/* Optional: set alpha to change significance level and CI width (e.g., 99%) */\nproc reg data = dataset alpha = 0.01;\n    model response = explanatory / clb;  /* clb = confidence limits for betas */\nrun;\n\n/* Alternate method to get the parameter estimate table using proc glm */\nproc glm data = dataset;\n    model response = explanatory / solution;  /* shows estimate table */\nrun;\n\n/* Add confidence intervals for coefficients (alternative way) */\nproc glm data = dataset alpha = 0.01;\n    model response = explanatory / solution clparm;\nrun;\n\n```\n:::\n\n\n\n\n\n### 7C. Confidence & Prediction Intervals for New Observations\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Example dataset with missing response values for prediction */\n/* Add new data */\ndata dataset;\n    input explanatory response;\n    datalines;\n    62 65\n    90 64\n    50 48\n    35 57\n    200 601\n    100 146\n    90 47\n    95 .\n    200 .\n    ;\nrun;\n\n/* CI for mean response (CLM = confidence limits for mean) */\nproc reg data = dataset;\n    model response = explanatory / clm;\nrun;\n\n/* PI for individual response (CLI = confidence limits for individual) */\nproc reg data = dataset;\n    model response = explanatory / cli;\nrun;    \n\n/* Optionally using proc glm */\nproc glm data = dataset;\n    model response = explanatory / solution clm;  /* confidence interval for mean */\nrun;\n\nproc glm data = dataset;\n    model response = explanatory / solution cli;  /* prediction interval for individual */\nrun;\n\n```\n:::\n\n\n\n\n\n\n## 8. Residual Analysis {#residual-analysis}\n\n> This section focuses on residual diagnostics to evaluate model assumptions such as linearity, homoscedasticity, and outliers.\n\n### 8A. Residual Plots & Diagnostics\n\n> SAS automatically produces residual plots (and other diagnostics) with `proc reg` if ODS graphics are enabled.\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\nods graphics on;\n\nproc reg data = dataset;\n    model response = explanatory;\nrun;\n\nods graphics off;\n\n/* If you need customized residual plots (e.g. residuals vs. predicted), use proc sgplot after outputting residuals: */\n\n/* Save residuals and predicted values */\nproc reg data = dataset;\n    model response = explanatory;\n    output out = diagnostics r = residual p = predicted;\nrun;\n\n/* Residuals vs. Fitted Values */\nproc sgplot data = diagnostics;\n    scatter x = predicted y = residual;\n    refline 0 / axis = y;\nrun;\n\n/* Residuals vs. Explanatory Variable */\nproc sgplot data = diagnostics;\n    scatter x = explanatory y = residual;\n    refline 0 / axis = y;\nrun;\n\n```\n:::\n\n\n\n\n\n### 8B. Studentized Residuals\n\n> Studentized residuals help detect outliers by standardizing residuals using their estimated standard errors.\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Use PROC REG to compute studentized residuals */\nproc reg data = dataset;\n    model response = explanatory;\n    output out = diagnostics\n        rstudent = studentized_resid  /* Studentized residuals */\n        h = leverage;                 /* Leverage values (optional) */\nrun;\n\nproc print data = diagnostics;\n    var response explanatory studentized_resid leverage;\nrun;\n\n/* Optional: plot studentized residuals */\nproc sgplot data = diagnostics;\n    scatter x = explanatory y = studentized_resid;\n    refline 0 / axis = y;\nrun;\n\n```\n:::\n\n\n\n\n\n### 8C. Influence Diagnostics\n\n> Influence diagnostics help identify observations that have an unusually large effect on the model. These include leverage, Cook's distance, and DFFITS.\n\n\n\n\n::: {.cell}\n\n```{.sas .cell-code}\n\n/* Influence statistics from PROC REG */\nods graphics on;\n\nproc reg data = dataset;\n    model response = explanatory;\n    output out = influence_out\n        rstudent = studentized_resid\n        cookd = cooks_d\n        dffits = dffits_val\n        h = leverage;\nrun;\n\nods graphics off;\n\nproc print data = influence_out;\n    var response explanatory studentized_resid cooks_d dffits_val leverage;\nrun;\n\n/* Visualize Cook’s Distance for all observations */\nproc sgplot data = influence_out;\n    scatter x = _N_ y = cooks_d;\n    refline 4 / axis = y;  /* Optional threshold line (e.g. rule of thumb for large values) */\nrun;\n\n```\n:::\n\n\n\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}