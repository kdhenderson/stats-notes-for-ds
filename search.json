[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Henderson’s Statistics Notes for Data Science",
    "section": "",
    "text": "Introduction\nThis book serves as a companion for students in the SMU Master of Science in Data Science program, specifically for the Statistical Foundations and Applied Statistics courses. It is designed to summarize both the theoretical understanding and practical applications of statistical methods.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Henderson's Statistics Notes</span>"
    ]
  },
  {
    "objectID": "index.html#book-structure",
    "href": "index.html#book-structure",
    "title": "Henderson’s Statistics Notes for Data Science",
    "section": "Book Structure",
    "text": "Book Structure\n\nPart 1: Statistical Foundations: Covers the theoretical groundwork.\nPart 2: Applied Statistics: Focuses on real-world statistical applications.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Henderson's Statistics Notes</span>"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Henderson’s Statistics Notes for Data Science",
    "section": "License",
    "text": "License\nThis book is licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0).\nAll code examples are licensed under the MIT License.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Henderson's Statistics Notes</span>"
    ]
  },
  {
    "objectID": "index.html#software-and-output",
    "href": "index.html#software-and-output",
    "title": "Henderson’s Statistics Notes for Data Science",
    "section": "Software and Output",
    "text": "Software and Output\nThis book includes example output from SAS® and R, generated using instructional or simulated datasets. These outputs are used solely for teaching and demonstration purposes. SAS is a registered trademark of SAS Institute Inc., and R is open-source software licensed under the GNU General Public License.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Henderson's Statistics Notes</span>"
    ]
  },
  {
    "objectID": "index.html#author-contributions",
    "href": "index.html#author-contributions",
    "title": "Henderson’s Statistics Notes for Data Science",
    "section": "Author Contributions",
    "text": "Author Contributions\n\nProfessor of Applied Statistics and Professor of Statistical Foundations: Developed the original course materials and lectures on which this book is based.\nKristin Henderson: Compiled, adapted, and updated these notes from the original course materials, and prepared the Quarto book for publication.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Henderson's Statistics Notes</span>"
    ]
  },
  {
    "objectID": "foundation-chapter01.html",
    "href": "foundation-chapter01.html",
    "title": "Drawing Statistical Conclusions",
    "section": "",
    "text": "Objectives\nThis chapter introduces how statistical studies are designed, how we draw conclusions from them, and how uncertainty is measured through hypothesis testing and resampling methods.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Drawing Statistical Conclusions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter01.html#objectives",
    "href": "foundation-chapter01.html#objectives",
    "title": "Drawing Statistical Conclusions",
    "section": "",
    "text": "Distinguish between observational studies and experiments, including the role of randomization.\n\nUnderstand key sampling methods and definitions (parameter vs. statistic).\n\nRecognize ethical requirements for data collection, including informed consent and IRB review.\n\nConduct hypothesis tests and interpret p-values in context.\n\nUse permutation testing to assess the likelihood of observed results under random assignment.\n\nCommunicate statistical results clearly, including context, limitations, and reproducibility.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Drawing Statistical Conclusions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter01.html#observational-studies-vs.-experiments",
    "href": "foundation-chapter01.html#observational-studies-vs.-experiments",
    "title": "Drawing Statistical Conclusions",
    "section": "Observational Studies vs. Experiments",
    "text": "Observational Studies vs. Experiments\n\nExperiment: The investigator actively manipulates the environment with random assignment to treatment groups.\n\nRandomization ensures groups are comparable across all potential confounding variables and removes researcher bias.\nEnables cause-and-effect conclusions.\n\nObservational study: The researcher is passive and observes without intervention.\n\nSuitable when experiments would be unethical or impractical.\nCan build evidence for causation when combined with multiple studies and theoretical reasoning (e.g., smoking causes lung cancer).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Drawing Statistical Conclusions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter01.html#statistical-sampling",
    "href": "foundation-chapter01.html#statistical-sampling",
    "title": "Drawing Statistical Conclusions",
    "section": "Statistical Sampling",
    "text": "Statistical Sampling\nRandom sampling uses chance to select a representative sample, allowing us to infer population characteristics.\n\nKey Definitions\n\nParameter: Characteristic of a population\nStatistic: Characteristic of a sample\n\n\n\nSampling Designs\n\nSimple random sample: Each individual has an equal chance of selection.\nStratified random sample: The population is divided into subgroups (e.g., gender), and random sampling is performed within each group.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Drawing Statistical Conclusions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter01.html#ethics-of-gathering-data",
    "href": "foundation-chapter01.html#ethics-of-gathering-data",
    "title": "Drawing Statistical Conclusions",
    "section": "Ethics of Gathering Data",
    "text": "Ethics of Gathering Data\n\nInformed consent must be obtained from participants so they are aware of the study’s purpose, procedures, and potential risks or benefits.\nThe Institutional Review Board (IRB) evaluates the study to determine its ethical and scientific appropriateness:\n\nEnsures the study minimizes risks and maximizes benefits.\nReviews the experimental design and statistical plan for ethical and scientific rigor.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Drawing Statistical Conclusions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter01.html#measuring-uncertainty",
    "href": "foundation-chapter01.html#measuring-uncertainty",
    "title": "Drawing Statistical Conclusions",
    "section": "Measuring Uncertainty",
    "text": "Measuring Uncertainty\n\nHypothesis Testing\n\nKey Concepts\n\nHypotheses:\n\nNull hypothesis (\\(H_0\\)): Assumes no effect or difference (e.g., treatment means are equal).\n\nBecause treatment group assignment is random, we assume that if the treatment has no effect, the population means are equal across groups.\n\nAlternative hypothesis (\\(H_a\\)): Suggests an effect or difference exists.\n\nTest statistic: A sample estimate (e.g., difference in means) divided by a measure of variability (e.g., standard error).\n\nExample: A t-statistic in a two-sample t-test.\n\np-value: Probability of observing by random chance a result as extreme as the sample, assuming \\(H_0\\) is true. Calculated using the test statistic.\nDecision: Compare the p-value to the significance level (\\(\\alpha\\)). Under the assumption that the population means are equal, a small p-value indicates that the observed result would be unlikely due to chance alone.\n\nIf \\(p &lt; \\alpha\\): Reject \\(H_0\\).\nOtherwise: Fail to reject \\(H_0\\).\n\nConclusion: Summarize the result in plain language, referencing both hypotheses and the p-value.\n\nIn observational studies, we use a fictitious chance model to apply the same calculations, but causal interpretations are limited due to lack of randomization.\n\n\n\n\nGeneral Principles\n\nEvidence is gathered by collecting a sample and analyzing differences in key metrics.\nIf \\(H_0\\) is true, differences between sample means should be small. The p-value quantifies how small is “small enough.”\n\n\n\nExample: Lottery Case\n\nAssumption (\\(H_0\\)): Bivin is playing fair.\nEvidence (test statistic): He won 10 times in a row.\nProbability (p-value): The probability of winning 10 times in a row, assuming fairness, is extremely low.\nDecision: Reject \\(H_0\\). The outcome is too unlikely under fair play.\nConclusion: Since the probability of winning 10 times in a row under fair play is so small, we conclude that Bivin is likely cheating.\n\n\n\n\nPermutation Testing\n\nPurpose: Tests results against all possible randomizations to assess how unusual the observed result is.\n\nIn an experiment, permutations represent all possible assignments of participants to treatment groups.\n\np-value calculation: Count how many permutations are as extreme as the observed result, and divide by the total number of permutations.\n\nExample: If 10 out of 1,000 permutations are as extreme as the observed result, the p-value is \\(10 / 1{,}000 = 0.01\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Drawing Statistical Conclusions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter01.html#writing-up-results",
    "href": "foundation-chapter01.html#writing-up-results",
    "title": "Drawing Statistical Conclusions",
    "section": "Writing Up Results",
    "text": "Writing Up Results\nResults are typically communicated in writing, often for non-expert audiences.\n\nInclude context about the experiment:\n\nWhat was the research question?\nWhat were the treatment groups?\nWhat was measured?\n\nInclude descriptive statistics:\n\nMean\nStandard deviation\nOutliers (with explanations)\nImportant differences observed in the data\n\nState the p-value:\n\nDoes it support or contradict \\(H_0\\)?\nWhat does this imply in the context of the study?\n\nMention challenges:\n\nDifficulties encountered during the study\nConfounding variables that may have affected results\n\nClarify the scope of the study:\n\nCan results be generalized to the target population?\nWas the sample representative?\n\nEnsure reproducibility:\n\nProvide enough detail for another researcher to reproduce the study.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Drawing Statistical Conclusions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html",
    "href": "foundation-chapter02.html",
    "title": "Inference Using T-Distributions",
    "section": "",
    "text": "Objectives\nThis chapter introduces confidence intervals and hypothesis tests based on t-distributions, which are used when population standard deviations are unknown. You will learn to:",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#objectives",
    "href": "foundation-chapter02.html#objectives",
    "title": "Inference Using T-Distributions",
    "section": "",
    "text": "Apply the Central Limit Theorem (CLT) to inference problems.\n\nConstruct and interpret confidence intervals using the t-distribution.\n\nPerform hypothesis tests and compute t-statistics and p-values.\n\nLink confidence intervals to hypothesis test results.\n\nDistinguish statistical from practical significance.\n\nUse R to calculate critical values and p-values.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#central-limit-theorem-clt",
    "href": "foundation-chapter02.html#central-limit-theorem-clt",
    "title": "Inference Using T-Distributions",
    "section": "Central Limit Theorem (CLT)",
    "text": "Central Limit Theorem (CLT)\nIf we draw a large enough sample from a normal (or approximately normal) distribution, the sampling distribution of the sample mean will also be normal. The mean of this sampling distribution of the sample means equals the population mean from which those sample means were taken. This allows us to use the sampling mean, \\(\\bar{X}\\), to make inferences about the population mean, \\(\\mu\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#interpretation-of-a-confidence-interval",
    "href": "foundation-chapter02.html#interpretation-of-a-confidence-interval",
    "title": "Inference Using T-Distributions",
    "section": "Interpretation of a Confidence Interval",
    "text": "Interpretation of a Confidence Interval\nIf we took many random samples from the same population and constructed a confidence interval for the mean from each one, then approximately 95% of those intervals would contain the true mean. For a single interval, we interpret this as: we are 95% confident that the interval contains the true mean.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#confidence-intervals",
    "href": "foundation-chapter02.html#confidence-intervals",
    "title": "Inference Using T-Distributions",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nMeasure how large or small a parameter value could plausibly be.\n\nRandom sampling leads to slightly different sample means (estimates of the population mean).\n\nA confidence interval is constructed around \\(\\bar{X}\\) with a given level of confidence that it contains \\(\\mu\\). In other words, it contains the plausible values of \\(\\mu\\).\nFrom normal distribution theory:\n\nApproximately 68% of values lie within \\(1\\sigma\\) of \\(\\mu\\)\nApproximately 95% within \\(2\\sigma\\)\n\nApproximately 99.7% within \\(3\\sigma\\)\n\n\nIn practice, we usually estimate both the population mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)) using sample values. We estimate \\(\\sigma\\) using the sample standard deviation, \\(s\\).\n\nThe t-distribution has fatter tails than the normal distribution to account for additional uncertainty from estimating \\(\\sigma\\) with the sample standard deviation \\(s\\).\n\nThe formula for a confidence interval is: \\[\nCI = \\bar{X} \\pm t_{\\text{crit}} \\left( \\frac{s}{\\sqrt{n}} \\right)\n\\] where \\(t_{\\text{crit}}\\) is based on the desired confidence level and degrees of freedom.\nExample confidence interval statement: “With \\((1-\\alpha) \\times 100\\%\\) confidence, the true mean \\(\\mu\\) is between [lower bound] and [upper bound], based on a sample of size \\(n\\) from this population.”",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#hypothesis-testing",
    "href": "foundation-chapter02.html#hypothesis-testing",
    "title": "Inference Using T-Distributions",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nSteps for Testing Significance\n\nChoose a significance level (\\(\\alpha\\)):\n\n\\(\\alpha\\) is the probability of a Type I error (rejecting \\(H_0\\) when it is true).\n\nSmaller values of \\(\\alpha\\) reduce the chance of a Type I error.\n\nSpecify the test direction and check assumptions:\n\nChoose a one-sided or two-sided test.\n\nConfirm that assumptions are met (e.g., approximate normality, random sampling).\n\nState the hypotheses (i.e., assumptions about the population parameter or parameters):\n\n\\(H_0\\): Null hypothesis (no effect or difference)\n\n\\(H_a\\): Alternative hypothesis (effect or difference exists)\n\nFollow these six steps:\n\nIdentify \\(H_0\\) and \\(H_a\\).\n\nFind the critical value(s) and draw and shade the rejection region.\n\nCalculate the test statistic (i.e., the evidence).\n\nCompute the p-value.\n\nCompare the p-value to \\(\\alpha\\) and decide whether to reject or fail to reject \\(H_0\\).\n\nWrite a conclusion in non-technical terms, including the p-value, confidence interval, and scope.\n\n\n\n\nTest Statistic\nA test statistic is a sample estimate divided by its variability (standard error): \\[\nt = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}\n\\]\n\nFor a one-sided test, the sign of the numerator matters. Always subtract \\(\\mu_0\\) from the sample mean \\(\\bar{X}\\).\n\n\n\np-Value\n\nCalculated assuming \\(H_0\\) is true.\n\nA small p-value suggests the observed difference is unlikely due to random variation alone.\n\nThe p-value is the area in one or both tails beyond the observed t-statistic, depending on the form of \\(H_a\\).\n\nA p-value is a probability - not a binary cutoff. Report the value and let the reader decide.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#linking-hypothesis-tests-and-confidence-intervals",
    "href": "foundation-chapter02.html#linking-hypothesis-tests-and-confidence-intervals",
    "title": "Inference Using T-Distributions",
    "section": "Linking Hypothesis Tests and Confidence Intervals",
    "text": "Linking Hypothesis Tests and Confidence Intervals\n\nA \\((1 - \\alpha) \\times 100\\%\\) confidence interval corresponds to a two-sided hypothesis test at significance level \\(\\alpha\\).\n\nIf the null value is outside the interval, we reject \\(H_0\\) at level \\(\\alpha\\).\nConfidence intervals provide an alternative way to evaluate hypothesis test results.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#statistical-significance-vs.-practical-significance",
    "href": "foundation-chapter02.html#statistical-significance-vs.-practical-significance",
    "title": "Inference Using T-Distributions",
    "section": "Statistical Significance vs. Practical Significance",
    "text": "Statistical Significance vs. Practical Significance\n\nStatistical significance means the result is unlikely due to random sampling error.\n\nPractical significance considers whether the effect is meaningful in context.\n\np-values are affected by sample size—large samples can make small effects statistically significant.\n\nEffect size (e.g., Cohen’s \\(d\\)) helps assess practical importance.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#in-r",
    "href": "foundation-chapter02.html#in-r",
    "title": "Inference Using T-Distributions",
    "section": "In R",
    "text": "In R\n\nCritical value: qt(probability, df)\n\nFor a two-sided test, use \\(\\alpha/2\\) and \\(1 - \\alpha/2\\).\n\nFor a one-sided test, use \\(\\alpha\\) or \\(1 - \\alpha\\).\n\np-value: pt(t_statistic, df, lower.tail = TRUE/FALSE)\n\nMultiply by 2 for a two-sided p-value.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter02.html#complete-analysis-format",
    "href": "foundation-chapter02.html#complete-analysis-format",
    "title": "Inference Using T-Distributions",
    "section": "Complete Analysis Format",
    "text": "Complete Analysis Format\n\nState the problem clearly.\n\nCheck that the assumptions are satisfied.\n\nPerform the appropriate test (using the six steps).\n\nWrite a conclusion in plain language, including:\n\nThe p-value\n\nThe confidence interval\n\nThe scope of inference",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inference Using T-Distributions</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html",
    "href": "foundation-chapter03.html",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#objectives",
    "href": "foundation-chapter03.html#objectives",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "",
    "text": "Review key elements of experimental design that support valid inference.\n\nUnderstand conditions and assumptions required for t-tests.\n\nIdentify and handle non-normality, unequal variance, and outliers.\n\nApply and interpret log transformations in skewed data.\n\nDistinguish between robustness and resistance in statistical tools.\n\nUse appropriate visual tools to assess assumptions and variance.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#experimental-design",
    "href": "foundation-chapter03.html#experimental-design",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Experimental Design",
    "text": "Experimental Design\n\nRandomization: Reduces potential bias by ensuring treatment groups are comparable.\n\nPlacebo: Controls for confounding variables by ensuring that only the treatment effect—the variable being tested—differs between groups.\nBlinding: Minimizes bias in outcomes by preventing subjects or researchers from knowing the treatment assignments.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#conditions-for-null-hypothesis-significance-testing-nhst",
    "href": "foundation-chapter03.html#conditions-for-null-hypothesis-significance-testing-nhst",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Conditions for Null Hypothesis Significance Testing (NHST)",
    "text": "Conditions for Null Hypothesis Significance Testing (NHST)\n\nRandom sampling\n\nIndependent observations\n\nRepresentative of the population: The sample reflects the population of interest.\n\nQuantitative data\n\nNearly normal distribution\n\nEqual standard deviations for two-sample tests\n\nAlso called homoscedasticity, meaning the groups have the same shape and spread.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#paired-t-test",
    "href": "foundation-chapter03.html#paired-t-test",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Paired t-Test",
    "text": "Paired t-Test\n\nUsed when the assumption of independence is violated due to pairing.\n\nCompares the difference between paired observations using a one-sample t-test.\n\nCommon in before-and-after studies or matched-subject designs.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#tools-for-checking-normality",
    "href": "foundation-chapter03.html#tools-for-checking-normality",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Tools for Checking Normality",
    "text": "Tools for Checking Normality\n\nBoxplot\n\nVisualizes the five-number summary.\n\nHighlights symmetry, skewness, and tail behavior.\n\nUseful for comparing groups side by side.\n\n\nDotplot\n\nDisplays individual data points.\n\nEasy to construct and interpret for small to moderate sample sizes.\n\n\nHistogram\n\nShows the distribution’s shape and symmetry.\n\nUseful for identifying skewness or multiple modes.\n\n\nNormal Quantile (QQ) Plot\n\nPlots theoretical normal values (X-axis) against observed data (Y-axis).\n\nPoints that align closely along a straight line suggest normality.\n\nSensitive to departures from normality, especially in the tails.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#robustness",
    "href": "foundation-chapter03.html#robustness",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Robustness",
    "text": "Robustness\n\nA procedure is robust if its results remain valid despite minor violations of assumptions.\n\nExample: A 95% confidence interval should still capture the true parameter 95% of the time, even if the data are not perfectly normal.\n\n\nModerate Robustness in t-Tools\n\nSample size effects:\n\nLarger samples tolerate greater departures from normality.\n\nException: Heavy-tailed distributions (i.e., many large outliers) can still distort results.\n\nTwo-sample t-tests:\n\nProblems arise when the groups have different shapes or skewness, or when standard deviations are unequal.\n\nThe worst-case scenario occurs when the group with the smaller sample size also has the larger standard deviation.\n\nIn this case, the sample may fail to accurately represent the population’s variability.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#independence",
    "href": "foundation-chapter03.html#independence",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Independence",
    "text": "Independence\n\nDefinition: Observations are independent if knowing one value provides no information about another.\n\nIndependence must be built into the experimental design.\n\nCluster effects:\n\nArise when data are grouped in natural subunits (e.g., littermates, classrooms).\n\nViolates independence unless each cluster is treated as a single observational unit or analyzed appropriately.\n\nSerial effects:\n\nOccur when measurements are taken over time (e.g., time series data).\n\nNearby values may be correlated, violating independence.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#outliers",
    "href": "foundation-chapter03.html#outliers",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Outliers",
    "text": "Outliers\n\nDefinition: Observations that fall far from the central tendency of the data (e.g., the group average).\nEffects:\n\nCan create long-tailed distributions.\n\nt-statistics are sensitive to outliers and can be distorted by extreme values.\n\n\n\nDealing with Outliers\n\nDo not remove outliers unless they result from data entry or measurement error.\n\nRun analyses with and without outliers and compare the results.\n\nReport both versions to provide transparency.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#resistance",
    "href": "foundation-chapter03.html#resistance",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Resistance",
    "text": "Resistance\n\nA procedure is resistant if its results remain stable when small parts of the data change.\n\nExample: The median is resistant to outliers, while the mean is not.\n\n\nt-tools are based on means and are not resistant to outliers or long-tailed distributions.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#log-transformation-natural-log",
    "href": "foundation-chapter03.html#log-transformation-natural-log",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Log Transformation (Natural Log)",
    "text": "Log Transformation (Natural Log)\n\nWhen to use:\n\nThe ratio of the largest to smallest value is greater than 10.\n\nThe data are skewed.\n\nThe group with the larger mean also has the larger variance.\n\nEffects:\n\nReduces skew, improves normality, and corrects non-constant variance.\n\nRequires back-transformation to interpret results (e.g., medians, confidence intervals) on the original scale.\n\n\n\nOther Transformations\n\nSquare root\n\nInverse\n\nReciprocal\n&gt; Note: These transformations are harder to back-transform than log transformations and may complicate interpretation.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#log-transformations-propositions-from-log-properties",
    "href": "foundation-chapter03.html#log-transformations-propositions-from-log-properties",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Log Transformations: Propositions from Log Properties",
    "text": "Log Transformations: Propositions from Log Properties\nThese propositions come from basic properties of logarithms and allow us to translate log-scale comparisons back to the original measurement scale.\n\nNormal distribution: In a normal distribution, the mean equals the median.\n\nMonotonicity: The log function is monotonically increasing, so \\(\\log(\\text{median}(x)) = \\text{median}(\\log(x))\\).\n\nLog differences: \\(\\log(a) - \\log(b) = \\log\\left(\\frac{a}{b}\\right)\\)\n\nExponentiation: \\(e^{\\log(x)} = x\\)",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#t-test-interpretation-log-transformed-data",
    "href": "foundation-chapter03.html#t-test-interpretation-log-transformed-data",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "t-Test Interpretation (Log-Transformed Data)",
    "text": "t-Test Interpretation (Log-Transformed Data)\nWe apply the previous propositions to interpret results from a t-test on log-transformed data. Suppose: \\[\n\\text{mean}(\\log(x)) - \\text{mean}(\\log(y)) = \\gamma\n\\]\nBecause the distribution is approximately normal, we assume the mean and median are roughly equal: \\[\n\\text{median}(\\log(x)) - \\text{median}(\\log(y)) = \\gamma\n\\]\nThe logarithmic function is monotonically increasing: \\[\n\\log(\\text{median}(x)) - \\log(\\text{median}(y)) = \\gamma\n\\]\nRewriting using the log difference identity: \\[\n\\log\\left(\\frac{\\text{median}(x)}{\\text{median}(y)}\\right) = \\gamma\n\\]\nExponentiating both sides: \\[\ne^{\\log\\left(\\frac{\\text{median}(x)}{\\text{median}(y)}\\right)} = e^\\gamma\n\\]\nTherefore: \\[\n\\frac{\\text{median}(x)}{\\text{median}(y)} = e^\\gamma\n\\]\n\nInterpretation\nThe median of group \\(x\\) is estimated to be \\(e^\\gamma\\) times the median of group \\(y\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#inequality-of-variance",
    "href": "foundation-chapter03.html#inequality-of-variance",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Inequality of Variance",
    "text": "Inequality of Variance\n\nVisual evidence should be the primary tool for detecting unequal variances (e.g., side-by-side boxplots or spread differences in histograms).\n\nF-test: A formal test for equality of variances, but it is sensitive to violations of normality.\n\n\\(H_0\\): Population variances are equal.\n\n\\(H_a\\): Population variances are not equal.\n\n\nUse hypothesis tests for equality of variance with caution, and only when assumptions are satisfied.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#general-rules-of-thumb",
    "href": "foundation-chapter03.html#general-rules-of-thumb",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "General Rules of Thumb",
    "text": "General Rules of Thumb\n\nWhen sample sizes are equal and large, t-tools are generally robust.\n\nWhen standard deviations differ:\n\nIf sample sizes are equal: t-tools are still valid with large samples.\n\nIf sample sizes are unequal: t-tools are not valid and alternative methods should be considered.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#welchs-t-test",
    "href": "foundation-chapter03.html#welchs-t-test",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Welch’s t-Test",
    "text": "Welch’s t-Test\n\nDesigned to handle situations where population standard deviations are unequal.\n\nAdjusts the degrees of freedom using the Satterthwaite approximation.\n\nStill assumes normality in the underlying populations.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#non-normal-distributions",
    "href": "foundation-chapter03.html#non-normal-distributions",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "Non-Normal Distributions",
    "text": "Non-Normal Distributions\n\nLong-tailed distributions:\n\nCan produce wider confidence intervals than expected (e.g., greater than the nominal \\((1 - \\alpha)\\%\\) level—for example, more than 95% when using a 95% CI), leading to fewer rejections of the null hypothesis.\n\nThese wider intervals increase the chance of capturing the true mean \\(\\mu\\), pushing the actual coverage above \\((1 - \\alpha)\\%\\) and resulting in rejection rates below \\(\\alpha\\).\n\n\nUnequal sample sizes and variances\n\nWhen both sample sizes and standard deviations differ substantially, confidence intervals may become too narrow or too wide.\n\nThis can cause actual coverage rates to deviate from the nominal 95% level—either above or below—depending on the direction of the imbalance.\n\n\nSee Displays 3.4 and 3.5 in The Statistical Sleuth (Ramsey and Schafer 2012) for simulation-based evidence.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter03.html#references",
    "href": "foundation-chapter03.html#references",
    "title": "Data Screening, Assumptions, and Transformations",
    "section": "References",
    "text": "References\n\n\n\n\nRamsey, F., and D. Schafer. 2012. The Statistical Sleuth: A Course in Methods of Data Analysis. Cengage Learning. https://books.google.com/books?id=jfoKAAAAQBAJ.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Screening, Assumptions, and Transformations</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html",
    "href": "foundation-chapter04.html",
    "title": "Type I, Type II Error, and Power",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#objectives",
    "href": "foundation-chapter04.html#objectives",
    "title": "Type I, Type II Error, and Power",
    "section": "",
    "text": "Define and distinguish between Type I error, Type II error, and statistical power.\nExplain how effect size, sample size, and significance level influence power.\nCalculate power or required sample size using R or SAS.\nCreate and interpret power curves to communicate trade-offs in study design.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#helpful-resources",
    "href": "foundation-chapter04.html#helpful-resources",
    "title": "Type I, Type II Error, and Power",
    "section": "Helpful Resources",
    "text": "Helpful Resources\n\nInteractive Power Applet\nSAS Power and Sample Size Documentation",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#hypothesis-test-errors-and-outcomes",
    "href": "foundation-chapter04.html#hypothesis-test-errors-and-outcomes",
    "title": "Type I, Type II Error, and Power",
    "section": "Hypothesis Test Errors and Outcomes",
    "text": "Hypothesis Test Errors and Outcomes\n\nType I Error\n\nIf the null hypothesis (\\(H_0\\)) is true, the test is correct when it fails to reject \\(H_0\\).\nRejecting \\(H_0\\) when it is true is a Type I error, with a probability equal to \\(\\alpha\\).\nThe critical value determines the rejection region. If \\(\\bar{x}\\) falls on the \\(H_0\\) side, the test fails to reject.\nThere is an \\(\\alpha\\)% chance that \\(H_0\\) is true and \\(\\bar{x}\\) is as extreme or more extreme than the critical value, leading to a Type I error.\n\n\n\nType II Error\n\nIf \\(H_0\\) is false, the test is correct when it rejects \\(H_0\\).\nFailing to reject \\(H_0\\) when it is false is a Type II error, with a probability equal to \\(\\beta\\).\n\n\n\nHypothesis Test Outcome Matrix\nThe following matrix summarizes the four possible outcomes of a hypothesis test, highlighting the probabilities of Type I error (\\(\\alpha\\)), Type II error (\\(\\beta\\)), and power (\\(1 - \\beta\\)).\n\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\n& H_0\\ \\textbf{True} & H_0\\ \\textbf{False} \\\\ \\hline\n\\textbf{Reject } H_0 & \\text{Type I error } (\\alpha) & \\text{✅ Power } (1 - \\beta) \\\\ \\hline\n\\textbf{FTR } H_0 & \\text{✅ Correct} & \\text{Type II error } (\\beta) \\\\ \\hline\n\\end{array}\n\\]\n\nMatrix of hypothesis test outcomes based on the truth of \\(H_0\\) and the decision to reject or not reject.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#power",
    "href": "foundation-chapter04.html#power",
    "title": "Type I, Type II Error, and Power",
    "section": "Power",
    "text": "Power\n\nPower is the probability of correctly rejecting \\(H_0\\) when it is false (\\(1 - \\beta\\)).\nIt measures the test’s ability to detect true differences between population distributions.\nHigher power means a greater likelihood of detecting a real effect.\n\nExample power statement: “At [power level]% power, this study can detect an effect size of \\(\\Delta\\) or larger at \\(\\alpha\\) = [significance level] with \\(n\\) = [sample size].”",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#effect-size",
    "href": "foundation-chapter04.html#effect-size",
    "title": "Type I, Type II Error, and Power",
    "section": "Effect Size",
    "text": "Effect Size\n\nEffect size is the difference between the null mean and the true mean.\nExample: If the null mean is 50 and the true mean is 60, the raw effect size is 10.\nCohen’s d is a standardized measure of effect size: \\[\nd = \\frac{\\text{raw effect size}}{\\text{standard deviation}} = \\frac{\\mu_1 - \\mu_0}{\\sigma}\n\\]\n\nIt normalizes the difference between the means using the standard deviation.\n\nIncreasing effect size increases power and decreases \\(\\beta\\), but it does not affect the critical value or \\(\\alpha\\).\nPower and the probability of a Type II error depend on the actual value of \\(\\mu\\).\n\n\n\n\nSampling Distributions, Power, and Effect Size. This diagram illustrates the relationship between effect size, critical values, power, and Type I and Type II errors. Narrower distributions from larger sample sizes improve the ability to detect true differences.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#how-to-increase-power",
    "href": "foundation-chapter04.html#how-to-increase-power",
    "title": "Type I, Type II Error, and Power",
    "section": "How to Increase Power",
    "text": "How to Increase Power\n\nIncrease effect size: Larger differences are easier to detect.\nIncrease \\(\\alpha\\): A less stringent threshold makes rejection more likely. Increasing \\(\\alpha\\) makes the critical value less extreme, making it easier for the test statistic to exceed it, thus increasing the chance of rejecting \\(H_0\\).\nIncrease sample size: Larger samples reduce variability in \\(\\bar{x}\\), making it more likely to be close to \\(\\mu\\) and increasing the likelihood of detecting true effects.\n\n\nNote: If power is close to \\(\\beta\\), the chances of detecting a difference or making a Type II error are similar. This may occur when the effect size is small. Increasing the sample size can help.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#balancing-type-i-and-type-ii-errors",
    "href": "foundation-chapter04.html#balancing-type-i-and-type-ii-errors",
    "title": "Type I, Type II Error, and Power",
    "section": "Balancing Type I and Type II Errors",
    "text": "Balancing Type I and Type II Errors\n\nReducing \\(\\alpha\\) decreases the probability of a Type I error but increases the probability of a Type II error.\nThere is often a trade-off between these two error types, so both should be considered in study design.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#example-code-for-finding-power-or-other-missing-parameters",
    "href": "foundation-chapter04.html#example-code-for-finding-power-or-other-missing-parameters",
    "title": "Type I, Type II Error, and Power",
    "section": "Example Code For Finding Power or Other Missing Parameters",
    "text": "Example Code For Finding Power or Other Missing Parameters\nR code:\n\n\nCode\nlibrary(tidyverse)\n\n## Missing parameter is indicated with `NULL`\n\n# One-sample t-test power calculation\npower.t.test(n = 41, delta = .07, \n             sd = 0.2, sig.level = 0.05,\n             power = NULL, \n             type = \"one.sample\", alternative = \"one.sided\")\n\n# Two-sample t-test example\npower.t.test(n = 250, delta = 5,\n             sd = 25, sig.level = 0.05, \n             power = NULL, \n             type = \"two.sample\", alternative = \"one.sided\")\n\n\nSAS code:\n\n\nCode\n/* Missing parameter is indicated with a period */\n\n/* One-sample t-test */\nproc power;\n    onesamplemeans\n        sides = 1\n        alpha = 0.1\n        nullmean = 20000\n        mean = 20450\n        stddev = 500\n        ntotal = 8\n        power = .;  /* parameter to solve for */\nrun;\n\n/* Two-sample t-test */\nproc power;\n*can specify mean for each (nullmean) and ntotal;   \n    twosamplemeans\n        sides = 1\n        alpha = 0.05\n        meandiff = 4\n        stddev = 3\n        npergroup = 50\n        power = .;  /* parameter to solve for */\nrun;",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#example-code-for-creating-a-power-curve",
    "href": "foundation-chapter04.html#example-code-for-creating-a-power-curve",
    "title": "Type I, Type II Error, and Power",
    "section": "Example Code For Creating a Power Curve",
    "text": "Example Code For Creating a Power Curve\nR code:\n\n\nCode\n# Loop to calculate power for sample sizes from 60 to 80\npowerholder = c()\nsamplesizes = seq(60, 80, by = 1)\n\nfor(i in 1:length(samplesizes)) {\n  powerholder[i] = power.t.test(n = samplesizes[i], delta = 0.07, sd = 0.20, sig.level = 0.05,\n                                type = \"one.sample\", alternative = \"one.sided\")$power\n}\n\n# Create a data frame\npowerdf = data.frame(samplesizes, powerholder)\n\n# Plot the power curve\npowerdf %&gt;% \n  ggplot(aes(x = samplesizes, y = powerholder)) +\n  geom_line(color = \"blue3\", linewidth = 1.5) +\n  ggtitle(\"Power Curve\") +\n  ylab(\"Power\") +\n  xlab(\"Sample Size\") +\n  ylim(0.75, 1.0) +\n  theme_bw()\n\n\nSAS code:\n\n\nCode\n/* Power curve for different sample sizes */\nods graphics on;\n\nproc power;\n    onesamplemeans\n        sides = 1\n        alpha = 0.05\n        nullmean = 0\n        ntotal = 60 80\n        mean = 0.07\n        stddev = 0.2\n        power = .;  /* parameter to solve for */\n        plot x = n min = 60 max = 80;\nrun;\n\nods graphics off;\n\n/* Power curve for different effect sizes */\nods graphics on;\n\nproc power;\n    twosamplemeans\n        sides = 1\n        alpha = 0.05\n        nulldiff = 0\n        meandiff = 3 to 5 by 0.1 \n        ntotal = 47\n        stddev = 4.5\n        power = .;  /* parameter to solve for */\n        plot x = effect min = 3 max = 5;\nrun;\n\nods graphics off;",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter04.html#summary-of-start-to-finish-analysis-for-client-presentation",
    "href": "foundation-chapter04.html#summary-of-start-to-finish-analysis-for-client-presentation",
    "title": "Type I, Type II Error, and Power",
    "section": "Summary of Start-to-Finish Analysis for Client Presentation",
    "text": "Summary of Start-to-Finish Analysis for Client Presentation\n\nInitial Meetings & Research Planning Phase\n\nDefine key parameters, such as desired power (e.g., at least 80%).\nConduct a power analysis to determine required sample sizes for different power thresholds.\nProvide multiple design options based on budget and desired power.\nCreate power curves to visualize trade-offs between sample size and power.\n\n\n\nFinal Presentation & Results Communication\n\nRestate the research question and test parameters.\nDisplay descriptive statistics and plots (e.g., boxplots, histograms).\nPresent test results, including p-values and confidence intervals.\nInclude a summary of assumptions and a six-step test outline in the appendix.\nShare contact information for follow-up.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Type I, Type II Error, and Power</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html",
    "href": "foundation-chapter05.html",
    "title": "Alternatives to the T-Tools",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html#objectives",
    "href": "foundation-chapter05.html#objectives",
    "title": "Alternatives to the T-Tools",
    "section": "",
    "text": "Recognize when the assumptions of the t-tools are violated or when these tools are inappropriate.\nUnderstand the logic and implementation of rank-based and permutation-based alternatives.\nApply and interpret the results of nonparametric tests, including the rank-sum test, signed-rank test, and permutation test.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html#nonparametric-methods",
    "href": "foundation-chapter05.html#nonparametric-methods",
    "title": "Alternatives to the T-Tools",
    "section": "Nonparametric Methods",
    "text": "Nonparametric Methods\nNonparametric methods provide a solution when assumptions of the t-test cannot be met, such as:\n\nSevere skewness in the data.\nLarge differences in variances between groups.\nSmall sample sizes that preclude assumptions about the population distribution.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html#censored-data",
    "href": "foundation-chapter05.html#censored-data",
    "title": "Alternatives to the T-Tools",
    "section": "Censored Data",
    "text": "Censored Data\nCensored data occurs when the exact value of an observation is unknown, often due to exceeding a measurement threshold (e.g., students taking longer than the maximum allowed time to complete a test).\nRank-based tests, such as the rank-sum test, rely on the ordering of data rather than specific values, making them robust to censored observations.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html#permutation-test",
    "href": "foundation-chapter05.html#permutation-test",
    "title": "Alternatives to the T-Tools",
    "section": "Permutation Test",
    "text": "Permutation Test\nA permutation test is a flexible, nonparametric alternative to the two-sample t-test.\nAssumptions:\n\nThe null hypothesis is true, and all permutations (random shufflings) of the data are equally likely under the null.\nThe test does not assume normality.\nThe null distribution is generated by repeatedly permuting the observed data.\n\nProcedure:\n\nCombine all \\(n + m\\) observations from the two groups.\nRandomly reassign labels to simulate permutation under \\(H_0\\).\nCompute a test statistic (e.g., mean, median, or ratio) for each permutation.\nCompare the observed test statistic to the permutation distribution.\n\nApplications:\n\nSuitable for small or non-normal datasets, especially when there are ties.\nEffective for a wide range of statistics including means, medians, and ratios.\nNot appropriate when the data have an inherent order that must be preserved.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html#wilcoxon-rank-sum-test",
    "href": "foundation-chapter05.html#wilcoxon-rank-sum-test",
    "title": "Alternatives to the T-Tools",
    "section": "Wilcoxon Rank-Sum Test",
    "text": "Wilcoxon Rank-Sum Test\nPurpose:\n\nA distribution-free method for comparing two independent samples.\nParticularly useful with small samples, where normality assumptions cannot be assessed.\nResistant to outliers.\nCapable of handling censored observations.\n\nHypothesis:\n\n\\(H_0\\): The two populations have equal medians.\n\nProcedure:\n\nCombine all observations and rank them (assign average ranks for ties).\nCompute the rank sum for one group (typically the smaller group, for ease of computation).\n\nThis rank sum serves as the test statistic.\n\nCompute the p-value:\n\nExact Method:\n\nEvaluate all possible permutations of ranks under \\(H_0\\) to generate the exact distribution of rank sums.\nCompute the proportion of permutations with rank sums as or more extreme than the observed value.\n\nThe number of rank sums greater than or equal to the observed value divided by the total number of permutations\n\nEquivalent to a permutation test on the rank sum statistic, rather than the difference in means.\nNot computationally feasible for large \\(n\\).\n\nNormal Approximation:\n\nFor larger samples (with few ties), the rank sum statistic approximates a normal distribution.\nCompute a Z-statistic using: \\[\nZ = \\frac{T - \\text{Mean}(T)}{\\text{SD}(T)}\n\\] Where:\n\n\\(T\\): The observed rank sum.\n\\(\\text{Mean}(T) = n_1 \\bar{R}\\), with \\(\\bar{R}\\) the average rank of all combined observations.\n\\(\\text{SD}(T) = s_R \\sqrt{ \\frac{n_1 n_2}{n_1 + n_2} }\\), where \\(s_R\\) is the standard deviation of all ranks.\n\nApply a continuity correction to improve p-value accuracy:\n\nAdd 0.5 to \\(T\\) for a left-tailed test.\nSubtract 0.5 from \\(T\\) for a right-tailed test.\n\nThis correction improves the match between the discrete statistic and the continuous normal curve.\n\n\n\nConfidence Intervals:\n\nUse the Hodges–Lehmann estimator to construct a confidence interval for the difference in medians.\n\n\nVisualizing the Continuity Correction\nWhen the rank sum distribution is approximated by a normal curve, a continuity correction adjusts for the fact that \\(T\\) is discrete.\nConceptually:\n\nThe rank sum statistic creates a histogram-like distribution (discrete bars).\nExact p-values are based on shaded bar areas beyond a cutoff.\nThe normal approximation uses a smooth curve instead.\nThe continuity correction shifts the normal cutoff to the center of the bar, improving the approximation.\n\n\n\n\nHow continuity correction improves normal approximation.\nIllustration of continuity correction in a rank-based test. The gray bars show the exact (discrete) distribution of the test statistic. The black curve represents the normal approximation. The dashed vertical line at 7 is the unadjusted threshold; the dotted red line at 7.5 shows the continuity-corrected threshold, which more accurately aligns the area under the normal curve (red shaded) with the area of the histogram bars.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html#alternatives-to-the-paired-t-test",
    "href": "foundation-chapter05.html#alternatives-to-the-paired-t-test",
    "title": "Alternatives to the T-Tools",
    "section": "Alternatives to the Paired t-Test",
    "text": "Alternatives to the Paired t-Test\n\nWilcoxon Signed-Rank Test\nHypothesis:\n\n\\(H_0\\): The median difference between paired observations is zero.\nConsider direction for one-sided tests.\n\nProcedure:\n\nCompute differences between pairs.\nRank absolute differences and sum ranks of positive values.\nCompute p-value using:\n\nExact Test: All permutations of rank assignments.\nNormal Approximation: \\[\n\\text{Mean}(S) = \\frac{n(n+1)}{4}, \\quad\n\\text{SD}(S) = \\sqrt{\\frac{n(n+1)(2n+1)}{24}}, \\quad\nZ = \\frac{S - \\text{Mean}(S)}{\\text{SD}(S)}\n\\]\np-Value: Derived from software or Z-tables.\n\n\nNotes on the Signed-Rank Test:\n\nResistant to outliers.\n\nRetains information on both the magnitude and direction of differences.\n\nMore powerful than the sign test, especially when magnitude matters.\n\n\n\nWilcoxon Signed-Rank Test Example\nScenario: An employer compares mileage from a 5-day and 4-day work week for 7 employees. The goal is to test whether mileage is lower under the 4-day week (i.e., higher under the 5-day week).\nHypotheses:\n\n\\(H_0\\): \\(\\text{mileage}_5 = \\text{mileage}_4\\)\n\\(H_a\\): \\(\\text{mileage}_5 &gt; \\text{mileage}_4\\) (one-sided)\n\n\n\n\n\n\n\n\n\n\n\n\nEmployee\n5-day Mileage\n4-day Mileage\nDifference (\\(d\\))\nRank\n\\(d &gt; 0\\)?\n\n\n\n\n1\n—\n—\n\\(-119\\)\n1\nNo\n\n\n2\n—\n—\n\\(1612\\)\n6\nYes\n\n\n3\n—\n—\n\\(1328\\)\n5\nYes\n\n\n4\n—\n—\n\\(-264\\)\n2\nNo\n\n\n5\n—\n—\n\\(1311\\)\n4\nYes\n\n\n6\n—\n—\n\\(3110\\)\n7\nYes\n\n\n7\n—\n—\n\\(-467\\)\n3\nNo\n\n\n\nTest Statistic:\n\n\\(S = \\text{sum of ranks for positive differences} = 6 + 5 + 4 + 7 = 22\\)\n\nNormal Approximation (used since \\(n = 7\\) is moderately small but adequate):\n\nMean: \\[\n\\text{Mean}(S) = \\frac{n(n+1)}{4} = \\frac{7(8)}{4} = 14\n\\]\n\nInterpretation: if \\(H_0\\) is True then \\(S\\) should be \\(\\approx 14\\)\n\nStandard deviation: \\[\n\\text{SD}(S) = \\sqrt{\\frac{n(n+1)(2n+1)}{24}} = \\sqrt{\\frac{7(8)(15)}{24}} \\approx 5.92\n\\]\nApply continuity correction: \\[\nZ = \\frac{S - 0.5 - \\text{Mean}(S)}{\\text{SD}(S)} = \\frac{22 - 0.5 - 14}{5.91} \\approx 1.27\n\\]\nOne-sided p-value: \\[\nP(Z &gt; 1.27) \\approx 0.1024\n\\]\nInterpretation: There is insufficient evidence to reject \\(H_0\\) at a typical 0.05 level.\n\n\n\n\nNormal approximation to the Wilcoxon signed-rank test statistic \\(S\\) with continuity correction. The curve represents the null distribution with \\(\\text{Mean}(S) = 14\\) and \\(\\text{SD}(S) \\approx 5.92\\). The dashed line at \\(S = 22\\) is the observed value; the dotted line at \\(S - 0.5 = 21.5\\) reflects the continuity-corrected value. The shaded region corresponds to a one-sided p-value of approximately 0.1024, indicating insufficient evidence to reject \\(H_0\\).\n\n\n\n\nSign Test\nPurpose:\n\nA simple alternative to the paired t-test.\nTests for a median difference between paired observations.\nLess powerful than signed-rank or permutation tests.\n\nProcedure:\n\nCompute the paired differences.\nCount the number of positive differences (\\(K\\)).\n\nHypothesis:\n\n\\(H_0\\): \\(K = \\frac{n}{2}\\) (half of differences are positive under \\(H_0\\)).\n\nNormal Approximation (for large \\(n\\)):\n\\[\nZ = \\frac{K - 0.5 - \\frac{n}{2}}{\\sqrt{\\frac{n}{4}}}\n\\]\n\n0.5 is a continuity correction.\n\\(\\sqrt{n/4}\\) is the standard deviation of \\(K\\) under \\(H_0\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html#levenes-median-test-of-equal-spread",
    "href": "foundation-chapter05.html#levenes-median-test-of-equal-spread",
    "title": "Alternatives to the T-Tools",
    "section": "Levene’s (Median) Test of Equal Spread",
    "text": "Levene’s (Median) Test of Equal Spread\nPurpose:\n\nRobust alternative to the F-test for comparing group variances.\nHelpful when data is non-normal.\nInitial visualization (e.g., boxplots) is still recommended.\n\nHypothesis:\n\n\\(H_0\\): Groups have equal spread (variance).\n\\(H_a\\): At least one group differs in spread.\n\nProcedure:\n\nFor each observation, compute the absolute deviation from the group median: \\[\n|\\text{observation} - \\text{group median}|\n\\]\nConduct a two-sample t-test (or ANOVA) on these deviations.\nInterpret the results:\n\nReject \\(H_0\\) if the p-value is below the significance threshold, indicating unequal spread.\n\n\n\nNotes: - In SAS: - The Brown–Forsythe Test (median-based variant) can be run with proc glm. - Levene’s test (mean- or median-based) is also available in proc glm.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter05.html#code-examples",
    "href": "foundation-chapter05.html#code-examples",
    "title": "Alternatives to the T-Tools",
    "section": "Code Examples",
    "text": "Code Examples\n\nSigned-Rank and Sign Tests in SAS\n\n\nCode\n/* Paired nerve cell density comparison in horses */\n\ndata horse;\ninput horse site1 site2;\ndatalines;\n6 14.2 16.4\n4 17 19\n8 37.4 37.6\n5 11.2 6.6\n7 24.2 14.4\n9 35.2 24.4\n3 35.2 23.2\n1 50.6 38\n2 39.2 18.6\n;\n\n/* Check that the data were read correctly */\nproc print data=horse;\nrun;\n\n/* Run a paired t-test */\n/* Assumption of normality may be violated because the sample size is small */\nproc ttest data=horse;\npaired site1*site2;\nrun;\n\n/* Set up for nonparametric tests\n   H0: Median difference between site1 and site2 = 0\n   HA: Median difference ≠ 0 (two-sided)\n       or Median difference &gt; 0 (one-sided) */\n\n/* Compute difference between paired values */\ndata horse2;\nset horse;\ndiff = site1 - site2;\nrun;\n\n/* Check new dataset with the computed differences */\nproc print data=horse2;\nrun;\n\n/* Run a signed-rank test (incorporates both sign and magnitude of differences)\n   Note: PROC UNIVARIATE runs:\n     - paired t-test\n     - sign test\n     - signed-rank test */\nproc univariate data=horse2;\nvar diff;\nrun;\n\n/* Conclusion:\n   There is strong evidence that the median difference in nerve cell density\n   between sites is greater than zero\n   (p = 0.0294, one-sided Wilcoxon signed-rank test). */\n\n\n\n\n\nSigned-Rank Test in R\n\n\nCode\n# Wilcoxon signed-rank test in R\n# H0: median difference = 0\n# HA: median difference ≠ 0 (or &gt; 0 if one-sided)\n\nwilcox.test(horse$site1, horse$site2, paired = TRUE)\n\n\n\n\nLevene’s Test in SAS\n\n\nCode\n/* Test prep example: Comparing spread of scores across teaching styles */\n\ndata exam;\ninput score type $;\ndatalines;\n37 New\n49 New\n55 New\n77 New\n23 Trad\n31 Trad\n46 Trad\n;\n\n/* Levene’s test (Brown–Forsythe variant based on medians) */\nproc glm data=exam;\nclass type;\nmodel score = type;\nmeans type / hovtest=bf; /* hov = homogeneity of variance; bf = Brown–Forsythe */\nrun;\n\n/* Manual demonstration of Brown–Forsythe:\n   Calculate absolute deviations from group medians */\n\ndata medianDiff;\ninput diff type $;\ndatalines;\n15 New\n3 New\n3 New\n25 New\n8 Trad\n0 Trad\n15 Trad\n;\n\n/* A t-test on the deviations (diff) should match the Brown–Forsythe result */\nproc ttest data=medianDiff;\nclass type;\nvar diff;\nrun;",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Alternatives to the T-Tools</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html",
    "href": "foundation-chapter06.html",
    "title": "Comparisons Among Several Samples",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#objectives",
    "href": "foundation-chapter06.html#objectives",
    "title": "Comparisons Among Several Samples",
    "section": "",
    "text": "Explain the purpose of analysis of variance (ANOVA) for comparing means across multiple groups.\nFormulate and interpret hypotheses for ANOVA tests.\nCheck model assumptions to ensure the validity of ANOVA results.\nConstruct and interpret ANOVA tables using the extra sum of squares principle.\nCompare full and reduced models using \\(F\\)-tests.\nUnderstand and apply the Kruskal-Wallis test as a non-parametric alternative.\nDistinguish between fixed and random effects in the context of ANOVA.\nCalculate sample sizes needed to detect a specified effect size using power analysis.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#anova-analysis-of-variance",
    "href": "foundation-chapter06.html#anova-analysis-of-variance",
    "title": "Comparisons Among Several Samples",
    "section": "ANOVA: Analysis of Variance",
    "text": "ANOVA: Analysis of Variance\n\nPurpose: Test equality of means from more than two populations by comparing variability within groups to variability between groups.\nAssumptions:\n\nAll populations have normal distributions (reasonable symmetry in samples).\nPopulation standard deviations are equal (to ensure differences in means aren’t confounded by differences in variability).\nIndependence within (achieved automatically with random samples) and between samples.\n\nHypotheses:\n\n\\(H_0\\): All population means are equal.\n\\(H_a\\): At least one population mean differs from another.\n\nANOVA is a preliminary test; if significant, it indicates that at least one mean differs. Specific pairwise differences can be explored using post-hoc tests (not covered in detail here).\n\n\nComparing Models in ANOVA\n\nTwo competing models:\n\nEqual means model (EMM): Assumes all groups share the same population mean (null hypothesis).\nSeparate means model (SMM): Assumes each group has its own mean (alternative hypothesis).\n\nHypotheses:\n\n\\(H_0\\): \\(\\mu_1 = \\mu_2 = \\mu_3\\)\n\\(H_a\\): At least one pair of means differs\n\nA residual is defined as: \\(\\text{  Residual} = \\text{Observed} - \\text{Predicted}\\)\n\n\n\n\nEqual Means vs. Separate Means Models. Comparison of two models: one assumes all groups share a single population mean (equal means model), and the other estimates a separate mean for each group (separate means model). Brackets illustrate residuals from observed values to the grand mean.\n\n\n\nEqual Means Model (EMM)\n\nAll observations are predicted using the grand mean: \\(\\bar{X} = 13\\)\nSum of squared residuals (SSR): \\(\\text{SSR}_{\\text{EMM}} = 462\\)\n\n\n\n\n\n\n\n\n\n\nLevel\nObservation 1\nObservation 2\nObservation 3\n\n\n\n\n1\n\\((3 - 13)^2 = 100\\)\n\\((5 - 13)^2 = 64\\)\n\\((7 - 13)^2 = 36\\)\n\n\n2\n\\((10 - 13)^2 = 9\\)\n\\((12 - 13)^2 = 1\\)\n\\((14 - 13)^2 = 1\\)\n\n\n3\n\\((20 - 13)^2 = 49\\)\n\\((22 - 13)^2 = 81\\)\n\\((24 - 13)^2 = 121\\)\n\n\n\n\n\nSeparate Means Model (SMM)\n\nEach group has its own sample mean (perfect fit).\nSum of squared residuals: \\(\\text{SSR}_{\\text{SMM}} = 24\\)\n\n\n\n\nLevel\nObservation 1\nObservation 2\nObservation 3\n\n\n\n\n1\n\\((3 - 5)^2 = 4\\)\n\\((5 - 5)^2 = 0\\)\n\\((7 - 5)^2 = 4\\)\n\n\n2\n\\((10 - 12)^2 = 4\\)\n\\((12 - 12)^2 = 0\\)\n\\((14 - 12)^2 = 4\\)\n\n\n3\n\\((20 - 22)^2 = 4\\)\n\\((22 - 22)^2 = 0\\)\n\\((24 - 22)^2 = 4\\)\n\n\n\n\n\nNotes\n\nA perfect fit means predicted values match the observations exactly, so residuals are zero.\nThe sum of squared residuals (SSR) quantifies total error: \\[\n\\text{SSR} = \\sum (\\text{Observed} - \\text{Predicted})^2 = \\sum (\\text{Residual})^2\n\\]\n\n\n\n\nComparing EMM and SMM Using an \\(F\\)-Test\nTo formally compare the equal means model (EMM) and separate means model (SMM), we use an \\(F\\)-test. This test evaluates whether the extra parameters in the more complex model (SMM) explain a significantly greater portion of the total variability.\nSee the ANOVA table below for how these calculations break down.\n\nANOVA Table\n\n\n\nSource\ndf\nSS\nMS\nF\nP\n\n\n\n\nModel (Between / Extra)\n2\n438\n219\n54.75\n0.0001\n\n\nError (Within / Full / SMM)\n6\n24\n4\n\n\n\n\nTotal (Reduced / EMM)\n8\n462\n\n\n\n\n\n\n\ndf: Degrees of freedom\nSS: Sum of squares\nMS: Mean square = SS / df\nF: Ratio of explained to unexplained variability: \\(F\\)-statistic = \\(\\frac{\\text{MS}_{\\text{model}}}{\\text{MS}_{\\text{error}}}\\)\nP: \\(p\\)-value from the \\(F\\)-distribution\n\n\n\nNotes\n\nDegrees of freedom reflect how many means are being estimated.\nMean square values (MS) are variances: \\(\\text{MS} = \\frac{\\text{SS}}{\\text{df}}\\), which follows the general variance formula: \\(\\text{var}(x) = \\frac{\\sum (X_i - \\bar{X})^2}{n - 1}\\)\nThe top row of the table (Between / Extra) is how much variance is explained by using separate means.\nThe mean square error (MSE) estimates within-group variance: \\(\\text{MSE} = 4\\)\nThe root mean square error (RMSE) is:\\(\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{4} = 2\\)\nThis is also our estimate of the shared population standard deviation: \\(\\hat{\\sigma} = \\text{RMSE} = 2\\)\n\n\n\nUnderstanding Degrees of Freedom in ANOVA\n\nDegrees of freedom reflect how many parameters (means) are estimated and how much data is available to estimate variability.\nIn ANOVA, the total degrees of freedom are split into two parts:\n\n\n\n\n\n\n\n\n\nSource\nFormula\nInterpretation\n\n\n\n\nModel (Between Groups)\n\\(k - 1\\)\nNumber of group means (parameters) being estimated minus 1\n\n\nError (Within Groups)\n\\(n - k\\)\nLeftover variation after estimating \\(k\\) group means\n\n\nTotal\n\\(n - 1\\)\nTotal variation in the dataset\n\n\n\nFor example, with 3 groups and 9 total observations:\n\nModel df = \\(3 - 1 = 2\\)\nError df = \\(9 - 3 = 6\\)\nTotal df = \\(9 - 1 = 8\\)\n\n\n\nVisualizing the \\(F\\)-Test\nThe \\(F\\)-statistic is compared to an \\(F\\)-distribution with 2 and 6 degrees of freedom. (Every \\(F\\)-distribution has 2 degrees of freedom.)\n\n\\(F_{2,6} = 54.75\\)\nCritical value at \\(\\alpha = 0.05\\): \\(F_{2,6}^{*} \\approx 5.14\\)\nThe region to the right of 54.75 under the curve gives the \\(p\\)-value, which is very small (\\(p = 0.0001\\)), indicating strong evidence against the null model (EMM).\n\n\n\n\n\\(F\\)-distribution. Right-skewed \\(F_{2,6}\\) distribution showing critical value (5.14), observed test statistic (54.75), and rejection region representing \\(p\\)-value (0.0001).\n\n\n\n\nInterpretation\n\nThe top row of the ANOVA table shows how much variability is explained by the model.\nThe second row shows how much variability is left over (residual error).\nA high \\(F\\)-value means the SMM explains significantly more variability than the EMM.\nWe conclude that at least one group mean differs significantly from the others.\n\nSee the summary figure below for a visual breakdown of how these components are computed and interpreted.\n\n\n\nANOVA Table Breakdown. Visual summary of how degrees of freedom, sum of squares, mean squares, and the \\(F\\)-statistic are calculated and interpreted for the model, error, and total variation.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#anova-six-step-hypothesis-test",
    "href": "foundation-chapter06.html#anova-six-step-hypothesis-test",
    "title": "Comparisons Among Several Samples",
    "section": "ANOVA: Six-Step Hypothesis Test",
    "text": "ANOVA: Six-Step Hypothesis Test\n\nDefine Hypotheses:\n\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\dots\\) (equal means model)\n\\(H_a\\): At least one pair of means is different\nThe null model assumes all observations are drawn from a single population with the same mean (grand mean).\nThe alternative allows group-specific distributions with different means (separate means model).\nModels are compared using the sum of squared residuals: a good fitting model has smaller residuals (observed − predicted).\n\nGet Critical Value:\n\nFrom an \\(F\\)-distribution\nDegrees of freedom: \\(df_1\\) (model) and \\(df_2\\) (error)\nIn R, use qf(1 - alpha, df1, df2) to find the critical value. (Use \\(1-\\alpha\\) for a R-tailed test.)\n\nCalculate \\(F\\)-Statistic: \\[\nF = \\frac{\\text{MS}_{\\text{between}}}{\\text{MS}_{\\text{within}}}\n  = \\frac{\\text{Extra SS} / \\text{Extra df}}{\\text{MSE}}\n  = \\frac{\\text{Variation Explained}}{\\text{Variation Left to Explain}}\n\\] where:\n\n\\(\\text{MS}_{\\text{between}} = \\frac{\\text{Extra SS}}{\\text{Extra df}}\\)\n\\(\\text{MS}_{\\text{within}} = \\text{MSE} = \\frac{\\text{Error SS}}{\\text{Error df}}\\)\n\nDetermine p-value:\n\nCompare the test statistic to the \\(F\\) distribution.\nIf \\(F\\)-statistic is in the upper tail, \\(p\\) will be small.\n\nDecision:\n\nReject \\(H_0\\) if \\(p &lt; \\alpha\\).\n\nInterpretation:\n\nRejecting \\(H_0\\) because of a significant result suggests at least one group mean differs.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#key-metrics-in-anova",
    "href": "foundation-chapter06.html#key-metrics-in-anova",
    "title": "Comparisons Among Several Samples",
    "section": "Key Metrics in ANOVA",
    "text": "Key Metrics in ANOVA\n\n\\(R^2\\): Coefficient of Determination\n\n\\(R^2 = \\dfrac{\\text{Explained Variation}}{\\text{Total Variation}} = \\dfrac{\\text{Extra SS}}{\\text{Total SS}}\\)\nRepresents the proportion of total variance in the response that is explained by the model (i.e., group membership).\n\\(R\\): Pearson correlation coefficient between observed and predicted values\n\n\n\nRMSE: Root Mean Square Error\n\n\\(\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\text{Unexplained Variation}}\\)\nEstimates the typical distance between observed and predicted values (i.e., the standard deviation of residuals).\n\n\n\nCoefficient of Variation (CV)\n\nA unitless measure of relative variability (standard deviation relative to the mean): \\[\n\\text{CV} = \\frac{\\text{RMSE}}{\\text{Grand Mean}} \\times 100 = \\frac{\\text{RMSE}}{\\bar{X}} \\times 100 = \\frac{\\sqrt{\\text{MSE}}}{\\bar{X}} \\times 100\n\\]",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#sas-code-for-anova",
    "href": "foundation-chapter06.html#sas-code-for-anova",
    "title": "Comparisons Among Several Samples",
    "section": "SAS code for ANOVA",
    "text": "SAS code for ANOVA\n\n\nCode\n* Generalized Linear Model: Extends analysis to multiple groups (e.g., ANOVA for 3+ groups);\nproc glm data = dataSet;\n  class group;\n  model responseVar = groupingVar; * Fits an ANOVA;\nrun;\n\n\n\nSAS ANOVA Output Summary\nSAS provides the \\(R^2\\), root MSE, and coefficient of variation in its ANOVA output. See the example output below for how these metrics are reported.\nExample SAS Output: ANOVA Summary\n\n\n\n\n\n\n\n\n\n\n\nSource\nDF\nSum of Squares\nMean Square\nF Value\nPr &gt; F\n\n\n\n\nModel (Between / Extra)\n2\n438.0\n219.0\n54.75\n0.0001\n\n\nError (SMM)\n6\n24.0\n4.0\n\n\n\n\nCorrected Total (EMM)\n8\n462.0\n\n\n\n\n\n\n\n\n\nR-Square\nCoeff Var\nRoot MSE\nScore Mean\n\n\n\n\n0.948052\n15.38462\n2.0\n13.0\n\n\n\nCalculations:\n\n\\(R^2 = \\dfrac{\\text{Explained Variation}}{\\text{Total Variation}} = \\dfrac{\\text{Extra SS}}{\\text{Total SS}} = \\frac{438}{462} \\approx 0.948\\)\n\\(\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\text{Unexplained Variation}} = 2\\)\n\\(\\bar{X}\\): grand mean, the mean of all observations (\\(n\\) = 9 in the example above)\nThe Score Mean reported by SAS is the grand mean (\\(\\bar{X} = 13\\)), the average of all observations across all groups.\n\\(\\text{CV} = \\frac{\\text{RMSE}}{\\bar{X}} \\times 100 = \\frac{2}{13} \\times 100 \\approx 15.38\\%\\)\n\nInterpretation:\n\nExtra sum of squares: variability explained by the full model (SMM)\nTotal sum of squares: total variability (that could be explained)\nThe model (group membership) explains 94.8% of the total variability in the response (\\(R^2 = 0.948\\)).\nRMSE = 2 indicates the estimated standard deviation of residuals, the typical size of the model residuals.\nCV ≈ 15.38% indicates moderate relative variability around the grand mean. This matches the SAS output: Coeff Var = 15.38462.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#r-code-for-anova",
    "href": "foundation-chapter06.html#r-code-for-anova",
    "title": "Comparisons Among Several Samples",
    "section": "R code for ANOVA",
    "text": "R code for ANOVA\n\n\nCode\n# aov = analysis of variance\n# numerical response ~ factor groupings\nfit = aov(responseVar ~ groupingVar, data = dataSet)\nsummary(fit)",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#anova-assumptions-and-robustness",
    "href": "foundation-chapter06.html#anova-assumptions-and-robustness",
    "title": "Comparisons Among Several Samples",
    "section": "ANOVA Assumptions and Robustness",
    "text": "ANOVA Assumptions and Robustness\n\nAssumptions\n\nNormality\n\nCheck with histograms, boxplots, and Q–Q plots.\nANOVA is fairly robust to non-normality, especially when sample sizes are large and equal across groups.\n\nEqual Standard Deviations:\n\nThis assumption is crucial for the validity of ANOVA and \\(F\\)-test results.\nANOVA is less robust to violations of this assumption compared to \\(t\\)-tests.\nConfidence intervals depend on this assumption being met.\nConfidence intervals are widest when the group with the largest standard deviation also has the largest sample size.\n\nIndependence\n\nObservations must be independent both within and between groups.\nThis is generally satisfied through random sampling or random assignment.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#alternatives-to-standard-anova",
    "href": "foundation-chapter06.html#alternatives-to-standard-anova",
    "title": "Comparisons Among Several Samples",
    "section": "Alternatives to Standard ANOVA",
    "text": "Alternatives to Standard ANOVA\n\nWelch’s ANOVA\n\nA robust alternative to classical ANOVA when standard deviations are unequal.\nStill assumes normality.\nAdjusts the degrees of freedom lower to account for unequal variances.\nOutput includes adjusted \\(F\\)-statistic and p-value.\n\n\n\nKruskal–Wallis Test\n\nA non-parametric alternative to ANOVA that compares medians instead of means.\nUseful for non-normal or skewed distributions or small sample sizes.\nAssumptions:\n\nDoes not assume normality.\nRobust to unequal variances.\nObservations must be independent.\n\nThe p-value is based on a chi-square distribution.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#power-analysis-for-anova-sas",
    "href": "foundation-chapter06.html#power-analysis-for-anova-sas",
    "title": "Comparisons Among Several Samples",
    "section": "Power Analysis for ANOVA (SAS)",
    "text": "Power Analysis for ANOVA (SAS)\n\n\nCode\nproc power;\n  onewayanova test=overall;\n  groupmeans ... ;\nrun;",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#random-vs.-fixed-effects",
    "href": "foundation-chapter06.html#random-vs.-fixed-effects",
    "title": "Comparisons Among Several Samples",
    "section": "Random vs. Fixed Effects",
    "text": "Random vs. Fixed Effects\n\nFixed Effects\n\nLevels (e.g., groups or treatments) are explicitly of interest and not intended to generalize beyond the study or represent a larger population.\nInference applies only to the levels included in the analysis.\nCommon in controlled experiments with pre-defined groups or treatments.\nThe model estimates a unique mean for each level.\n\n\n\nRandom Effects\n\nLevels represent a random sample from a larger population of possible groups or conditions.\nThe goal is to make inferences about the entire population of levels—not just those observed in the study. That is, even if you cannot sample every possible level, the levels in the study are meant to be representative of the population of interest.\nThe model accounts for two sources of variation:\n\nResidual variance (within-group variability): variance of each observation from the overall mean\nRandom effect variance (between-group variability): variance associated with the random effects\n\nObservations are nested within groups drawn at random.\nThere is typically more error associated with random effects models.\n\n\n\nStatistical Considerations\n\nRandom effects models include additional variability from the group-level random component. This increases standard errors but yields more conservative and generalizable inferences.\nFixed effects models do not account for this extra group-level variability, which may lead to underestimated standard errors if used when random effects would be more appropriate.\nChoosing the wrong model type can increase the risk of Type I or Type II errors.\n\n\nIn short:\n\nUse fixed effects when your levels (e.g., treatments) are all of interest and exhaust the population you care about.\n\nUse random effects when your levels are sampled from a larger population and you want to generalize your conclusions.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter06.html#writing-up-results",
    "href": "foundation-chapter06.html#writing-up-results",
    "title": "Comparisons Among Several Samples",
    "section": "Writing Up Results",
    "text": "Writing Up Results\nANOVA tests whether the between-group variability is significantly larger than the within-group variability, providing evidence that group means differ.\n\nThe \\(F\\)-test indicates whether at least one group mean differs.\nIt does not identify which specific means are different or how they differ.\nAdditional procedures such as post-hoc tests are required to explore these questions of interest (QOIs).\n\n\nSteps for Writing Results\n\nState the research question, experimental conditions, and context clearly.\nDescribe the study design, including how data were collected, sample sizes, and treatments or groups.\nCheck and summarize assumptions:\n\nUse graphical tools (e.g., histograms, Q-Q plots, residual plots).\nNote whether normality, equal variance, and independence were reasonable.\n\nProvide descriptive statistics for each group.\nReport the ANOVA test results:\n\nInclude the \\(F\\)-statistic, degrees of freedom, \\(p\\)-value, and relevant effect sizes (e.g., \\(R^2\\), RMSE, CV).\n\nInclude residual diagnostics:\n\nMention if any transformations were applied.\nNote any violations and how they were addressed (e.g., using Welch’s ANOVA).\n\nInterpret the results in context:\n\nDiscuss whether the null hypothesis was rejected.\nRelate the findings to the original research question.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Comparisons Among Several Samples</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html",
    "href": "foundation-chapter07.html",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html#objectives",
    "href": "foundation-chapter07.html#objectives",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "",
    "text": "Recognize the limitations of the alternative hypothesis in an ANOVA F-test.\n\nConstruct and interpret linear combinations of group means.\n\nUnderstand the need for multiple comparison procedures and when to apply them.\n\nApply methods such as Bonferroni and Dunnett to test planned and unplanned comparisons.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html#fallacies-in-hypothesis-testing",
    "href": "foundation-chapter07.html#fallacies-in-hypothesis-testing",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "Fallacies in Hypothesis Testing",
    "text": "Fallacies in Hypothesis Testing\n\nFalse causality: A small p-value does not indicate causation. Causality can only be inferred from randomized experiments, not observational studies.\nAccepting the null: We should say there is “no evidence of a difference,” not that the null hypothesis is true. There is not enough evidence to suggest the observed difference is due to anything other than chance.\nStatistical vs. practical significance: Statistical significance does not imply practical importance. Evaluate practical significance using power, effect size, and confidence intervals.\n\nDifferences that are statistically but not practically significant may arise due to large sample sizes.\n\nIf a difference is practically significant but not statistically significant, more data may be needed.\n\nData dredging: Avoid fishing for significance (data snooping). This can lead to publication bias against negative results.\nGood statistics from bad data: Biased or non-random data compromise conclusions. Experimental design determines which inferences and statistical methods are valid.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html#linear-combination-of-group-means",
    "href": "foundation-chapter07.html#linear-combination-of-group-means",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "Linear Combination of Group Means",
    "text": "Linear Combination of Group Means\n\nANOVA allows only pairwise comparisons of means and does not account for meaningful structure across groups. In practice, you may wish to compare the average of several means to a single group, or to the average of others.\n\nThe ANOVA F-test serves as an initial screening tool for detecting any overall differences in means. If the F-test is significant, follow-up tests can be considered.\n\n\nLinear Contrasts\n\nA linear combination of group means is defined as: \\[\n\\gamma = C_1\\mu_1 + C_2\\mu_2 + \\dots + C_I\\mu_I\n\\] where \\(\\gamma\\) represents the linear combination and the \\(C_i\\) are coefficients. When the coefficients sum to zero, the combination is called a contrast.\nEstimate \\(\\gamma\\) using \\(g = C_1\\bar{x}_1 + C_2\\bar{x}_2 + \\dots + C_I\\bar{x}_I\\), where \\(\\bar{x}_i\\) are group sample means.\nThe standard error of \\(g\\), denoted \\(SE(g)\\), is given by: \\[\nSE(g) = S_p \\sqrt{\\frac{C_1^2}{n_1} + \\frac{C_2^2}{n_2} + \\dots + \\frac{C_I^2}{n_I}}\n\\] where \\(S_p\\) is the pooled standard deviation.\nEven when comparing only two groups (i.e., the other coefficients and terms under the square root are zero), the pooled standard deviation is used under the assumption of equal variances across all groups.\nThe t-statistic for testing contrasts is: \\[\nt_{\\alpha, df} = \\frac{g - \\gamma}{SE(g)}\n\\] where \\(g\\) is the observed linear combination, \\(\\gamma\\) is the hypothesized value (e.g., \\(\\gamma = 0\\)), and \\(df\\) is the degrees of freedom associated with \\(S_p\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html#steps-for-a-linear-contrast-test",
    "href": "foundation-chapter07.html#steps-for-a-linear-contrast-test",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "Steps for a Linear Contrast Test",
    "text": "Steps for a Linear Contrast Test\n\nSummarize the data: Obtain group means, sample sizes, and the pooled standard deviation from the ANOVA model (e.g., RMSE).\nSpecify the coefficients: Choose \\(C_i\\) values such that \\(\\sum C_i = 0\\).\nEstimate the contrast: Compute the linear combination \\(g\\) using the sample means and chosen coefficients.\nCompute the standard error: Calculate \\(SE(g)\\) using the formula above.\nConstruct confidence intervals: \\[\nCI = g \\pm t_{\\alpha, df} \\cdot SE(g)\n\\]\nPerform the test: Calculate the t-statistic to assess the contrast.\n\n\nSimultaneous Inferences\n\nWhen testing multiple contrasts or pairwise comparisons, the risk of a Type I error increases. Adjustments to significance levels or p-values are needed to maintain the overall error rate.\nDistinguish between:\n\nIndividual confidence level: The probability that a single interval captures its parameter (\\(1 - \\alpha\\)).\nFamilywise confidence level: The probability that all intervals simultaneously capture their parameters. This probability is less than \\(1 - \\alpha\\) unless corrections are applied.\n\n\n\n\nCommon Applications of Linear Contrasts\n\nComparing average values, e.g., the mean of groups 1 and 2 versus group 3.\nComparing response rates across treatments, such as dietary interventions in animals.\nTesting specific hypotheses about structured combinations of group means.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html#adjusting-for-multiple-comparisons",
    "href": "foundation-chapter07.html#adjusting-for-multiple-comparisons",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "Adjusting for Multiple Comparisons",
    "text": "Adjusting for Multiple Comparisons\nWhen conducting multiple tests, it is important to control the familywise error rate (FWER). Common post-hoc procedures are outlined below.\n\nProcedures for All Pairwise Differences in Means\n\nBonferroni adjustment\n\nAdjusts the significance level: \\[\n\\text{Adjusted } \\alpha = \\frac{\\alpha}{\\# \\text{ comparisons}}\n\\]\nExample: For 4 groups, there are \\(\\binom{4}{2} = 6\\) pairwise comparisons (i.e., 4 choose 2): \\[\n\\alpha' = \\frac{0.05}{6} = 0.0083\n\\]\nStrengths: Simple, widely applicable\n\nWeaknesses: Very conservative; reduces power\n\nTukey’s Honestly Significant Difference (HSD)\n\nUsed to construct simultaneous confidence intervals for all pairwise mean differences\n\nBased on the studentized range statistic: \\[\nq = \\frac{\\bar{X}_{\\text{largest}} - \\bar{X}_{\\text{smallest}}}{\\sqrt{\\frac{MSE}{n}}}\n\\] (for groups with equal \\(n\\))\n\nConfidence intervals: \\[\n(\\bar{X}_i - \\bar{X}_j) \\pm q_{\\alpha, (k, N-k)} \\cdot \\sqrt{\\frac{MSE}{n}}\n\\]\n\nWhen group sizes are unequal, use the harmonic mean of \\(n_i\\) and \\(n_j\\) (as done in SAS): \\[\nn_{ij} = \\frac{2 \\cdot n_i \\cdot n_j}{n_i + n_j}\n\\]\n\nStrengths: Maintains FWER; easy to interpret\n\nWeaknesses: Assumes equal variances (can be extended via Tukey-Kramer)\n\nRyan-Elliot-Gabriel-Welsch Q (REGWQ) procedure\n\nRecommended by SAS; balances power and Type I error control\n\nMethod:\n\nOrder the group means in descending order\nReject \\(H_0\\) if: \\[\n\\text{Difference} &gt; q_{\\text{critical}} \\cdot \\text{Studentized range}\n\\]\nAdjust the p-values for the number of comparisons\n\n\nStrengths: High power; nominal Type I error\n\nWeaknesses: Algorithmically complex\n\n\n\n\nProcedures for Pairwise Differences vs. Control\n\nDunnett’s procedure\n\nCompares each treatment group to a single control group\nUses the \\(D\\)-statistic: \\[\nD = d_{(k-1, N-k)} \\cdot \\sqrt{\\frac{2 \\cdot MSE}{n_{\\text{harmonic}}}}\n\\]\nDegrees of freedom: \\[\ndf = (k - 1, N - k)\n\\] where \\(k - 1\\) is the between-groups degrees of freedom and \\(N - k\\) is the within-groups degrees of freedom\nStrengths: Targets control comparisons directly\n\nWeaknesses: Not designed for all pairwise tests and limited to control-versus-treatment tests\n\n\n\n\nProcedures for All Possible Comparisons\n\nScheffé’s method\n\nAllows for testing any linear combination of means\nUsed for all possible comparisons, including non-pairwise contrasts\nBased on the F-distribution\n\nStrengths: Flexible, ideal for complex non-pairwise hypotheses, and less conservative than Bonferroni\nWeaknesses: Less powerful for simple pairwise tests",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html#key-considerations-for-post-hoc-comparisons",
    "href": "foundation-chapter07.html#key-considerations-for-post-hoc-comparisons",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "Key Considerations for Post-Hoc Comparisons",
    "text": "Key Considerations for Post-Hoc Comparisons\n\nType I Error Control\n\nMultiple tests increase the chance of a false positive (Type I error).\n\nEven if all null hypotheses are true, testing too many comparisons increases the likelihood of finding a “significant” result by chance.\n\nPost-hoc adjustments help control the overall Type I error rate.\n\nPlanned vs. unplanned comparisons\n\nUse planned comparisons when testing specific hypotheses defined in advance.\n\nUse unplanned post-hoc comparisons when no prior hypotheses were made, but the ANOVA is significant.\n\nDecision framework after ANOVA\n\nIf the F-statistic is not significant, no further testing is needed. There is no evidence that group means differ.\nIf the F-statistic is significant, then post-hoc comparisons are appropriate. The choice of follow-up method depends on:\n\nWhether there is meaningful structure in the groups (e.g., contrasts like “average of groups A and B vs. group C”).\nWhether pairwise comparisons or structured contrasts best address your research question.\n\n\n\n\nSummary Table of Post-Hoc Methods\n\n\n\n\n\n\n\n\n\nProcedure\nPurpose\nStrengths\nWeaknesses\n\n\n\n\nBonferroni Adjustment\nControls Type I error for pairwise tests\nSimple, widely applicable\nVery conservative, reduced power\n\n\nTukey’s HSD\nAll pairwise differences\nMaintains familywise error rate, easy interpretation\nAssumes equal variances\n\n\nDunnett’s Procedure\nCompare to control group\nFocused on control vs. treatments\nNot suitable for all pairwise comparisons\n\n\nREGWQ Procedure\nPairwise differences\nGood power, recommended by SAS\nRequires algorithmic implementation\n\n\nScheffé’s Method\nAll possible comparisons (non-pairwise)\nFlexible, good for complex comparisons\nLess powerful for pairwise differences",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html#reporting-results",
    "href": "foundation-chapter07.html#reporting-results",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "Reporting Results",
    "text": "Reporting Results\n\nDiscuss the research question, design, and assumptions.\nSummarize the exploratory data analysis (EDA).\nReport ANOVA results: F-statistic, degrees of freedom, and p-value.\nDescribe the effect size and post-hoc analysis used.\nConclude in the context of the original research question.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter07.html#linear-combination-of-group-means-1",
    "href": "foundation-chapter07.html#linear-combination-of-group-means-1",
    "title": "Linear Combinations and the Multiple Comparison Problem",
    "section": "Linear Combination of Group Means",
    "text": "Linear Combination of Group Means\n\nHandicap & Capability Study: ANOVA and Follow-Up Contrast\n\nGlobal Question of Interest\nGoal:\nHow do physical handicaps affect perception of employment qualification?\nAssumptions:\n- Independent observations\n- Normal distributions\n- Equal variances\nThere is no visual evidence to suggest these assumptions are violated.\nANOVA Setup:\nLet\n\n\\(H_0\\): \\(\\mu_1 = \\mu_2 = \\mu_3 = \\mu_4 = \\mu_5\\) (equal means model)\n\n\\(H_a\\): At least one \\(\\mu_i \\ne \\mu_j\\) for some \\(i \\ne j\\)\n\nResults:\n\nF-statistic: \\(F_{4,65} = 2.85\\)\n\np-value: 0.0301\n\nDecision: Reject \\(H_0\\)\n\nConclusion:\nThere is sufficient evidence to suggest that at least two group means differ (p = 0.0301 from a one-way ANOVA).\n\n\n\nTargeted Contrast: Comparing Two Group Averages\nWe now test whether the average score of the Amputee and Hearing groups differs from that of the Crutch and Wheelchair groups.\n\nHypotheses\n\\[\nH_0: \\frac{\\mu_{\\text{Amp}} + \\mu_{\\text{Hear}}}{2} = \\frac{\\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}}{2}\n\\] \\[\nH_A: \\frac{\\mu_{\\text{Amp}} + \\mu_{\\text{Hear}}}{2} \\ne \\frac{\\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}}{2}\n\\]\nRewritten by subtraction: \\[\nH_0: \\frac{\\mu_{\\text{Amp}} + \\mu_{\\text{Hear}}}{2} - \\frac{\\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}}{2} = 0\n\\] \\[\nH_A: \\frac{\\mu_{\\text{Amp}} + \\mu_{\\text{Hear}}}{2} - \\frac{\\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}}{2} \\ne 0\n\\]\nMultiply both sides by 2: \\[\nH_0: \\mu_{\\text{Amp}} + \\mu_{\\text{Hear}} - \\mu_{\\text{Crutch}} - \\mu_{\\text{Wheel}} = 0\n\\] \\[\nH_A: \\mu_{\\text{Amp}} + \\mu_{\\text{Hear}} - \\mu_{\\text{Crutch}} - \\mu_{\\text{Wheel}} \\ne 0\n\\]\n\n\nDefining the Contrast\nThis contrast compares the average of the Amputee and Hearing groups to the average of the Crutch and Wheelchair groups, excluding the None group. The coefficients (weights) are assigned based on the groupings of interest. The group labels are listed alphabetically, which is the default in most statistical software.\n\\[\n\\gamma = 1\\mu_{\\text{Amp}} - 1\\mu_{\\text{Crutch}} + 1\\mu_{\\text{Hear}} + 0\\mu_{\\text{None}} - 1\\mu_{\\text{Wheel}}\n\\]\nHere, \\(\\gamma\\) represents the population value of the contrast—a linear combination of group means. A value of \\(\\gamma = 0\\) would indicate no difference between the two averaged group sets.\n\n\nMethod: Linear Contrast Formulas and Test Statistic\nTo evaluate this question, we use a linear contrast to compare combined group means.\n\nHypotheses: \\[\nH_0: \\gamma = 0 \\quad \\text{vs.} \\quad H_A: \\gamma \\ne 0\n\\]\nGeneral definition of a contrast: \\[\n\\gamma = C_1\\mu_1 + C_2\\mu_2 + \\dots + C_I\\mu_I\n\\] where \\(C_i\\) are the contrast weights and must satisfy the constraint:\n\\[\n\\sum C_i = 0\n\\]\nContrast estimate: \\[\ng = C_1\\bar{x}_1 + C_2\\bar{x}_2 + \\dots + C_I\\bar{x}_I\n\\] where \\(C_i\\) are the contrast weights and \\(\\bar{x}_i\\) are the sample means.\nStandard error: \\[\nSE(g) = S_p \\sqrt{ \\frac{C_1^2}{n_1} + \\frac{C_2^2}{n_2} + \\dots + \\frac{C_I^2}{n_I} }\n\\] where \\(S_p = \\sqrt{MSE}\\) is the pooled standard deviation (assuming equal variances and independent observations).\nTest statistic: \\[\nt = \\frac{g - \\gamma}{SE(g)}\n\\] This follows a t-distribution with degrees of freedom: \\[\ndf = N - I\n\\] where \\(N\\) is the total number of observations and \\(I\\) is the number of groups.\n\n\n\n\nWorked Example: Difference of Sums\n\nHypotheses: \\[\nH_0: \\frac{\\mu_{\\text{Amp}} + \\mu_{\\text{Hear}}}{2} = \\frac{\\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}}{2}\n\\] \\[\nH_A: \\frac{\\mu_{\\text{Amp}} + \\mu_{\\text{Hear}}}{2} \\ne \\frac{\\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}}{2}\n\\]\nContrast coefficients: \\[\n\\gamma = 1\\mu_{\\text{Amp}} - 1\\mu_{\\text{Crutch}} + 1\\mu_{\\text{Hear}} + 0\\mu_{\\text{None}} - 1\\mu_{\\text{Wheel}}\n\\]\nEstimate \\(\\gamma\\) with \\(g\\) using group means: \\[\ng = 1\\bar{x}_{\\text{Amp}} - 1\\bar{x}_{\\text{Crutch}} + 1\\bar{x}_{\\text{Hear}} + 0\\bar{x}_{\\text{None}} - 1\\bar{x}_{\\text{Wheel}}\n\\] \\[\ng = (1)(4.43) + (-1)(5.92) + (1)(4.05) + (0)(4.9) + (-1)(5.34) = -2.78\n\\]\n\nThe estimated contrast represents the estimated difference between the sum of the populations means of the Amputee and Hearing groups and the sum of the populations means of of the Crutch and Wheelchair groups.\n\nStandard error: \\[\nSE(g) = \\sqrt{2.6666 \\left( \\frac{1^2}{14} + \\frac{(-1)^2}{14} + \\frac{1^2}{14} + \\frac{0^2}{14} + \\frac{(-1)^2}{14} \\right)} = 0.8729\n\\] where \\(S_p = \\sqrt{MSE} = \\sqrt{2.6666}\\)\n\n\nConfidence Interval (95%) for the Difference of Sums\n\nFormula: \\[\ng \\pm t_{df, 0.975} \\cdot SE(g)\n\\]\nDegrees of freedom: \\[\ndf = 70 - 5 = 65 \\quad \\Rightarrow \\quad t_{65, 0.975} = 1.991\n\\]\nCalculation: \\[\n-2.78 \\pm (1.991)(0.8729)\n\\]\nInterval for the difference of sums: \\[\nCI = (-4.518, -1.042)\n\\]\nInterval for the difference of means (averaging over 2 vs. 2 groups): \\[\nCI = \\left( \\frac{-4.518}{2}, \\frac{-1.042}{2} \\right) = (-2.259, -0.521)\n\\]\n\nThere is sufficient evidence that the sum of points assigned to the Amputee and Hearing groups is smaller (\\(g = -2.8\\)) than the sum of points assigned to the Crutch and Wheelchair groups at the \\(\\alpha = 0.05\\) confidence level, because the confidence interval does not contain 0.\n\n\nSummary of Findings\n\nThe initial ANOVA showed a statistically significant difference across all five groups (p = 0.0301).\nA targeted contrast comparing the average of the Amputee and Hearing groups to that of the Crutch and Wheelchair groups yielded:\n\nContrast estimate: \\(g = -2.78\\)\n95% CI for difference of means: \\((-2.26, -0.52)\\)\n\\(t(65) = -2.78\\), p &lt; 0.01\n\n\nWe conclude that the Amputee and Hearing groups were rated significantly lower, on average, than the Crutch and Wheelchair groups. )\n\n\n\nHypothesis Test—Sums\n\nHypotheses: \\[\nH_0: \\mu_{\\text{Amp}} + \\mu_{\\text{Hear}} = \\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}\n\\] \\[\nH_A: \\mu_{\\text{Amp}} + \\mu_{\\text{Hear}} \\ne \\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}\n\\]\nCritical value: \\[\nt_{65}(0.975) = 1.9971\n\\]\nt-statistic: \\[\nSE(g) = 0.8729 \\Rightarrow t_{\\text{stat}} = \\frac{-2.78}{0.8729} = -3.19\n\\]\np-value: \\(p = 0.0022\\)\nDecision: Reject \\(H_0\\)\nConclusion:\nThere is strong evidence to suggest that the sum of the means of the Amputee and Hearing groups is less than that of the Crutch and Wheelchair groups (p-value = 0.0022). The 95% confidence interval for the difference of sums is \\((-4.529, -1.043)\\) points.\n\n\n\nHypothesis Test—Means (Not Sums)\n\nHypotheses: \\[\nH_0: \\frac{\\mu_{\\text{Amp}} + \\mu_{\\text{Hear}}}{2} = \\frac{\\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}}{2}\n\\] \\[\nH_A: \\frac{\\mu_{\\text{Amp}} + \\mu_{\\text{Hear}}}{2} \\ne \\frac{\\mu_{\\text{Crutch}} + \\mu_{\\text{Wheel}}}{2}\n\\]\nCritical value: \\[\nt_{65}(0.975) = 1.9971\n\\]\nStandard error: \\[\nSE(g) = \\sqrt{2.6666 \\left( \\frac{(0.5)^2}{14} + \\frac{(-0.5)^2}{14} + \\frac{(0.5)^2}{14} + \\frac{0^2}{14} + \\frac{(-0.5)^2}{14} \\right)} = \\sqrt{0.1905} = 0.4364\n\\] Test statistic: \\[\ng = -1.393 \\quad \\Rightarrow \\quad t = \\frac{g - \\gamma}{SE(g)} = \\frac{g - 0}{SE(g)} = \\frac{-1.393}{0.4364} = -3.19\n\\] Same \\(t\\)-statistic as for sums, but different \\(g\\) because the 0.5 vs. 1 and different SE.\np-value: \\(p = 0.0022\\)\nDecision: Reject \\(H_0\\)\nConclusion:\nThere is strong evidence to suggest that the average of the means of the Amputee and Hearing groups is less than that of the Crutch and Wheelchair groups (p-value = 0.0022). The 95% confidence interval for the difference in means is (-2.26, -0.52) points.\n\n\nNote: This is based on means, not sums.\n\n\nFinal Conclusion (Client-Facing—Difference in Group Means)\nThere is strong evidence to suggest that the average of the means of the Amputee and Hearing groups is less than the average of the means of the Crutches and Wheelchair groups (p-value = 0.0022).\nWe are 95% confident that the average of the mean scores of the Crutches and Wheelchair groups is between 0.5215 and 2.2605 points greater than the average of the mean points of the Amputee and Hearing groups.\n\n\n\nWhy We Do a Multiple Comparison Correction — The Bonferroni\n\nMotivation\nWhen conducting multiple hypothesis tests, the probability of making at least one Type I error (a false positive, rejecting \\(H_0\\) when \\(H_0\\) is true) increases. Bonferroni correction helps control this overall risk by adjusting the significance level for individual tests.\n\n\n\nProbability Review: Two Coin Flips\n\nProp 1: Independence of Events\n\\[\nP(AB) = P(A) \\cdot P(B)\n\\]\nExample: \\[\nP(\\text{HH}) = P(\\text{H}) \\cdot P(\\text{H}) = 0.5 \\cdot 0.5 = 0.25\n\\]\n\n\nProp 2: Sample Space of Two Fair Coin Flips\n\n\n\nOutcome\nProbability\n\n\n\n\nHH\n0.25\n\n\nHT\n0.25\n\n\nTH\n0.25\n\n\nTT\n0.25\n\n\n\nProbability of at least one head:\n\\[\nP(\\text{at least 1 H}) = 1 - P(\\text{no heads}) = 1 - P(\\text{TT}) = 1 - 0.25 = 0.75\n\\]\n\n\n\nMultiple Testing Analogy: Coin Flips\nThis parallels the logic behind multiple testing:\n\nGetting two tails = no Type I error\nGetting at least one head = at least one Type I error\n\nJust like the probability of getting at least one head increases with more coin flips, the probability of making at least one Type I error increases with more hypothesis tests — unless we adjust for it.\nThis illustrates how running multiple independent tests increases the probability of rejecting at least one true null—even if all nulls are actually true. That’s why corrections like the Bonferroni adjustment are necessary.\n\n\nFamilywise Error Rate With Multiple Tests\nLet \\(K = 2\\) (number of independent hypothesis tests), and assume the null hypothesis is true in both.\n\nTIE = Type I error\n\nFTR = Fail to reject \\(H_0\\)\n\n\nProbability of at Least One Type I Error Without Correction\n\\[\nP(\\text{at least 1 TIE in 2 tests}) = 1 - P(\\text{no TIE in 2 tests}) = 1-P(\\text{FTR in 2 tests})\n\\]\nAssuming each test has \\(\\alpha = 0.05\\):\n\\[\n= 1 - P(\\text{FTR})P(\\text{FTR}) = 1 - P(\\text{FTR})^2 = 1 - (1 - \\alpha)^2 = 1 - (0.95)^2 = 0.0975\n\\]\n\nThis means there’s a 9.75% chance of incorrectly rejecting at least one null hypothesis when both are actually true.\n\n\n\n\nBonferroni Adjustment\nTo maintain a familywise error rate of \\(\\alpha = 0.05\\), Bonferroni sets a more stringent per-test threshold:\n\\[\n\\alpha' = \\frac{\\alpha}{K} = \\frac{0.05}{2} = 0.025\n\\] where:\n\n\\(\\alpha\\) is the desired familywise error rate (e.g., 0.05).\n\\(k\\) is the number of comparisons.\n\\(\\alpha'\\) is the adjusted threshold for each test, the per-comparison significance level.\n\nThen the familywise error becomes:\n\\[\nP(\\text{at least 1 TIE in 2 tests}) = 1 - P(\\text{no TIE in 2 tests}) = 1 - P(\\text{FTR})^2 = 1 - (1 - \\alpha')^2 = 1 - (0.975)^2 = 0.0494\n\\]\nSo Bonferroni successfully lowers the overall chance of making a Type I error across all tests back to the desired 0.05 level.\n\n\nInterpreting the Diagram\n\n\n\nBell curve showing original \\(\\alpha\\) and Bonferroni-corrected rejection regions. The Bonferroni-adjusted regions lie farther from 0, reflecting the more stringent critical values.\n\n\nThe shaded areas represent rejection regions under two scenarios:\n\nOuter shaded tails: Original \\(\\alpha = 0.05\\) rejection regions (2.5% in each tail)\nInner shaded tails: Bonferroni-adjusted \\(\\alpha' = 0.025\\) rejection regions (1.25% in each tail)\n\nThe critical value for Bonferroni (CVB) is the \\(t\\)- or \\(z\\)-value that corresponds to \\(\\alpha'\\), which lies further from 0 than the uncorrected critical value. This makes it harder to reject \\(H_0\\).\n\n\nKey Concepts Illustrated\n\nWithout correction: \\[\nP(\\text{at least one TIE}) = 1 - (1 - \\alpha)^K = 1 - (0.95)^2 = 0.0975\n\\]\nWith Bonferroni correction: \\[\n\\alpha' = \\frac{0.05}{2} = 0.025 \\quad \\Rightarrow \\quad P(\\text{at least one TIE}) = 1 - (0.975)^2 = 0.0494\n\\]\nCVB (critical value for Bonferroni) moves farther from 0, tightening the rejection region.\nBonferroni maintains a familywise error rate at or below 0.05.\n\n\n\nSummary\n\nWhen we conduct multiple comparisons, the overall Type I error rate is inflated.\nThe Bonferroni correction addresses this by adjusting the per-comparison significance level: \\[\n\\alpha' = \\frac{\\alpha}{K}\n\\]\nPros:\n\nSimple and widely applicable\nWorks for any number of tests\nMakes no assumptions about the test structure\nCan be applied directly to p-values\n\nCons:\n\nCan be overly conservative\nReduces power, making it harder to reject \\(H_0\\)\n\n\n\n\nMultiple Comparison Procedures — Handicap Study\nWe now explore multiple comparison questions using the Handicap study data. These comparisons build on the need for error rate control, such as the Bonferroni adjustment, after identifying overall group differences.\n\nQuestions of Interest (QOIs)\n\nAre any pairs of group means different?\n\nDoes the Amputee group have a different mean score than the None group?\n\nWhich specific pairs of groups differ?\n\nDo the means of the four Handicap groups differ from the Non-Handicap (None) group?\n\nEach of these questions involves multiple comparisons and may require adjustment for familywise error rates.\n\n\nQOI 1: Are Any Group Means Different?\nWe begin with an overall test to determine if there are any mean differences across the five groups. This involves an ANOVA and is the first step in any further group comparisons.\n\nAssumptions:\n\nNormality\n\nEqual variances (e.g., visual checks and Brown–Forsythe test)\n\nIndependence (assumed from study design)\n\n\n\nHypotheses: \\[\nH_0: \\mu_1 = \\mu_2 = \\dots = \\mu_5 \\quad \\text{(All group means are equal)}\n\\] \\[\nH_A: \\text{At least two group means differ}\n\\]\nCritical value: \\(F_{\\alpha, 4, 65}\\)\nANOVA test statistic (\\(F\\)-statistic): \\(F = 2.85\\)\np-value: \\(p = 0.0301\\)\nDecision: Reject \\(H_0\\) (needle in the haystack)\nConclusion: There is sufficient evidence at \\(\\alpha = 0.05\\) to conclude that at least two group means differ (\\(p = 0.0301\\), from a standard ANOVA).\n\n\nSince the omnibus ANOVA test is significant, we proceed to investigate which group differences are driving the result. Multiple comparison procedures will be necessary to identify specific contrasts.\n\nModel fitting R code (for context):\n\n\nCode\nfit &lt;- aov(Score ~ Handicap, data = Handicap)\n\n\n\n\nQOI 2: Does the Amputee Group Differ from the None Group?\nWe now test whether the mean score for the Amputee group differs from that of the None group.\n\nThis contrast was identified before looking at the data (i.e., a planned comparison), so we do not need to apply a multiple comparison correction.\n\nHypotheses:\n\\[\nH_0: \\mu_{\\text{Amp}} = \\mu_{\\text{None}}\n\\] \\[\nH_A: \\mu_{\\text{Amp}} \\ne \\mu_{\\text{None}}\n\\]\nOptions for Testing the Contrast:\nWe could use one of the following approaches:\n\nTwo-sample \\(t\\)-test (just Amputee vs. None):\n\nPooled standard deviation\n\nDegrees of freedom: \\(df = 26\\)\n\n\\(t\\)-distribution\n\\(p\\)-value: 0.4678\n\nFit a GLM model using only Amputee and None:\n\nEquivalent \\(F\\)-statistic\n\nSame result as above: \\(df = 1\\), \\(26\\)\n\n\\(F\\)-distribution\n\\(p\\)-value: 0.4678\n\nBest option: Use all 70 observations:\n\nUse the pooled standard deviation from the full model\n\nConduct the planned contrast within the global ANOVA model\nCritical value: $F_{, 4, 65}\n\\(F\\)-statistic with extended degrees of freedom: \\(df = 65\\)\n\n\\(p\\)-value: 0.4477\n\n\nConclusion:\n\nDecision: Fail to reject \\(H_0\\)\nInterpretation: There is not sufficient evidence to suggest that the mean rating of the Amputee group is different from the None group (p = 0.4477 from a contrast using all the data).\n\n\n\nQOI 3: Which Specific Pairs of Groups Differ?\nWe now explore whether there is evidence that any specific pair of group means differ. These are not planned comparisons, so we must adjust for the increased chance of Type I error due to multiple testing.\n\nThere are 5 groups, which gives \\(K = \\binom{5}{2} = 10\\) pairwise comparisons.\nWithout correction, the risk of at least one false positive (rejecting \\(H_0\\) when it is true) increases.\nThe Bonferroni correction provides a simple solution by adjusting the significance threshold.\n\nUnadjusted Procedure\nCompare each group pair using pairwise comparisons without correction:\n\n\nCode\nproc glm data=Handicap;\n  class Handicap;\n  model Score = Handicap;\n  means Handicap / hovtest=bf;\n  ls means Handicap / pdiff;\nrun;\n\n\n\nCompare each pair’s raw p-value to \\(\\alpha = 0.05\\)\nInflated Type I error risk due to multiple tests\n\nBonferroni Adjustment and Procedure:\nTo control the familywise error rate, adjust \\(\\alpha\\) using the Bonferroni correction:\n\nAdjusted threshold: \\(\\alpha' = \\frac{\\alpha}{K} = \\frac{0.05}{10} = 0.005\\)\nUse Bonferroni-adjusted confidence intervals and p-values to control the error rate across the family of comparisons.\n\nThe Bonferroni-adjusted analysis in SAS uses the adjust=bon option:\n\n\nCode\nproc glm data=Handicap;\n  class Handicap;\n  model Score = Handicap;\n  means Handicap / hovtest=bf;\n  ls means Handicap / pdiff adjust=bon cl; *cl = confidence level;\nrun;\n\n\n\nThe cl option provides Bonferroni-adjusted confidence intervals.\nThese intervals are wider because:\n\n\\(\\alpha\\)’ is smaller than \\(\\alpha\\).\nThe critical value is larger.\nThe multiplier increases.\nWider intervals result from a more conservative correction.\n\nThe cldiff option gives both directions (e.g., \\(A - B\\) and \\(B - A\\)).\nEach p-value is multiplied by \\(K\\) before comparison to the original \\(\\alpha\\): \\[\nK \\cdot p_{\\text{adj}} \\leq \\alpha\n\\]\n\nInterpretation:\n\nThis procedure protects against Type I error across the entire family of tests.\nIt is conservative but appropriate when many unplanned comparisons are being made.\n\nConclusion:\nAfter applying the Bonferroni adjustment,only 1 of the 10 tests produced a statistically significant result. Therefore, there is evidence (p-value = 0.0035 from a t-test) that the Crutches and Hearing groups have different mean ratings. A 95% Bonferroni-adjusted confidence interval for the difference in means between the Crutches and Hearing groups is \\((0.0779,\\ 3.6649)\\).\n\n\nQOI 4: Do the Means of the Four Handicap Groups Differ from the Non-Handicap (None) Group?\nAssume we are interested in testing whether the means of the four handicap groups differ from the mean of the non-handicap group (i.e., the None group).\n\nUse Dunnett’s procedure because we are comparing the control group (None) to all the others — a pairwise set of dependent comparisons (repeating the control group).\n\nOption 1: Dunnett-adjusted confidence intervals\n\nSpecify the control group on the right side using dunnett('None')\nAlso provides Dunnett-corrected confidence intervals\n\n\n\nCode\nproc glm data=Handicap;\n  class Handicap;\n  model Score = Handicap;\n  means Handicap / hovtest=bf dunnett('None');\nrun;\n\n\nOption 2: Dunnett-adjusted p-values only\n\nUse control('None') to specify the control group\nProvides Dunnett-adjusted p-values for all pairwise comparisons with the None group\n\n\n\nCode\nproc glm data=Handicap;\n  class Handicap;\n  model Score = Handicap;\n  ls means Handicap / pdiff=control('None');\nrun;",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Combinations and the Multiple Comparison Problem</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html",
    "href": "foundation-chapter08.html",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#objectives",
    "href": "foundation-chapter08.html#objectives",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "",
    "text": "Understand how to calculate and interpret Pearson’s \\(r\\).\nRecognize the relationship between Pearson’s \\(r\\) and scatterplots.\nIdentify how patterns in data affect the magnitude and sign of Pearson’s \\(r\\).\nDiscuss when correlation equals causation and when it does not.\nExplain the basics of simple linear regression.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#helpful-resources",
    "href": "foundation-chapter08.html#helpful-resources",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Helpful Resources",
    "text": "Helpful Resources\n\nInteractive Correlation Visualization\nRegression Shuffle Applet",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#scatterplots",
    "href": "foundation-chapter08.html#scatterplots",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Scatterplots",
    "text": "Scatterplots\nScatterplots visually represent the relationship between two quantitative variables, illustrating how they vary together. Key points:\n\nThe explanatory variable (\\(X\\)) is plotted on the X-axis, while the response variable (\\(Y\\)) is on the Y-axis.\nEach dot represents an observation.\nPatterns to look for include:\n\nPositive or negative linear relationships\nCurved patterns (e.g., parabolic)\nLogarithmic or sinusoidal relationships\nRandom scatter (no clear relationship)",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#interpreting-correlations",
    "href": "foundation-chapter08.html#interpreting-correlations",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Interpreting Correlations",
    "text": "Interpreting Correlations\n\nSquare of Correlation Coefficient (\\(r^2\\))\n\nRepresents shared variance\nExample: \\(r = 0.8\\) implies \\(r^2 = 0.64\\), meaning 64% of variability in \\(Y\\) is explained by its linear relationship with \\(X\\)\n\n\n\nSignificance\n\nWhen \\(r = 1\\), there is a perfect positive linear relationship.\nWhen \\(r = -1\\), there is a perfect negative linear relationship.\nWhen \\(r = 0\\), there is no linear relationship.\n\n\n\nKey Notes\n\nThe sign of \\(r\\) indicates the direction of the slope (positive or negative):\n\nA negative correlation reflects an inverse relationship.\nPositive and negative correlations of the same magnitude have the same shared variance.\n\nChanging sample size does not affect \\(r\\).\nCorrelation does not imply causation.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#correlation-analysis",
    "href": "foundation-chapter08.html#correlation-analysis",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Correlation Analysis",
    "text": "Correlation Analysis\n\nKey Formula\n\\[\nr = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{(n-1) S_x S_y} = \\frac{\\sum_{i=1}^n Z_x Z_y}{n-1}\n\\] where \\(n\\) = number of \\((x, y)\\) pairs.\n\n\nWhy Plot the Data First?\n\nUse scatterplots to visually check for linear relationships, outliers, or curved patterns (e.g., Anscombe’s dataset). Then calculate the correlation to assess the strength of the relationship.\nOutliers can significantly distort \\(r\\), regression slopes, and intercepts, as these measures are not resistant to extreme values.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#factors-affecting-the-magnitude-of-r",
    "href": "foundation-chapter08.html#factors-affecting-the-magnitude-of-r",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Factors Affecting the Magnitude of \\(r\\)",
    "text": "Factors Affecting the Magnitude of \\(r\\)\n\nBivariate Outliers: Can inflate or deflate \\(r\\).\nDistribution Shape: Differences in variability between \\(X\\) and \\(Y\\) can distort \\(r\\).\nRange Restrictions: Restricted ranges of data can misrepresent \\(r\\).\nCombining Groups: Mixed groups may lead to misleading correlations. Averages are less variable, so the correlation will be stronger.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#facts-about-r",
    "href": "foundation-chapter08.html#facts-about-r",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Facts About \\(r\\)",
    "text": "Facts About \\(r\\)\n\n\\(r\\) estimates the population correlation, \\(\\rho\\).\nMeasures the strength of a linear relationship between two variables.\nIs always between \\(-1\\) and \\(1\\).\nIs unitless and unaffected by changes in measurement scales.\nAssumes both variables are quantitative.\nAssumes bivariate normal distribution (for any value of \\(y\\), \\(x\\) has a normal distribution, and vice versa).\nIs not resistant to outliers.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#interpreting-r2-the-coefficient-of-determination",
    "href": "foundation-chapter08.html#interpreting-r2-the-coefficient-of-determination",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Interpreting \\(r^2\\), the Coefficient of Determination",
    "text": "Interpreting \\(r^2\\), the Coefficient of Determination\n\nDefinition\n\\(r^2\\), also known as the coefficient of determination, represents the proportion of variability in \\(Y\\) that is explained by its linear relationship with \\(X\\).\nIf \\(r^2\\) is calculated from a sample, it serves as an estimate of how well changes in \\(X\\) explain variation in \\(Y\\).\nFor example, an \\(r^2\\) of 0.75 means that 75% of the variability in \\(Y\\) can be attributed to its linear relationship with \\(X\\), while the remaining 25% remains unexplained by the model.\n\n\nFormula\n\\[\nR^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}}\n\\] where:\n\n\\(SS_{\\text{res}}\\) = sum of squared residuals\n\\(SS_{\\text{tot}}\\) = total sum of squares\n\nThis measures how much of the total variance from the equal means model is explained by the regression model.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#correlation-doesnt-equal-causation",
    "href": "foundation-chapter08.html#correlation-doesnt-equal-causation",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Correlation Doesn’t Equal Causation",
    "text": "Correlation Doesn’t Equal Causation\n\nAssociation (strong correlation) is not causation.\nThe only way to make cause-and-effect statements is with a randomized experiment.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#keys-to-remember",
    "href": "foundation-chapter08.html#keys-to-remember",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Keys to Remember",
    "text": "Keys to Remember\n\nThe correlation coefficient assumes equal standard deviation.\n\nDon’t confuse fewer data points with smaller standard deviation.\n\nThe range of the data is a proxy for the spread. Knowing the particular \\(X\\) value reduces the variation.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#data-exploration",
    "href": "foundation-chapter08.html#data-exploration",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Data Exploration",
    "text": "Data Exploration\n\nAlways plot the data using scatterplots for two quantitative variables.\nLook for overall patterns: positive/negative, strong/weak, curved/linear.\nIf the relationship is linear, calculate a numerical summary.\nPlot a regression line for interpretation.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#least-squares-regression",
    "href": "foundation-chapter08.html#least-squares-regression",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Least Squares Regression",
    "text": "Least Squares Regression\n\nOrigin of Regression\n\nThe term regression originates from Francis Galton’s phrase “Regression toward mediocrity,” referring to regression to the mean.\nA regression line is a straight line that describes how a response variable (\\(Y\\)) changes as an explanatory variable (\\(X\\)) changes. It is used to predict the value of \\(Y\\) for a given \\(X\\).\n\n\n\nKey Points\n\nOne Best-Fit Line:\n\nThere is only one best-fit line per dataset.\nThis line minimizes the distance between observed points and the line (residuals).\nResiduals: The difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)), calculated as \\(\\text{Residual} = y_i - \\hat{y}_i\\). Residuals measure the error in prediction.\nThe best-fit line (slope and y-intercept) minimizes the sum of squared residuals (SSR).\nAll the residuals would be zero for a perfect fitting line.\n\nRelation to Correlation:\n\n\\(\\hat{b_1}\\) (slope) and \\(r\\) always have the same sign.\nThe least squares regression line always passes through \\((\\bar{X}, \\bar{Y})\\).\n\nChoice of Variables:\n\nRegression equation depends on the designation of explanatory and response variables.\nWith correlation you can flip \\(X\\) and \\(Y\\) but not with regression.\n\nSubpopulations:\n\nIn simple regression with a single explanatory variable, each value of the explanatory variable corresponds to a subpopulation of responses.\nRegression describes the relationship between the means of these subpopulations and the explanatory variable.\n\n\n\n\nEstimating Regression Coefficients\n\nSlope (\\(\\hat{\\beta}_1\\)): \\[\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2} = r \\frac{S_y}{S_x}\n\\]\nIntercept (\\(\\hat{\\beta}_0\\)): \\[\n\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\n\\]\n\n\n\nDefinition\nA regression line predicts \\(Y\\) from \\(X\\): \\[\nY = \\beta_0 + \\beta_1 X\n\\]\n\n\nInterpretation\n\nSlope (\\(\\hat{\\beta}_1\\)), coefficient of \\(X\\):\n\nRepresents the predicted change in \\(Y\\) for a one-unit increase in \\(X\\).\n“Rise over run”: \\(\\frac{\\Delta Y}{\\Delta X}\\)\nEach one-unit increase in \\(X\\) is associated with an estimated increase of \\(\\beta_1\\) units in the predicted value of \\(Y\\).\nExample: A slope of \\(6.708\\) means a one-hour increase in study time predicts an average score increase of 6.708 points.\n\nIntercept (\\(\\hat{\\beta}_0\\)), constant term:\n\nRepresents the predicted value of \\(Y\\) when \\(X = 0\\).\nExample: An intercept of \\(40.993\\) means a predicted score of 40.993 when no study time is recorded.\n\n\n\n\nExtrapolation\n\nPredictions are only valid for \\(X\\) values within the range used to build the model.\nExtrapolation: Predicting values of \\(Y\\) for \\(X\\) outside the observed data range. Use cautiously, as extrapolated predictions may not reliably represent real-world behavior, and clearly communicate that the results are extrapolated.\n\n\n\nAssumptions for Linear Regression\n\nNormality, conditional on \\(X\\):\n\nThe response variable is normally distributed for each value of \\(X\\).\n\nLinearity:\n\nThe relationship between the means of \\(Y\\) for each value of \\(X\\) is linear. The mean of the normal distributions follow a linear pattern.\n\nEqual Standard Deviation:\n\nVariance of residuals is constant for all \\(X\\).\nEstimate: \\(\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n \\text{residuals}_i^2}{n - 2}} = \\text{RMSE}\\).\n\nIndependence:\n\nObservations are independent of each other.\n\n\n\n\nNotation\n\n\\(m_{Y|X} = b_0 + b_1X\\): Mean of \\(Y\\) as a function of \\(X\\) or for a specific value of \\(X\\).\n\\(s_{Y|X} = s\\): Standard deviation of \\(Y\\) as a function of \\(X\\), assuming equal standard deviation across \\(X\\) values.\n\n\n\nHand-Calculated Pearson’s \\(r\\)\nWe can calculate the sample linear correlation coefficient, \\(r\\), using either of the following equivalent formulas: \\[\nr = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{(n - 1) S_X S_Y} = \\frac{\\sum_{i=1}^n Z_{X_i} Z_{Y_i}}{n - 1}\n\\] where:\n\n\\(Z_{X_i} = \\dfrac{X_i - \\bar{X}}{S_X}\\)\n\\(Z_{Y_i} = \\dfrac{Y_i - \\bar{Y}}{S_Y}\\)\n\n\nExample: Calculating \\(Z\\)-scores\nTo compute \\(Z_{X}\\) for the first observation: \\[\nZ_{X_1} = \\frac{1 - 3.923}{2.397} = -1.220\n\\]\nTo compute \\(Z_{Y}\\) for the first observation: \\[\nZ_{Y_1} = \\frac{34 - 67.308}{19.564} = -0.578\n\\]\n\n\n\nRaw Data and Z-Scores\n\n\n\nHours (\\(X\\))\nScore (\\(Y\\))\n\\(Z_X\\)\n\\(Z_Y\\)\n\\(Z_X Z_Y\\)\n\n\n\n\n1\n34\n-1.220\n-1.7703\n2.077\n\n\n1\n56\n-1.220\n-0.578\n0.705\n\n\n2\n45\n-0.802\n-1.140\n0.915\n\n\n2\n70\n-0.802\n0.138\n-0.110\n\n\n2\n55\n-0.802\n-0.624\n0.305\n\n\n3\n68\n-0.385\n0.035\n-0.014\n\n\n4\n67\n0.032\n-0.016\n-0.001\n\n\n4\n79\n0.032\n0.598\n0.019\n\n\n4\n45\n0.032\n-1.140\n-0.037\n\n\n6\n89\n0.862\n1.109\n0.956\n\n\n7\n95\n1.284\n1.416\n1.817\n\n\n7\n78\n1.284\n0.547\n0.702\n\n\n8\n94\n1.701\n1.364\n2.321\n\n\n\nSummary statistics:\n\n\\(\\bar{X} = 3.923\\), \\(S_X = 2.397\\)\n\\(\\bar{Y} = 67.308\\), \\(S_Y = 19.564\\)\n\\(n = 13\\)\n\\(\\sum Z_X Z_Y = 9.860\\)\n\n\n\nFinal Computation of \\(r\\)\n\\[\nr = \\frac{\\sum_{i=1}^{13} Z_{X_i} Z_{Y_i}}{13 - 1} = \\frac{9.860}{12} = 0.8217\n\\]\nTherefore, the sample correlation is: \\(r = 0.8217\\)\n\n\nScatterplot of Test Score by Study Hours\nAfter plotting the data, we do not see evidence of:\n\nOutliers\nUnequal standard deviations\nA curved relationship\n\nSince a linear relationship appears appropriate, we proceed with correlation analysis.\nThe correlation coefficient is: \\(r = 0.8217\\)\nThis value provides evidence of a strong positive linear association between study hours and test score.\n\n\n\nScatterplot of test score vs. study hours with best-fit line.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#pearsons-r-and-the-six-step-hypothesis-test",
    "href": "foundation-chapter08.html#pearsons-r-and-the-six-step-hypothesis-test",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Pearson’s \\(r\\) and the Six-Step Hypothesis Test",
    "text": "Pearson’s \\(r\\) and the Six-Step Hypothesis Test\n\n1. Hypotheses (Testing \\(\\rho\\), the Population Correlation Coefficient)\n\n\\(H_0\\): \\(\\rho = 0\\) (no linear correlation in the population)\n\\(H_a\\): \\(\\rho \\ne 0\\) (a linear correlation exists in the population)\n\n\n\n2. Critical Value (From a t-Distribution)\n\n\\(\\pm t_{0.975, 13 - 2} = \\pm 2.201\\)\n\n\nComputing the critical value:\n\nIn SAS: quantile(\"t\", 0.975, 13 - 2)\nIn R: qt(0.975, 11)\n\n\n\n\n3. Test Statistic\nThe sample linear correlation coefficient \\(r\\) is transformed into a t-distribution using the formula: \\[\nt = \\frac{r\\sqrt{n - 2}}{\\sqrt{1 - r^2}} \\sim t_{n - 2}\n\\]\nSubstituting values: \\[\nt = \\frac{0.8217 \\cdot \\sqrt{13 - 2}}{\\sqrt{1 - (0.8217)^2}} = 4.718\n\\]\n\n\nCompute \\(r\\) in Statistical Software\n\nIn SAS:\n\n\nCode\nproc corr data = Studytime;\nrun;\n\n\n\n\nIn R:\n\n\nCode\ncor.test(StudyTime$StudyHours, StudyTime$ExamScore)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutputs from SAS and R showing the Pearson correlation between study time and exam score. SAS includes descriptive statistics, \\(r = 0.8217\\), and a p-value. R includes the \\(t\\)-statistic, degrees of freedom, confidence interval, estimate (\\(r = 0.8217\\)), and p-value for \\(H_0: \\rho = 0\\).\n\n\n\n\n4. Find the p-Value\nThe p-value is calculated using the t-distribution with \\(n - 2\\) degrees of freedom.\n\nIn this example, the p-value is 0.0006.\n\n\n\n5. Decision\nAt a significance level of \\(\\alpha = 0.05\\):\n\nSince \\(p = 0.0006 &lt; 0.05\\), we reject the null hypothesis \\(H_0\\).\n\n\n\n6. Conclusion\nAt the \\(\\alpha = 0.05\\) level, there is strong evidence that exam scores are linearly correlated with study hours (p-value = 0.0006).\n\nSince the correlation is statistically significant, it makes sense to interpret \\(R^2\\).\nIt is estimated that \\(R^2 = 67.5\\%\\) of the variation in exam scores is explained by study hours.\n\nScope:\nBecause students were not randomly assigned study hours, we cannot conclude causation, only association. Also, since the data collection method is unknown, we cannot generalize this result beyond the students in the study.\n\n\nLeast Squares Regression Model\nWe now estimate the least squares regression line: \\[\n\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X\n\\]\nBased on the sample of 13 students, the slope and intercept are calculated using the formulas: \\[\n\\hat{\\beta}_1 = \\dfrac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}, \\quad\n\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\n\\]\n\n\nHand Calculation of Coefficients\n\n\n\n\n\n\n\n\n\n\n\n\\(Y_i\\ \\text{(Grade)}\\)\n\\(X_i\\ \\text{(Hours)}\\)\n\\(X_i - \\bar{X}\\)\n\\(Y_i - \\bar{Y}\\)\n\\((X_i - \\bar{X})(Y_i - \\bar{Y})\\)\n\\((X_i - \\bar{X})^2\\)\n\n\n\n\n34\n1\n-2.9231\n-33.3077\n97.3609\n8.5444\n\n\n56\n1\n-2.9231\n-11.3077\n33.0533\n8.5444\n\n\n45\n2\n-1.9231\n-22.3077\n42.8994\n3.6982\n\n\n70\n2\n-1.9231\n2.6923\n-5.1775\n3.6982\n\n\n55\n2\n-1.9231\n-12.3077\n23.6686\n3.6982\n\n\n68\n3\n-0.9231\n0.6923\n-0.6391\n0.8521\n\n\n67\n4\n0.0769\n-0.3077\n-0.0237\n0.0059\n\n\n79\n4\n0.0769\n11.6923\n0.8994\n0.0059\n\n\n45\n4\n0.0769\n-22.3077\n-1.7160\n0.0059\n\n\n89\n6\n2.0769\n21.6923\n45.0533\n4.3136\n\n\n95\n7\n3.0769\n27.6923\n85.2071\n9.4675\n\n\n78\n7\n3.0769\n10.6923\n32.8994\n9.4675\n\n\n94\n8\n4.0769\n26.6923\n108.8225\n16.6213\n\n\n\n\n\n\nStatistic\nValue\n\n\n\n\n\\(\\bar{X}\\) (mean of study hours)\n3.923\n\n\n\\(\\bar{Y}\\) (mean of exam scores)\n67.308\n\n\n\\(\\sum (X_i - \\bar{X})^2\\)\n68.923\n\n\n\\(\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})\\)\n462.308\n\n\n\n\nSlope: \\[\n\\hat{\\beta}_1 = \\dfrac{462.308}{68.923} = 6.708\n\\]\nIntercept: \\[\n\\hat{\\beta}_0 = 67.308 - (6.708 \\times 3.923) = 40.993\n\\]\n\nFinal least squares regression line: \\[\n\\widehat{\\text{Grade}} = 40.993 + 6.708 \\times \\text{StudyHours}\n\\]",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#regression-output-in-software",
    "href": "foundation-chapter08.html#regression-output-in-software",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Regression Output in Software",
    "text": "Regression Output in Software\n\n\nCode\nproc reg data = StudyTime;\n   * Model syntax: response = explanatory;\n   model ExamScore = StudyTime;\nrun;\n\n* To request confidence intervals for coefficients, use the CLB option:\n* model ExamScore = StudyTime / clb;\n\n* Alternatively, use PROC GLM for similar results:\nproc glm data = StudyTime;\n   * The SOLUTION option displays the parameter estimates;\n   model ExamScore = StudyTime / solution;\nrun;\n\n\n\n\nCode\n# Fit a linear model: response ~ explanatory\nfit = lm(ExamScore ~ StudyHours, data = StudyTime)\n\n# Display regression coefficients, standard errors, t-tests, and R-squared\nsummary(fit)\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeast squares regression estimates from SAS and R. SAS and R both estimate the regression line: \\(\\widehat{\\text{Grade}} = 40.993 + 6.708 \\times \\text{StudyHours}\\), reporting standard errors, \\(t\\)-statistics, and p-values for both coefficients.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#sampling-distributions-of-the-coefficients",
    "href": "foundation-chapter08.html#sampling-distributions-of-the-coefficients",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Sampling Distributions of the Coefficients",
    "text": "Sampling Distributions of the Coefficients\n\nSlope (\\(\\hat{\\beta}_1\\))\n\nCenter: The mean of the sampling distribution is \\(\\beta_1\\).\nSpread: \\[\n\\text{SE}(\\hat{\\beta}_1) = \\hat{\\sigma} \\sqrt{\\dfrac{1}{(n - 1)s_X^2}}, \\quad \\text{df} = n - 2\n\\] where \\(s_X^2\\) is the sample variance of the \\(X\\)s.\nShape: Normal (under regression assumptions)\n\n\n\nIntercept (\\(\\hat{\\beta}_0\\))\n\nCenter: The mean of the sampling distribution is \\(\\beta_0\\).\nSpread: \\[\n\\text{SE}(\\hat{\\beta}_0) = \\hat{\\sigma} \\sqrt{\\dfrac{1}{n} + \\dfrac{\\bar{X}^2}{(n - 1)s_X^2}}, \\quad \\text{df} = n - 2\n\\]\nShape: Normal (under regression assumptions)\n\n\n\nResidual Standard Deviation\nThe residual standard deviation estimates the true standard deviation \\(\\sigma\\) of the errors in the regression model: \\[\n\\hat{\\sigma} = \\sqrt{\\dfrac{\\text{Sum of Squared Residuals}}{\\text{df}}}\n\\]\nThis is also known as the root mean squared error (RMSE). The degrees of freedom for simple linear regression are: \\[\n\\text{df} = n - 2\n\\]\n\n\nSampling Distributions of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)\nWhen fitting a simple linear regression model, the estimated coefficients \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) each have their own sampling distribution:\n\nStandard Error of the Slope\n\\[\n\\text{SE}(\\hat{\\beta}_1) = \\hat{\\sigma} \\sqrt{ \\frac{1}{(n - 1)s_X^2} }\n\\]\n\n\nStandard Error of the Intercept\n\\[\n\\text{SE}(\\hat{\\beta}_0) = \\hat{\\sigma} \\sqrt{ \\frac{1}{n} + \\frac{\\bar{X}^2}{(n - 1)s_X^2} }\n\\] where:\n\n\\(\\hat{\\sigma}\\) is the residual standard deviation.\n\\(s_X^2\\) is the sample variance of the explanatory variable.\n\\(\\bar{X}\\) is the mean of the \\(X_i\\) values.\n\nThese formulas assume the regression model meets the standard assumptions (linearity, independence, equal variance, and normality of errors).\n\n\n\nExample: Study Hours and Exam Grades\nFrom the regression of 13 students’ exam grades on study hours, we are given or calculated:\n\n\\(n = 13\\)\n\\(\\bar{X} = 3.923\\)\n\\(\\sum (X_i - \\bar{X})^2 = 68.923\\)\n\\(\\hat{\\beta}_1 = 6.708\\), \\(\\hat{\\beta}_0 = 40.993\\)\n\\(\\text{SSE} = \\sum (Y_i - \\hat{Y}_i)^2 = 1491.80\\)\n\n\n1. Sample Variance of \\(X\\)\nWe compute the sample variance of the explanatory variable: \\[\ns_X^2 = \\frac{1}{n - 1} \\sum (X_i - \\bar{X})^2 = \\frac{68.923}{13-1} = 5.744\n\\]\n\n\n2. Residual Standard Deviation\nThe residual standard deviation estimates the typical deviation between the actual and predicted exam scores: \\[\n\\hat{\\sigma} = \\sqrt{\\dfrac{\\text{Sum of squared residuals}}{\\text{df}}} = \\sqrt{ \\dfrac{ \\sum_{i=1}^n (Y_i - \\hat{Y}_i)^2 }{n - 2} } = \\sqrt{ \\dfrac{1491.799}{11} } = 11.646\n\\]\nThis is the square root of the mean squared error (MSE) from the regression and is used to quantify residual variability.\n\n\n\n\n\n\nHow is the sum of squared residuals (SSE) calculated?\n\n\n\n\n\nTo compute the sum of squared residuals (also called SSE or Sum of Squared Errors), we use the fitted regression line: \\[\n\\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_i = 40.993 + 6.708 \\cdot X_i\n\\]\nFor each observation:\n\nCompute the predicted value:\n\\[\n\\hat{Y}_i = 40.993 + 6.708 \\cdot X_i\n\\]\nFind the residual:\n\\[\ne_i = Y_i - \\hat{Y}_i\n\\]\nSquare the residual:\n\\[\ne_i^2 = (Y_i - \\hat{Y}_i)^2\n\\]\nSum the squared residuals:\n\\[\n\\text{SSE} = \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2 = 1491.799\n\\] Substituting back into the formula: \\[\n\\hat{\\sigma} = \\sqrt{\\dfrac{1491.799}{13 - 2}} = \\sqrt{\\dfrac{1491.799}{11}} = 11.646\n\\]\n\n\n\n\n\n\n3. Standard Error of the Slope\n\\[\n\\text{SE}(\\hat{\\beta}_1) = \\hat{\\sigma} \\sqrt{\\dfrac{1}{(n - 1)s_X^2}}, \\quad \\text{df} = n - 2\n\\]\n\\[\n\\text{SE}(\\hat{\\beta}_1) = 11.646 \\cdot \\sqrt{\\frac{1}{12 \\cdot 5.744}} = 1.403\n\\]\n\n\n4. Standard Error of the Intercept\n\\[\n\\text{SE}(\\hat{\\beta}_0) = \\hat{\\sigma} \\sqrt{\\frac{1}{n} + \\frac{\\bar{X}^2}{(n - 1)s_X^2}}\n\\]\n\\[\n\\text{SE}(\\hat{\\beta}_0) = 11.646 \\cdot \\sqrt{ \\frac{1}{13} + \\frac{3.923^2}{12 \\cdot 5.744} } = 6.381\n\\]\n\n\nSummary\n\n\\(\\text{SE}(\\hat{\\beta}_1) = 1.403\\)\n\\(\\text{SE}(\\hat{\\beta}_0) = 6.381\\)\n\nThese values describe the variability in slope and intercept estimates across hypothetical repeated samples.\n\n\n\nSampling Distributions of Regression Coefficients\n\n\n\nSampling distributions of \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\). Under the assumptions of simple linear regression, the sampling distributions of the slope and intercept are approximately normal. Their centers are the true population coefficients (\\(\\beta_0\\) and \\(\\beta_1\\)), and their spread depends on sample size (\\(n\\)), the variability in the explanatory variable (\\(X\\)), and the residual variability (\\(\\hat{\\sigma}^2\\)). These distributions are the foundation for t-tests and confidence intervals in regression.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#hypothesis-testing-for-slope-and-intercept",
    "href": "foundation-chapter08.html#hypothesis-testing-for-slope-and-intercept",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Hypothesis Testing for Slope and Intercept",
    "text": "Hypothesis Testing for Slope and Intercept\nIn simple linear regression, we can test whether either regression coefficient is significantly different from zero. This includes:\n\nA t-test for the slope \\(\\beta_1\\) to assess whether the explanatory variable is linearly associated with the response.\nA t-test for the intercept \\(\\beta_0\\) to assess whether the predicted response is significantly different from zero when the explanatory variable is zero.\n\nThe general form of the hypotheses is:\n\nFor the intercept: \\[\nH_0: \\beta_0 = 0 \\quad \\text{vs.} \\quad H_A: \\beta_0 \\ne 0\n\\]\nFor the slope: \\[\nH_0: \\beta_1 = 0 \\quad \\text{vs.} \\quad H_A: \\beta_1 \\ne 0\n\\]\n\nWe now demonstrate the full hypothesis test procedure using the slope \\(\\beta_1\\) as an example.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#hypothesis-test-and-confidence-interval-for-the-slope",
    "href": "foundation-chapter08.html#hypothesis-test-and-confidence-interval-for-the-slope",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Hypothesis Test and Confidence Interval for the Slope",
    "text": "Hypothesis Test and Confidence Interval for the Slope\nWe test whether the slope of the regression line differs significantly from zero using a two-tailed t-test.\n\n1. Hypotheses\nWe are testing whether the number of study hours is linearly related to exam score: \\[\nH_0: \\beta_1 = 0 \\\\\nH_A: \\beta_1 \\ne 0\n\\]\n\n\n2. Critical Value Method\nDegrees of freedom: \\[\ndf = n - 2 = 13 - 2 = 11\n\\]\nFor a two-tailed test with \\(\\alpha = 0.05\\): \\[\nt_{0.975,11} = \\pm 2.201\n\\]\n\n\n3. Test Statistic\n\\[\nt = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)} = \\frac{6.708}{1.403} = 4.78\n\\]\n\n\n4. p-value\n\\[\n\\text{p-value} = 0.0006 &lt; 0.05\n\\]\n\n\n5. Decision\nSince the test statistic exceeds the critical value and the p-value is less than 0.05, we reject \\(H_0\\).\n\n\n6. Conclusion\nThere is strong evidence to suggest that the number of study hours and grade scores are positively linearly related.\nThat is, the slope is significantly greater than 0 (p-value = 0.0006).\n\n\n7. 95% Confidence Interval for the Slope\n\\[\n\\hat{\\beta}_1 \\pm t_{0.975, 11} \\cdot SE(\\hat{\\beta}_1) = 6.708 \\pm 2.201 \\times 1.403 = (3.609, 9.807)\n\\]\nWe are 95% confident that for each 1-hour increase in study time, the mean exam score increases between 3.6 and 9.8 points. Our best estimate of that increase is 6.708 points.\n\nNote: A similar t-test and confidence interval can be constructed for the intercept \\(\\beta_0\\), using the same degrees of freedom and standard error of the intercept. Most software packages report both tests automatically.\n\n\n\n\nTwo-tailed t-test for slope coefficient. The red line shows the observed test statistic (\\(t = 4.78\\)). Shaded regions represent the critical regions at \\(\\alpha = 0.05\\) for a two-tailed test with 11 degrees of freedom. The slope coefficient is statistically significant (p-value = 0.0006).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter08.html#summary-steps-in-simple-linear-regression",
    "href": "foundation-chapter08.html#summary-steps-in-simple-linear-regression",
    "title": "Linear Correlation and Simple Linear Regression",
    "section": "Summary: Steps in Simple Linear Regression",
    "text": "Summary: Steps in Simple Linear Regression\n\nPlot the data to visualize the relationship.\nAssess linear association between the two variables:\n\nCompute and test the correlation coefficient \\(\\rho\\).\nIf \\(\\rho \\ne 0\\), there is evidence of a linear relationship.\n\nCalculate the regression coefficients:\n\nEstimate the slope \\(\\hat{\\beta}_1\\) and intercept \\(\\hat{\\beta}_0\\).\nThese describe the fitted line and are needed for inference.\n\nTest the slope coefficient (\\(\\beta_1\\)):\n\nUse a t-test to determine whether the explanatory variable is significantly associated with the response.\nIn simple linear regression, this test is equivalent to testing whether the correlation coefficient \\(\\rho\\) differs from 0.\n\nInterpret the regression coefficients (slope and intercept):\n\nReport the slope and intercept in context, assessing practical significance.\nInclude point estimates, standard errors, and confidence intervals.\n\nUse the model for prediction:\n\nOnly make predictions within the range of observed values for the explanatory variable.\n\n\n\nNote: In simple linear regression, testing whether \\(\\beta_1 = 0\\) is equivalent to testing whether the population correlation \\(\\rho = 0\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html",
    "href": "foundation-chapter09.html",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#objectives",
    "href": "foundation-chapter09.html#objectives",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "",
    "text": "Calculate and interpret confidence intervals for the slope of a regression line.\nPredict future values using the regression model.\nObtain and interpret confidence intervals for predicted responses.\nUse a regression model to calibrate one measurement against another.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#useful-resources",
    "href": "foundation-chapter09.html#useful-resources",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "Useful Resources",
    "text": "Useful Resources\n\nRossman Chance Applets: Regression Shuffle",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#statistical-relationships",
    "href": "foundation-chapter09.html#statistical-relationships",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "Statistical Relationships",
    "text": "Statistical Relationships\n\nKey Insight: The value of the explanatory variable determines the mean response value.\nVariability exists in the response variable for a given explanatory value.\nThe slope and intercept each have their own sampling distribution and standard error.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#formal-assumptions",
    "href": "foundation-chapter09.html#formal-assumptions",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "Formal Assumptions",
    "text": "Formal Assumptions\n\nLinearity: A linear relationship exists between the means of the response variable distributions and the explanatory variable.\nIndependence: Observations are independent.\nNormality: The response variable \\(y\\) is normally distributed for each fixed \\(x\\) value.\n\nErrors are in \\(y\\), not \\(x\\).\nNormality is assumed for \\(y\\) at each fixed \\(x\\), not for \\(y\\) overall.\n\nConstant variance: The variability in the \\(y\\) distributions is constant across all values of \\(x\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#regression-model",
    "href": "foundation-chapter09.html#regression-model",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "Regression Model",
    "text": "Regression Model\n\nTheoretical model: \\[\ny = \\beta_0 + \\beta_1 x + \\varepsilon\n\\]\n\n\\(y =\\) mean \\(\\pm\\) residual, where the residual represents the difference between the observed value and the mean.\nResiduals (\\(\\varepsilon\\)) follow a normal distribution with mean zero and constant variance (\\(\\sigma^2\\)).\n\nRegression line (estimated values): \\(\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x\\)\nResiduals: \\(e_i = y_i - \\hat{y}_i = y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)\\)\nDistribution of residuals: \\(\\varepsilon \\sim N(0, \\sigma^2)\\)\n\nResiduals are normally distributed around zero, with estimated standard deviation \\(\\hat{\\sigma}\\), i.e., the standard deviation of each \\(y\\) distribution.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#using-residual-plots-to-check-regression-validity",
    "href": "foundation-chapter09.html#using-residual-plots-to-check-regression-validity",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "Using Residual Plots to Check Regression Validity",
    "text": "Using Residual Plots to Check Regression Validity\n\nKey points:\n\nResidual plots help validate regression assumptions.\nRandom patterns in residuals suggest a valid model.\n\nLook for randomness, no obvious pattern, constant variability (homoscedasticity), and a mean of zero.\nWatch for outliers or patterns that might suggest curvature or unequal spread.\nNarrower bands of residuals (i.e., smaller spread) suggest a stronger relationship between \\(x\\) and \\(y\\); wider spread suggests a weaker relationship.\nIt’s easier to detect deviations from a horizontal line (in residuals) than from a sloped regression line.\n\nA Q–Q plot of residuals assesses normality.\nIf residuals are randomly distributed with constant variance, and the Q–Q plot shows normality, the model is appropriate for inference.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#analysis-of-variance-in-regression",
    "href": "foundation-chapter09.html#analysis-of-variance-in-regression",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "Analysis of Variance in Regression",
    "text": "Analysis of Variance in Regression\n\nData Summary\n\n\n\nLevel\nScore 1\nScore 2\nScore 3\n\n\n\n\n1\n3\n5\n7\n\n\n2\n10\n12\n14\n\n\n3\n20\n22\n24\n\n\n\nSample size: \\(n = 9\\)\n\n\nRegression Equation\nFitting a linear model: \\[\n\\text{Score} = -4 + 8.5 \\cdot \\text{Level}\n\\]\n\n\nEqual Means Model vs. Regression Model Comparison\n\nTotal Variability Under the Equal Means Model\nThe Equal Means Model (EMM) assumes a single grand mean across all groups:\n\\[\n\\bar{y} = 13\n\\]\nWe compute the squared deviations from the grand mean for each observation. These add up to the Total Sum of Squares (SST).\n\n\nEqual Means Model: Squared Deviations from Grand Mean\n\n\n\n\n\n\n\n\n\n\n\\(\\textcolor{#BB4444}{\\textbf{Level}}\\)\n\\(\\textcolor{#BB4444}{\\textbf{Obs1}}\\)\n\\(\\textcolor{#BB4444}{\\textbf{Obs2}}\\)\n\\(\\textcolor{#BB4444}{\\textbf{Obs3}}\\)\n\n\n\n\n\\(\\textcolor{#BB4444}{1}\\)\n\\(\\textcolor{#BB4444}{(3 - 13)^2 = 100}\\)\n\\(\\textcolor{#BB4444}{(5 - 13)^2 = 64}\\)\n\\(\\textcolor{#BB4444}{(7 - 13)^2 = 36}\\)\n\n\n\\(\\textcolor{#BB4444}{2}\\)\n\\(\\textcolor{#BB4444}{(10 - 13)^2 = 9}\\)\n\\(\\textcolor{#BB4444}{(12 - 13)^2 = 1}\\)\n\\(\\textcolor{#BB4444}{(14 - 13)^2 = 1}\\)\n\n\n\\(\\textcolor{#BB4444}{3}\\)\n\\(\\textcolor{#BB4444}{(20 - 13)^2 = 49}\\)\n\\(\\textcolor{#BB4444}{(22 - 13)^2 = 81}\\)\n\\(\\textcolor{#BB4444}{(24 - 13)^2 = 121}\\)\n\n\n\n\n\\[\n\\text{SST} = \\sum (y_i - \\bar{y})^2 = \\textcolor{#BB4444}{462}\n\\]\n\n\nResidual Variability Under the Regression Model\nWe now compute residuals from the fitted regression model:\n\\[\n\\hat{y}_i = -4 + 8.5 \\cdot x_i\n\\]\n\n\nRegression Model: Squared Residuals\n\n\n\n\n\n\n\n\n\n\n\\(\\textcolor{#44AA55}{\\textbf{Level}}\\)\n\\(\\textcolor{#44AA55}{\\textbf{Obs1}}\\)\n\\(\\textcolor{#44AA55}{\\textbf{Obs2}}\\)\n\\(\\textcolor{#44AA55}{\\textbf{Obs3}}\\)\n\n\n\n\n\\(\\textcolor{#44AA55}{1}\\)\n\\(\\textcolor{#44AA55}{(3 - 32.5)^2 = 6.25}\\)\n\\(\\textcolor{#44AA55}{(5 - 32.5)^2 = 20.25}\\)\n\\(\\textcolor{#44AA55}{(7 - 32.5)^2 = 56.25}\\)\n\n\n\\(\\textcolor{#44AA55}{2}\\)\n\\(\\textcolor{#44AA55}{(10 - 13)^2 = 9}\\)\n\\(\\textcolor{#44AA55}{(12 - 13)^2 = 1}\\)\n\\(\\textcolor{#44AA55}{(14 - 13)^2 = 1}\\)\n\n\n\\(\\textcolor{#44AA55}{3}\\)\n\\(\\textcolor{#44AA55}{(20 - 19.5)^2 = 0.25}\\)\n\\(\\textcolor{#44AA55}{(22 - 19.5)^2 = 6.25}\\)\n\\(\\textcolor{#44AA55}{(24 - 19.5)^2 = 20.25}\\)\n\n\n\n\n\\[\n\\text{SSE} = \\sum (y_i - \\hat{y}_i)^2 = \\textcolor{#44AA55}{28.5}\n\\]\n\n\nDecomposition of Variance\n\n\nANOVA Table: Comparing Regression to Equal Means Model\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\textcolor{#4477DD}{\\textbf{Source}}\\)\n\\(\\textcolor{#4477DD}{\\textbf{df}}\\)\n\\(\\textcolor{#4477DD}{\\textbf{SS}}\\)\n\\(\\textcolor{#4477DD}{\\textbf{MS}}\\)\n\\(\\textcolor{#4477DD}{\\textbf{F}}\\)\n\\(\\textcolor{#4477DD}{\\mathit{p}\\text{-value}}\\)\n\n\n\n\n\\(\\textcolor{#4477DD}{\\text{Model}}\\)\n\\(\\textcolor{#4477DD}{1}\\)\n\\(\\textcolor{#4477DD}{433.5}\\)\n\\(\\textcolor{#4477DD}{433.5}\\)\n\\(\\textcolor{#4477DD}{106.47}\\)\n\\(\\textcolor{#4477DD}{&lt; 0.0001}\\)\n\n\n\\(\\textcolor{#44AA55}{\\text{Error}}\\)\n\\(\\textcolor{#44AA55}{7}\\)\n\\(\\textcolor{#44AA55}{28.5}\\)\n\\(\\textcolor{#AA9933}{4.07}\\)\n\n\n\n\n\\(\\textcolor{#BB4444}{\\text{Total}}\\)\n\\(\\textcolor{#BB4444}{8}\\)\n\\(\\textcolor{#BB4444}{462}\\)\n\n\n\n\n\n\n\n\nNote: The regression model estimates both a slope and an intercept, using 2 degrees of freedom. This reduces the error degrees of freedom from 8 (in the Equal Means Model) to 7:\n\\[\n\\text{df}_{\\text{Error}} = n - 2 = 9 - 2 = 7\n\\]\n\n\n\n\\(R^2\\) and RMSE Interpretation\nThe \\(R^2\\) value quantifies how much of the total variability in the response is explained by the regression model. It is based on the decomposition of total variability into two parts: variability explained by the model (SSR) and unexplained variability due to error (SSE):\n\\[\nR^2 = \\frac{\\text{SSR}}{\\text{SST}} = 1 - \\frac{\\text{SSE}}{\\text{SST}}\n\\] \\[\nR^2 = \\frac{\\textcolor{#4477DD}{433.5}}{\\textcolor{#BB4444}{462}} = 1 - \\frac{\\textcolor{#44AA55}{28.5}}{\\textcolor{#BB4444}{462}} = 0.938\n\\]\nThis means 93.8% of the variability in scores is explained by the regression model.\nThe error variance is measured by the Mean Squared Error (MSE), and the square root of MSE gives the Root Mean Squared Error (RMSE):\n\\[\n\\textcolor{#AA9933}{\n  \\text{MSE} = 4.07 \\quad \\Rightarrow \\quad\n  \\text{RMSE} = \\hat{\\sigma} \\text{ of each } y \\text{ distribution} = \\sqrt{4.07} \\approx 2.02\n}\n\\]\n\n\nVisual Comparison of Models\n\n\n\nVisual Comparison of Residuals: EMM vs. Regression Model. The regression model reduces residual error compared to the EMM. Residuals from both models are shown for a single point to illustrate how \\(R^2\\) captures relative model improvement.\n\n\n\n\nF Distribution Under the Null Hypothesis\n\n\n\nF Distribution Under the Null Hypothesis. Area to the right of \\(F = 106.47\\) is shaded. This corresponds to a p-value &lt; 0.0001 under the equal means model.\n\n\nThe F-test compares how much variability is explained by the regression model relative to unexplained error. A large value like \\(F = 106.47\\) indicates a significantly better fit than the Equal Means Model.\nBecause the p-value is less than 0.0001, we reject the null hypothesis that all group means are equal. The regression model explains a substantial proportion of the total variability in scores.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#anova-output-in-software",
    "href": "foundation-chapter09.html#anova-output-in-software",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "ANOVA Output in Software",
    "text": "ANOVA Output in Software\n\nSAS Code\n\n\nCode\nproc glm data=ToyExample;\n  model score = level / solution;\nrun;\n\n\n\n\nR Code\n\n\nCode\nfit &lt;- lm(score ~ level, data = anovaData)\nanova(fit)      # ANOVA table: sums of squares, F-stat\nsummary(fit)    # Coefficient table, t-tests, R², F-stat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANOVA and Regression Output from SAS and R. The top row compares ANOVA tables from SAS and anova(fit) in R, both showing the F-statistic and p-value for the model. The lower R output from summary(fit) includes the regression coefficients, \\(t\\)-tests, \\(R^2\\), and overall F-test.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#inferential-tools-for-predicted-responses",
    "href": "foundation-chapter09.html#inferential-tools-for-predicted-responses",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "Inferential Tools for Predicted Responses",
    "text": "Inferential Tools for Predicted Responses\nRegression models are used to predict response values given specific explanatory values.\nThere is uncertainty in the prediction due to sampling variability and model estimation error.\nDo we want:\n\na confidence interval for the mean response at a given \\(x\\) value?\n\nor a prediction interval for an individual value at that \\(x\\)?\n\n\nConfidence Intervals for the Mean Response\nThe regression line is modeling the mean of \\(Y\\) at values of \\(X\\).\nMean of \\(Y\\), given \\(X_0\\):\n\\[\n\\hat{Y}_{\\text{mean} \\mid X_0} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_0\n\\]\nWe want to know how confident we are that \\(\\hat{Y}\\) is near the true \\(Y\\) value.\nStandard error of the mean at \\(X = X_0\\):\n\\[\nSE\\left( \\hat{Y}_{\\text{mean} \\mid X_0} \\right) = \\hat{\\sigma} \\sqrt{ \\frac{1}{n} + \\frac{(X_0 - \\bar{X})^2}{(n - 1) S_X^2} }\n\\]\nwhere \\(S_X^2\\) is the sample variance of the explanatory variable \\(X\\).\nAs \\(X_0 \\to \\bar{X}\\):\n\\[\nSE\\left( \\hat{Y}_{\\text{mean} \\mid X_0} \\right) = SE\\left( \\bar{Y} \\right) = \\hat{\\sigma} \\sqrt{ \\frac{1}{n} + 0}\n\\]\n\n\n\n\n\n\nNote\n\n\n\nSee the Study Hours and Exam Grades example for a worked calculation of \\(\\bar{X}\\), \\(s_X^2\\), and \\(\\hat{\\sigma}\\), which are used in computing \\(SE\\left( \\hat{Y}_{\\text{mean} \\mid X_0} \\right)\\).\n\n\n\n\n\nSampling Distribution of the Mean Response at \\(X_0\\). The dot marks the predicted mean response \\(\\hat{Y}_{\\text{mean} \\mid X_0}\\) from the regression line. The sideways bell curve illustrates its sampling distribution across repeated samples. The vertical lines mark one standard error above and below the mean response; this is narrower than the full 95% confidence interval.\n\n\nConfidence interval for the mean response:\n\\[\n\\text{CI} = \\hat{Y} \\pm t_{\\alpha/2, n - 2} \\cdot SE\\left( \\hat{Y}_{\\text{mean} \\mid X_0} \\right)\n\\]\nThe interval is wider for values of \\(X_0\\) that are farther from \\(\\bar{X}\\).\n\n\nPrediction Intervals for Individual Responses\nIndividual value of \\(Y\\), given \\(X_0\\):\n\\[\n\\text{Pred}\\{Y \\mid X_0\\} = \\hat{Y}_{\\text{ind} \\mid X_0} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_0\n\\]\nThis is the predicted mean response at \\(X_0\\), obtained from the regression line. To estimate how far an individual observation might deviate from the predicted value, we must account for uncertainty in both the regression model and the individual value.\nStandard error for predicting an individual:\nCombines uncertainty from estimating the mean (estimation error) and natural variability in individuals (random sampling error):\n\\[\nSE\\left( \\hat{Y}_{\\text{ind} \\mid X_0} \\right) = \\hat{\\sigma} \\sqrt{\n1 + \\frac{1}{n} + \\frac{(X_0 - \\bar{X})^2}{(n - 1) S_X^2} }\n\\]\nTo highlight the two sources of uncertainty:\n\\[\nSE\\left( \\hat{Y}_{\\text{ind} \\mid X_0} \\right) = \\hat{\\sigma} \\sqrt{\n\\underbrace{1}_{\\text{individual variability}} +\n\\underbrace{\\frac{1}{n} + \\frac{(X_0 - \\bar{X})^2}{(n - 1) S_X^2}}_{\\text{estimation uncertainty}} }\n\\]\nNote that the second term under the square root matches the formula for the standard error of the mean response at \\(X_0\\):\n\\[\nSE\\left( \\hat{Y}_{\\text{mean} \\mid X_0} \\right)^2 = \\hat{\\sigma}^2 \\left(\n\\frac{1}{n} + \\frac{(X_0 - \\bar{X})^2}{(n - 1) S_X^2} \\right)\n\\] Thus:\n\\[\nSE\\left( \\hat{Y}_{\\text{ind} \\mid X_0} \\right) = \\hat{\\sigma}\n\\sqrt{\\underbrace{1}_{\\text{individual variability}} +\n\\underbrace{\\text{estimation variance}}_{\\text{mean response}}}\n\\]\n\nThe 1 reflects random variation in individual responses. Even if we knew the true mean exactly, individuals naturally vary around it.\nThe remaining terms reflect sampling variability in the regression coefficients used to compute \\(\\hat{Y}_{\\text{ind} \\mid X_0}\\).\n\nPrediction interval:\n\\[\n\\text{PI} = \\hat{Y}_{\\text{ind}} \\pm t_{\\alpha/2, n - 2} \\cdot SE\\left( \\hat{Y}_{\\text{ind} \\mid X_0} \\right)\n\\]\nPrediction intervals are wider than confidence intervals because they include additional uncertainty for individual outcomes.\nThey are narrowest when \\(X_0 = \\bar{X}\\) and widen as \\(X_0\\) moves farther from the sample mean.\n\n\n\nRegression Line with Confidence and Prediction Intervals. The dotted blue line shows the fitted regression line, and the vertical dotted line marks the sample mean \\(\\overline{X}\\). The shaded green band represents the 95% confidence interval (CI) for the mean response \\(\\hat{Y}\\), while the shaded orange band shows the 95% prediction interval (PI) for an individual response. The solid blue bell curve represents the sampling distribution of the predicted mean response at \\(\\overline{X}\\) under repeated sampling. The center dot marks \\(\\hat{Y}(\\overline{X})\\), and the upper and lower green dots indicate the 95% CI bounds, \\(\\hat{Y} \\pm t \\cdot SE_{\\text{mean}}\\). The green bell-shaped curves mirror these bounds, visually suggesting the plausible range of values that the mean response might take across repeated samples.\n\n\nUnderstanding the Confidence Interval:\nSee supplementary figure below for an illustration of how the confidence interval represents plausible sampling distributions of the mean response.\n\n\n\nPlausible Sampling Distributions for the Mean Response at \\(\\bar{X}\\). Each curve represents a possible sampling distribution of \\(\\hat{Y}(\\bar{X})\\) if the true population mean were at that location. The central blue distribution corresponds to the sample estimate, while the green curves show other plausible means consistent with the 95% confidence interval. The confidence interval for the mean spans the horizontal segment beneath the distributions.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter09.html#regression-for-calibration-inverse-prediction",
    "href": "foundation-chapter09.html#regression-for-calibration-inverse-prediction",
    "title": "Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals",
    "section": "Regression for Calibration (Inverse Prediction)",
    "text": "Regression for Calibration (Inverse Prediction)\nRather than predicting \\(y\\) for a given \\(x\\), calibration estimates the \\(x\\) value that would produce a desired \\(y\\) (i.e., solve for \\(x\\) when \\(y = y_0\\)).\nPrediction equation:\n\\[\n\\text{Pred}\\{Y \\mid X_0\\} = \\hat{Y}_{\\text{ind} \\mid X_0} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_0\n\\]\nCalibration equation (solving for \\(X_0\\) given \\(y_0\\)):\n\\[\n\\hat{X} = \\frac{y_0 - \\hat{\\beta}_0}{\\hat{\\beta}_1}\n\\]\n\nConfidence Interval for the Mean (Calibration Target)\nGiven a desired outcome (e.g., a grade of \\(y = 75\\)), we can estimate the value of \\(X\\), the number of study hours that would produce it:\n\\[\n\\hat{X} = \\frac{75 - 40.99}{6.71} = 5.07\n\\]\nTo construct a confidence interval for the mean \\(X\\), we treat this as an inverse prediction problem and quantify the uncertainty in the estimate of \\(\\hat{X}\\).\nStandard error of the calibration estimate:\n\\[\nSE(\\hat{X}) = \\frac{SE\\left( \\hat{Y}_{\\text{mean} \\mid X_0} \\right)}{|\\hat{\\beta}_1|}\n\\]\nUsing:\n\n\\(n = 13\\), \\(\\bar{X} = 3.92\\), \\(S_X^2 = 5.74\\)\n\\(\\hat{\\sigma} = 11.65\\) (from MSE \\(= 135.62\\))\n\\(\\hat{X} = 5.07\\)\n\\(\\hat{\\beta}_1 = 6.71\\)\n\nCompute \\(SE(\\hat{X})\\):\n\\[\nSE(\\hat{X}) = \\frac{11.65}{|6.71|} \\sqrt{ \\frac{1}{13} + \\frac{(5.07 - 3.92)^2}{(13 - 1) \\cdot 5.74} } = \\frac{11.65}{|6.71|} \\cdot \\sqrt{0.0889} = 0.538\n\\]\n95% Confidence Interval for \\(\\hat{X}\\):\nUsing \\(t_{0.975, n-2} \\approx 2.02\\):\n\\[\n\\text{95% CI} = \\hat{X} \\pm t_{0.975, n-2} \\cdot SE(\\hat{X}) = 5.07 \\pm 2.02 \\cdot 0.538 = (3.983,\\ 6.157)\n\\]\nInterpretation:\n\nWe are 95% confident that the number of study hours a student would need to earn a mean grade of 75 is in the interval (3.983, 6.157) hours.\n\n\n\nPrediction Interval for an Individual \\(X\\)\nSometimes we want to predict the \\(X\\) value associated with a single observation that yields a specific \\(y\\).\nWe still estimate:\n\\[\n\\hat{X} = 5.07\n\\]\nBut the standard error includes an extra term for individual-level variation:\n\\[\nSE\\left( \\hat{Y}_{\\text{ind} \\mid X_0} \\right) = \\hat{\\sigma} \\sqrt{ 1 + \\frac{1}{n} + \\frac{(X_0 - \\bar{X})^2}{(n - 1) S_X^2} }\n\\]\nThen:\n\\[\nSE(\\hat{X}) = \\frac{SE\\left( \\hat{Y}_{\\text{ind} \\mid X_0} \\right)}{|\\hat{\\beta}_1|}\n\\] This yields a wider interval than the confidence interval for the mean, because it reflects both model error and individual-level error.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quantifying Uncertainty: Confidence, Prediction and Calibration Intervals</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html",
    "href": "foundation-chapter10.html",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#objectives",
    "href": "foundation-chapter10.html#objectives",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "",
    "text": "Calculate and interpret residuals, standardized residuals, and studentized residuals.\nUse residuals to check regression assumptions.\nApply necessary remedies when assumptions are violated.\nUnderstand the robustness of assumptions (i.e., what can you get away with?)",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#robustness-of-regression-assumptions",
    "href": "foundation-chapter10.html#robustness-of-regression-assumptions",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Robustness of Regression Assumptions",
    "text": "Robustness of Regression Assumptions\n\nLinearity\n\nParameter estimates will be misleading if a straight-line model is inadequate or fits only part of the data.\nPredictions will be biased, and confidence intervals (CIs) will not appropriately reflect uncertainty.\nRemedy: Consider adding polynomial terms (quadratic or cubic) to improve model fit.\n\n\n\nNormality\n\nTransformations that correct for normality often address constant variance as well.\nEffects of non-normality:\n\nCoefficient estimates and standard errors: Robust, except with many outliers and small sample sizes.\nConfidence intervals: Affected primarily by outliers (long tails).\nPrediction intervals: Sensitive to non-normality due to reliance on normal distributions.\n\n\n\n\nConstant Variance (Homoscedasticity)\n\nFor every value of \\(x\\), the spread of \\(y\\) should be the same.\nLeast squares estimates remain unbiased with slight violations.\nLarge violations can cause standard errors to underestimate or overestimate uncertainty, leading to misleading confidence intervals and hypothesis tests.\nRemedy: Large violations should be corrected using a transformation.\n\n\n\nIndependence\n\nParameter estimates: Not affected by violations.\nStandard errors: Affected significantly. Violations can lead to underestimated standard errors, which inflate t-statistics and make it easier to incorrectly reject the null hypothesis.\nRemedy: Serial and cluster effects require different models.\n\n\n\nHow Much Deviation Is Acceptable?\n\nSmall violations of assumptions generally do not invalidate regression results.\nHowever, large deviations can lead to inaccurate estimates, especially for standard errors, confidence intervals, and p-values.\nTransformations can often correct violations and improve interpretability.\nOnly severe departures from linearity or normality (e.g., due to outliers) typically require alternative methods.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#influential-and-outlying-observations",
    "href": "foundation-chapter10.html#influential-and-outlying-observations",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Influential and Outlying Observations",
    "text": "Influential and Outlying Observations\n\nKey Concepts\n\nInfluential observations: These are points that, if added or removed, substantially change the regression line (e.g., the slope or intercept).\nLeverage: A measure of how far an observation’s \\(x\\) value is from the mean of all \\(x\\) values (\\(\\bar{x}\\)).\n\nPoints farther from \\(\\bar{x}\\) have higher leverage.\nMathematically, leverage increases with the squared distance from \\(x_i\\) to \\(\\bar{x}\\), relative to the total sum of squares in \\(x\\). This is closely related to how many standard deviations \\(x_i\\) is from the mean.\nLeverage is based on the \\(x\\) values alone; it does not depend on \\(y\\).\n\n\n\n\nImpact of Outliers\n\nLow leverage, low influence: Minimal effect on estimates.\nHigh leverage, low influence: Far from most data but consistent with the trend; minimal effect on the correlation, standard errors, and regression estimates.\nHigh leverage, high influence: Can distort results by pulling the regression line toward the outlier, resulting in different parameter estimates.\n\n\n\nDetecting Influential Observations\n\nLeverage Statistic, \\(h_{ii}\\)\n\nMeasures how far the \\(x\\) value for an observation is from the mean \\(\\bar{x}\\), in relation to the total spread of \\(x\\) values. Larger values of \\(h_{ii}\\) indicate higher leverage.\nAn observation is considered to have high leverage if \\(h_{ii} &gt; \\dfrac{2p}{n}\\), where \\(p\\) is the number of parameters in the model (including the intercept).\nFormula: \\[\nh_{ii} = \\frac{1}{n} + \\frac{(X_i - \\bar{X})^2}{\\sum_{j=1}^{n} (X_j - \\bar{X})^2}\n\\] or \\[\nh_{ii} = \\frac{1}{n - 1} \\left[ \\frac{(X_i - \\bar{X})}{s_x} \\right]^2 + \\frac{1}{n}\n\\]",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#types-of-residuals",
    "href": "foundation-chapter10.html#types-of-residuals",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Types of Residuals",
    "text": "Types of Residuals\n\nStandardized: \\(e_i / \\text{RMSE}\\)\nStudentized: \\(e_i / \\sqrt{\\text{MSE} \\cdot (1 - h_{ii})}\\)\nStudentized-deleted (R-student):\n\nRemove an observation, recalculate the regression, and compute the studentized residual.\nThe standard deviation is calculated without the point in question.\nLarge residual values indicate potentially influential points.\nFormula: \\[\n\\text{RSTUDENT} = \\frac{\\text{res}_i}{s_i \\sqrt{1 - h_i}}\n\\]\n\nWhy different types? All three aim to stabilize variance so that residuals are comparable, but they differ in how they estimate the error term:\n\nStandardized: Uses a single overall RMSE.\nStudentized: Adjusts for leverage via \\((1 - h_{ii})\\).\nR-student: Recalculates without the observation for more accurate influence detection.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#leave-one-out-statistics",
    "href": "foundation-chapter10.html#leave-one-out-statistics",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Leave-One-Out Statistics",
    "text": "Leave-One-Out Statistics\nThese measures assess the impact of each observation by considering the model fit when that observation is omitted.\nLet \\(\\hat{Y}_{i(i)}\\) be the predicted value of \\(Y_i\\) when the \\(i\\)-th observation is left out of the regression model.\n\nPRESS (Predicted Residual Sum of Squares)\n\\[\n\\text{PRESS}_p = \\sum_{i=1}^n \\left(Y_i - \\hat{Y}_{i(i)}\\right)^2 = \\sum e_{i(i)}^2\n\\]\n\nSmaller PRESS values indicate better-fitting models.\n\n\n\nCook’s Distance (\\(D_i\\))\n\nCombines information on residual size and leverage, and is equivalent to comparing predictions from the full model to those from a leave-one-out model: \\[\nD_i = \\sum_{i=1}^n \\frac{\\left(\\hat{Y}_{i(i)} - \\hat{Y}_i\\right)^2}{p \\cdot \\text{MSE}} = \\frac{1}{p} (\\text{studres}_i)^2 \\left[\\frac{h_i}{1 - h_i}\\right]\n\\]\nHere, \\(p\\) is the number of parameters in the model (including the intercept).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#durbin-watson-test-for-independence",
    "href": "foundation-chapter10.html#durbin-watson-test-for-independence",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Durbin-Watson Test for Independence",
    "text": "Durbin-Watson Test for Independence\n\\[\nd = \\frac{\\sum_{i=1}^n (e_i - e_{i-1})^2}{\\sum_{i=1}^n e_i^2}\n\\]\n\nValues near 0 indicate positive correlation; values near 4 indicate negative correlation. The distribution is symmetric about 2.\nAvailable in R and SAS.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#residual-types-summary",
    "href": "foundation-chapter10.html#residual-types-summary",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Residual Types Summary",
    "text": "Residual Types Summary\n\n\n\n\n\n\n\n\nName\nExpression\nUse\n\n\n\n\nResidual\n\\(e_i = y_i - \\hat{y}_i\\)\nResidual plots\n\n\nStandardized residual\n\\(r_i = \\frac{e_i}{s \\sqrt{1 - h_{ii}}}\\)\nIdentify outliers\n\n\nStudentized residual\n\\(t_i = \\frac{e_i}{s_{(i)} \\sqrt{1 - h_{ii}}}\\)\nTest outlying \\(Y\\) values\n\n\nDeleted residual\n\\(e_{i(i)} = y_i - \\hat{y}_{i(i)} = \\frac{e_i}{1 - h_{ii}}\\)\nCalculate PRESS\n\n\n\n\nFor studentized residuals, at \\(\\alpha = 0.05\\) we expect about 5% to be greater than 2 or less than –2.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#residual-diagnostics-panel",
    "href": "foundation-chapter10.html#residual-diagnostics-panel",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Residual Diagnostics Panel",
    "text": "Residual Diagnostics Panel\n\n\n\nResidual diagnostics panel. A collection of plots used to assess regression assumptions and identify potential problems. Several plots use standardized, studentized, or studentized-deleted (R-student) residuals to improve comparability across observations. These include: residuals vs. predicted values (checking for nonlinearity or heteroscedasticity), R-studentized residuals vs. predicted values (highlighting outliers), and R-studentized residuals vs. leverage (identifying high-leverage outliers). Other diagnostics include the normal QQ plot and histogram of residuals (assessing normality), predicted values vs. observed values (evaluating fit), Cook’s distance by observation (identifying influential points by combining leverage and residual size), and QQ plots of fitted means and residuals. Together, these diagnostics help evaluate model adequacy and guide possible remedies.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#graphical-assessment-of-residuals",
    "href": "foundation-chapter10.html#graphical-assessment-of-residuals",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Graphical Assessment of Residuals",
    "text": "Graphical Assessment of Residuals\n\n\n\n\n\n\n\n\nPattern\nPotential Issue\nSolution\n\n\n\n\nLinear means, constant SD\nModel fits well\nNo action needed\n\n\nCurved means, equal SD\nNonlinearity\nTransform \\(X\\)\n\n\nCurved means, increasing SD\nNonlinearity + heteroscedasticity\nTransform \\(Y\\)\n\n\nSkewed residuals\nNon-normality\nCan still model the mean, but CIs/PIs may be unreliable. Consider transformations.\n\n\nLinear means, increasing SD\nHeteroscedasticity\nUse weighted regression",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#remedies-for-violations",
    "href": "foundation-chapter10.html#remedies-for-violations",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Remedies for Violations",
    "text": "Remedies for Violations\n\nNonlinearity\n\nAdd more complexity to the model.\nApply a transformation to \\(X\\).\nAdd another variable, which may also help nonconstant variance.\n\n\n\nNonconstant Variance\n\nTransform \\(Y\\).\nUse weighted least squares to down-weight observations with larger variance so they don’t influence the regression model as much as observations closer to the line.\n\n\n\nCorrelated Errors\n\nOften detected via residual plots, where you may see small values follow small values, and large follow large.\nUse time series or spatial models for serial effects within data.\n\n\n\nOutliers\n\nUse robust regression.\nCheck for data entry or other errors. Only delect observations in this situation.\n\n\n\nNon-normality\n\nUsually fixed via the above methods, so wait to fix until last.\nConsider transforming the data.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#residual-patterns-and-suggested-remedies",
    "href": "foundation-chapter10.html#residual-patterns-and-suggested-remedies",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Residual Patterns and Suggested Remedies",
    "text": "Residual Patterns and Suggested Remedies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual patterns to watch for. Each panel shows a scatter with bin-wise means and standard deviations (dark line and bars). Patterns suggest remedies: (a) compare the distribution of \\(Y\\) across \\(X\\); (b) curvature may call for transforming \\(X\\); (c) symmetric curvature suggests adding a quadratic term; (d) fan-shaped spread indicates transforming \\(Y\\); (e) right-skewed residuals should be reported; (f) variance that changes with \\(X\\) motivates weighted regression.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#nonconstant-variance-and-transformations",
    "href": "foundation-chapter10.html#nonconstant-variance-and-transformations",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Nonconstant Variance and Transformations",
    "text": "Nonconstant Variance and Transformations\nWhen the spread of residuals changes with fitted values, transforming the response variable \\(Y\\) can often stabilize the variance.\n\nTransformation Recommendations\n\nLog transformation\nSquare root transformation\nOther transformations (e.g., reciprocal)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamples of variance-stabilizing transformations. When the spread of residuals changes with fitted values, transforming the response variable \\(Y\\) can help stabilize variance. The panels illustrate three common recommendations: (a) a log transformation for decreasing variance, (b) a square root transformation for increasing variance, and (c) a reciprocal transformation for variance proportional to the mean. These transformations change the interpretation of model coefficients, and results may need to be back-transformed for reporting.\n\n\n\nInterpretation Considerations\n\nAdjust interpretation to the audience, transformation type, and variables transformed.\nBack-transform results when necessary.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#log-transformations-types-and-interpretations",
    "href": "foundation-chapter10.html#log-transformations-types-and-interpretations",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Log Transformations: Types and Interpretations",
    "text": "Log Transformations: Types and Interpretations\nLog transformations can be highly effective and may yield more interpretable regression results.\nThe three most common forms are log-linear, linear-log, and log-log models.\n\n\n\n\n\n\nUseful Properties for Log Transformations\n\n\n\n\nIf \\(X \\sim N(\\mu, \\sigma)\\), then \\(\\text{mean}(X) = \\text{median}(X)\\)\n\n\\(\\log(\\text{median}(X)) = \\text{median}(\\log(X))\\)\n\n\\(a^{\\log_a y} = y\\) for \\(a &gt; 0\\)\n\n\\(\\log A - \\log B = \\log\\left(\\frac{A}{B}\\right)\\)\n\n\\(a \\log b = \\log b^a\\)\n\n\n\n\nLog-Linear Transformation (Log on Response)\n\\[\n\\log(\\hat{Y}_i) = \\beta_0 + \\beta_1 X_i\n\\]\n\nConditional on \\(X\\), assume \\(\\log(Y)\\) is normally distributed.\nMedian response: \\[\n\\text{Median}(Y \\mid X) = e^{\\beta_0 + \\beta_1 X}\n\\]\nThe mean of the logged response is linearly related to \\(X\\).\nMultiplicative interpretation:\nA one-unit increase in \\(X\\) changes the median of \\(Y\\) by a factor of \\(\\exp(\\beta_1)\\): \\[\n\\frac{\\text{Median}(Y \\mid X+1)}{\\text{Median}(Y \\mid X)} = \\exp(\\beta_1)\n\\]\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nDerivation: From log response to median interpretation\n\nStart from the conditional mean: \\[\n\\mu\\{\\log(Y) \\mid X\\} = \\beta_0 + \\beta_1 X\n\\]\nIf \\(\\log(Y) \\mid X\\) is normal, then mean equals median: \\[\n\\text{Median}\\{\\log(Y) \\mid X\\} = \\beta_0 + \\beta_1 X\n\\]\nUse \\(\\log(\\text{Median}(Y)) = \\text{Median}(\\log Y)\\): \\[\n\\log(\\text{Median}(Y) \\mid X) = \\beta_0 + \\beta_1 X\n\\]\nExponentiate both sides: \\[\n\\text{Median}(Y) \\mid X = e^{\\beta_0 + \\beta_1 X}\n\\]\nFor \\(X+1\\): \\[\n\\text{Median}(Y) \\mid X+1 = e^{\\beta_0 + \\beta_1(X+1)}\n\\]\nTake the ratio: \\[\n\\frac{\\text{Median}(Y) \\mid X+1}{\\text{Median}(Y) \\mid X}\n= \\frac{e^{\\beta_0 + \\beta_1 (X+1)}}{e^{\\beta_0 + \\beta_1 X}}\n= \\frac{e^{\\beta_0} e^{\\beta_1 (X+1)}}{e^{\\beta_0} e^{\\beta_1 X}}\n= \\frac{e^{\\beta_1 X} e^{\\beta_1}}{e^{\\beta_1 X}}\n= e^{\\beta_1}\n\\]\n\n\n\n\nInterpretation: A one unit increase in \\(X\\) is associated with an \\(e^{\\beta_1}\\) multiplicative change in the median of \\(Y\\).\n\n\nLinear-Log Transformation (Log on Explanatory Variable)\n\\[\n\\hat{Y}_i = \\beta_0 + \\beta_1 \\log (X_i)\n\\]\n\nInterpretation depends on the log base:\n\nDoubling \\(X\\) changes \\(Y\\) by \\(\\beta_1 \\log(2)\\) units on average.\nA tenfold increase changes \\(Y\\) by \\(\\beta_1 \\log(10)\\) units.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nDerivation: Mean change after doubling \\(X\\)\n\nStart from: \\[\n\\mu\\{Y \\mid \\log(X)\\} = \\beta_0 + \\beta_1 \\log(X)\n\\]\nFor \\(X\\) replaced by \\(2X\\): \\[\n\\mu\\{Y \\mid \\log(2X)\\} = \\beta_0 + \\beta_1 \\log(2X)\n\\]\nDifference in means: \\[\n\\mu\\{Y \\mid \\log(2X)\\} - \\mu\\{Y \\mid \\log(X)\\} = \\big[ \\beta_0 + \\beta_1 \\log(2X) \\big] - \\big[ \\beta_0 + \\beta_1 \\log(X) \\big]\n\\]\nSimplify: \\[\n= \\beta_1 \\left[\\log(2X) - \\log(X)\\right] = \\beta_1 \\log\\left( \\frac{2X}{X} \\right) = \\beta_1 \\log(2)\n\\]\n\n\n\n\nInterpretation:\nA doubling of \\(X\\) is associated with a \\(\\beta_1 \\log(2)\\) unit change in the mean of \\(Y\\).\n\n\nLog-Log Transformation (Both Variables Logged)\n\\[\n\\log (\\hat{Y}_i) = \\beta_0 + \\beta_1 \\log (X_i)\n\\]\n\nModels a multiplicative effect:\n\nDoubling \\(X\\) changes the median of \\(Y\\) by a factor of \\(2^{\\beta_1}\\).\nA tenfold increase changes the median of \\(Y\\) by \\(10^{\\beta_1}\\).\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nDerivation: Effect of doubling \\(X\\)\n\nStart from: \\[\n\\mu \\{\\log(Y) \\mid \\log(X)\\} = \\beta_0 + \\beta_1 \\log(X)\n\\]\nIf \\(\\log(Y)\\mid X\\) is normal, then mean equals median: \\[\n\\text{Median}\\{\\log(Y) \\mid \\log(X)\\} = \\beta_0 + \\beta_1 \\log(X)\n\\]\nUse \\(\\log(\\text{Median}(Y)) = \\text{Median}(\\log Y)\\): \\[\n\\log(\\text{Median}(Y) \\mid \\log(X)) = \\beta_0 + \\beta_1 \\log(X)\n\\]\nExponentiate: \\[\ne^{\\log\\big(\\text{Median}(Y) \\mid \\log(X)\\big)} = e^{\\beta_0 + \\beta_1 \\log(X)}\n\\]\nSimplify: \\[\n\\text{Median}(Y) \\mid \\log(X) = e^{\\beta_0 + \\beta_1 \\log(X)}\n\\]\nFor \\(X\\) replaced by \\(2X\\): \\[\n\\text{Median}(Y) \\mid \\log(2X) = e^{\\beta_0 + \\beta_1 \\log(2X)}\n\\]\nRatio: \\[\n\\frac{\\text{Median}(Y) \\mid \\log(2X)}{\\text{Median}(Y) \\mid \\log(X)} = \\frac{e^{\\beta_0 + \\beta_1 \\log(2X)}}{e^{\\beta_0 + \\beta_1 \\log(X)}} = \\frac{e^{\\beta_0}e^{\\beta_1 \\log(2X)}}{e^{\\beta_0}e^{\\beta_1 \\log(X)}} = \\frac{e^{\\beta_1 \\log(2X)}}{e^{\\beta_1 \\log(X)}} = e^{\\beta_1 \\log(2X) - \\beta_1 \\log(X)}\n\\]\nSimplify: \\[\n= e^{\\beta_1[\\log(2X) - \\log(X)]} = e^{\\beta_1 \\log\\left(\\frac{2X}{X}\\right)} = e^{\\beta_1 \\log(2)} = 2^{\\beta_1}\n\\]\n\n\n\n\nInterpretation:\nA doubling of \\(X\\) is associated with a \\(2^{\\beta_1}\\) multiplicative change in the median of \\(Y\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#summary-table-interpretation-by-model-type",
    "href": "foundation-chapter10.html#summary-table-interpretation-by-model-type",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Summary Table: Interpretation by Model Type",
    "text": "Summary Table: Interpretation by Model Type\n\n\n\n\n\n\n\n\n\nModel Type\n\n\nEquation\n\n\nInterpretation\n\n\n\n\n\n\nLog-linear\n\n\n\\(\\log Y = \\beta_0 + \\beta_1 X\\)\n\n\n1 unit increase in \\(X\\) \\(\\rightarrow\\) \\(e^{\\beta_1}\\) change in median \\(Y\\)\n\n\n\n\nLinear-log\n\n\n\\(Y = \\beta_0 + \\beta_1 \\log X\\)\n\n\nDoubling \\(X\\) \\(\\rightarrow\\) \\(\\beta_1 \\log(2)\\) change in mean \\(Y\\)\n\n\n\n\nLog-log\n\n\n\\(\\log Y = \\beta_0 + \\beta_1 \\log X\\)\n\n\nDoubling \\(X\\) \\(\\rightarrow\\) ×\\(2^{\\beta_1}\\) change in median \\(Y\\)\n\n\n\n\nNote: Logging \\(Y\\) generally shifts interpretation from the mean to the median.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter10.html#formal-test-for-lack-of-fit",
    "href": "foundation-chapter10.html#formal-test-for-lack-of-fit",
    "title": "Regression Diagnostics and Model Refinement",
    "section": "Formal Test for Lack of Fit",
    "text": "Formal Test for Lack of Fit\n\nUse: Requires replicated \\(X\\) values with different \\(Y\\) observations.\nAssumptions:\n\nNormality of \\(Y|X\\)\nIndependence of \\((X, Y)\\) pairs\nConstant variance of \\(Y\\) across all values of \\(X\\)\n\n\n\nProcedure\n\nFit a linear regression model, obtain \\(SS_{\\text{res}_{LR}}\\).\nFit a separate means model (ANOVA), obtain \\(SS_{\\text{res}_{SM}}\\).\nNull hypothesis: Linear model fits.\nAlternative: Linear model is inadequate, i.e., the variability cannot be explained by the model.\nCompute: \\[\nF = \\frac{(SS_{\\text{res}_{LR}} - SS_{\\text{res}_{SM}}) / (\\text{df}_{LR} - \\text{df}_{SM})}{\\text{MSE}_{SM}}\n\\]\n\n\nGuidance: Even a good-fitting model may not be the best model.\n\nPrinciple of parsimony: Use the simplest model that explains the most variation.\n\n\n\n\nStrategy\n\nANOVA compares the equal means model to the linear model.\nIf the lack of fit test fails to reject, the linear model is adequate and comparable with the best fitting model.\n\n\n\nExample in SAS\nThe following SAS code fits both a simple linear regression model and a separate means model (one mean per iron content level). The ANOVA tables from each model are then used to compute the extra-sum-of-squares (lack-of-fit) test manually.\n\n\nCode\n/* linear regression model */\nproc glm data = IronCor;\nmodel Corrosion = IronContent / solution;\nrun;\n\n/* separate means model (7 groups) */\nproc glm data = IronCor;\nclass IronContent;\nmodel Corrosion = IronContent;\nrun;\n\ndata critval;\ncriticalValue = finv(0.95, 5, 6);\nrun;\nproc print data = critval;\nrun;\n\ndata pval;\npValue = 1-probf(9.28, 5, 6);\nrun;\nproc print data = pval;\nrun;\n\n\n\n\n\n\nBoxplot showing variation in corrosion measurements at each iron content level, used in assessing model fit.\n\n\n\n\n\nFit plot with 95% confidence and prediction intervals for the linear regression model of corrosion versus iron content.\n\n\n\n\nANOVA output from SAS for the linear regression model (left) and separate means model (right) used in the lack-of-fit test.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra-sum-of-squares table showing the manual calculation of the lack-of-fit test from SAS output.\n\n\n\n\nSource\nDF\nSS\nMS\nF\nPr &gt; F\n\n\n\n\nModel\n5\n91.07\n18.21\n9.28\n0.0009\n\n\nError / Full (SMM)\n6\n11.78\n1.96\n\n\n\n\nTotal / Reduced (LRM)\n11\n102.85\n\n\n\n\n\n\n\n\n\\(H_0\\): Linear regression model fits well (no lack of fit).\n\\(H_a\\): Separate means model fits better (lack of fit).\n\nConclusion: The lack-of-fit test compares the linear regression model (reduced) to the separate means model (full). There is strong evidence, to suggest the linear regression model lacks fit with respect to the separate means model, p-value = 0.0009.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regression Diagnostics and Model Refinement</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html",
    "href": "foundation-chapter11.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#objectives",
    "href": "foundation-chapter11.html#objectives",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Learn how to obtain a multiple linear regression (MLR) model.\nUnderstand the meaning of regression coefficients.\nIdentify the types of data structures that can be analyzed with multiple regression.\nVisualize and interpret multidimensional relationships among qualitative and quantitative variables.\nDetermine when and how to include interaction terms in a model.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#adding-a-third-variable",
    "href": "foundation-chapter11.html#adding-a-third-variable",
    "title": "Multiple Linear Regression",
    "section": "Adding a Third Variable",
    "text": "Adding a Third Variable\n\nWhen adding \\(X_2\\) to the model, the relationship between \\(X_1\\) and \\(Y\\) may:\n\nRemain unchanged, indicating that \\(X_2\\) is unnecessary.\nBecome stronger, weaker, or change direction.\nVary across different values of \\(X_2\\), suggesting an interaction effect.\n\nTypically, explanatory variables \\(X_1\\) and \\(X_2\\) are correlated.\n\nIdeally, there should be no correlation.\nCorrelation introduces changes in the estimated response when additional variables are included.\nVariables should only be added to improve model explanation, not simply to increase fit.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#exploratory-approaches-to-adding-a-third-variable",
    "href": "foundation-chapter11.html#exploratory-approaches-to-adding-a-third-variable",
    "title": "Multiple Linear Regression",
    "section": "Exploratory Approaches to Adding a Third Variable",
    "text": "Exploratory Approaches to Adding a Third Variable\n\nScatterplots:\n\nPlot each pair: \\((X_1, X_2, Y)\\)\nIdentify potential linear relationships.\nExplanatory variables can be weakly correlated but should have a strong linear relationship with the response variable.\n\nPearson correlation:\n\nCalculate correlation between all pairs of variables.\nCorrelation between explanatory variables should ideally be weaker than each variable’s correlation with the response variable.\nIf the correlation between explanatory variables is too strong, they may be redundant, indicating multicollinearity.\n\nMulticollinearity:\n\nOccurs when explanatory variables are highly correlated, violating the independence assumption.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#regression-equations-with-two-predictors",
    "href": "foundation-chapter11.html#regression-equations-with-two-predictors",
    "title": "Multiple Linear Regression",
    "section": "Regression Equations with Two Predictors",
    "text": "Regression Equations with Two Predictors\n\nPopulation equation: \\(Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2\\)\nInterpreting slopes:\n\nThe coefficient of an explanatory variable in an MLR model does not usually equal its coefficient in a simple linear regression (SLR), except when \\(X_2\\) is completely independent of \\(X_1\\).\nIn MLR, the coefficient represents the effect of changing the value of a predictor while holding all other variables constant.\nIn SLR, the coefficient represents the effect of changing the value of a predictor without accounting for other variables.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#benefits-of-adding-variables",
    "href": "foundation-chapter11.html#benefits-of-adding-variables",
    "title": "Multiple Linear Regression",
    "section": "Benefits of Adding Variables",
    "text": "Benefits of Adding Variables\n\nImproves response prediction.\nIncreases the proportion of variance explained by the model.\nProvides a more realistic description when a single explanatory variable is inadequate to explain the response.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#incorporating-categorical-dummy-explanatory-variables",
    "href": "foundation-chapter11.html#incorporating-categorical-dummy-explanatory-variables",
    "title": "Multiple Linear Regression",
    "section": "Incorporating Categorical (Dummy) Explanatory Variables",
    "text": "Incorporating Categorical (Dummy) Explanatory Variables\n\nBest practice for a two-category variable:\n\nCode one category as 0 (the reference group) and the other as 1 (the comparison group).\nThe reference category’s mean corresponds to the intercept.\nThe coefficient of the indicator variable represents the average difference between the two groups.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#approaches-to-handling-a-third-variable-with-two-categories",
    "href": "foundation-chapter11.html#approaches-to-handling-a-third-variable-with-two-categories",
    "title": "Multiple Linear Regression",
    "section": "Approaches to Handling a Third Variable with Two Categories",
    "text": "Approaches to Handling a Third Variable with Two Categories\n\nSLR: Both categories are combined.\nParallel lines model: Different intercepts, same slope.\nInteraction model: Different intercepts and slopes.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#examples-of-multiple-linear-regression-models",
    "href": "foundation-chapter11.html#examples-of-multiple-linear-regression-models",
    "title": "Multiple Linear Regression",
    "section": "Examples of Multiple Linear Regression Models",
    "text": "Examples of Multiple Linear Regression Models\nThe following equations illustrate several ways that explanatory variables can enter a multiple linear regression model.\n\nTwo predictors, additive model:\n\\[\n\\mu(Y \\mid X_1, X_2) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2\n\\] The mean of \\(Y\\) is modeled as a linear function of \\(X_1\\) and \\(X_2\\), each contributing additively.\nOne predictor with a quadratic term:\n\\[\n\\mu(Y \\mid X_1) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_1^2\n\\] Includes a squared term for \\(X_1\\) to capture curvature in the relationship.\nTwo predictors with an interaction term:\n\\[\n\\mu(Y \\mid X_1, X_2) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 (X_1 X_2)\n\\] Allows the effect of one predictor to depend on the value of the other.\nLogarithmic transformation of predictors:\n\\[\n\\mu(Y \\mid X_1, X_2) = \\beta_0 + \\beta_1 \\log(X_1) + \\beta_2 \\log(X_2)\n\\] Models multiplicative relationships between \\(X_1\\), \\(X_2\\), and \\(Y\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#assumption-of-constant-variance",
    "href": "foundation-chapter11.html#assumption-of-constant-variance",
    "title": "Multiple Linear Regression",
    "section": "Assumption of Constant Variance",
    "text": "Assumption of Constant Variance\n\nConstant variance assumption: \\(\\text{Var}\\{Y \\mid X_1, X_2\\} = \\sigma^2\\)\nThe variance of \\(Y\\) remains the same across all values of \\(X_1\\) and \\(X_2\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#interpretation-of-regression-coefficients",
    "href": "foundation-chapter11.html#interpretation-of-regression-coefficients",
    "title": "Multiple Linear Regression",
    "section": "Interpretation of Regression Coefficients",
    "text": "Interpretation of Regression Coefficients\n\nThe regression surface of an MLR model with two explanatory variables is planar:\n\n\\(\\beta_0\\) represents the height of the plane when both predictors are zero.\n\\(\\beta_1\\) represents the slope along \\(X_1\\), holding \\(X_2\\) constant.\n\\(\\beta_2\\) represents the slope along \\(X_2\\), holding \\(X_1\\) constant.\n\nThe effect of an explanatory variable is the change in mean response associated with a one-unit increase in that variable, while keeping all other explanatory variables fixed:\n\nEffect of \\(X_1\\): \\(\\mu(Y \\mid X_1 + 1, X_2) - \\mu(Y \\mid X_1, X_2) = \\beta_1\\)\nEffect of \\(X_2\\): \\(\\mu(Y \\mid X_1, X_2 + 1) - \\mu(Y \\mid X_1, X_2) = \\beta_2\\)\nThe coefficient of each explanatory variable measures its effect at fixed values of the other.\nIn the planar model, effects are the same at all levels of the explanatory variable.\n\n\n\nIllustration of Regression Plane\n\n\n\nInterpretation of regression coefficients in an additive multiple linear regression model with two explanatory variables. The planar surface represents the fitted model \\(\\hat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2\\). Each bell curve shows the distribution of \\(Y\\) at a fixed \\(X_1\\) and \\(X_2\\) value. The slope \\(\\beta_1\\) is the change in mean response per unit increase in \\(X_1\\), holding \\(X_2\\) constant (illustrated by the gray line through the back row of means). The slope \\(\\beta_2\\) is the change in mean response per unit increase in \\(X_2\\), holding \\(X_1\\) constant (illustrated by the purple connector between two bells at the same \\(X_1\\)).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#parallel-lines-regression-model",
    "href": "foundation-chapter11.html#parallel-lines-regression-model",
    "title": "Multiple Linear Regression",
    "section": "Parallel Lines Regression Model",
    "text": "Parallel Lines Regression Model\n\nIndicator (dummy) variable:\n\nRepresents two levels of a categorical explanatory variable.\n\nTakes values 0 (reference group, attribute absent) or 1 (comparison group, attribute present).\n\nThe fit is the same if you reverse the levels of the indicator.\n\n\nRegression model for an indicator variable:\n\nWhen \\(\\text{pred}_2 = 0\\):\n\\[\n\\mu(Y \\mid X_1, \\text{pred}_2 = 0) = \\beta_0 + \\beta_1 X_1 + \\beta_2(0) = \\beta_0 + \\beta_1 X_1\n\\]\nWhen \\(\\text{pred}_2 = 1\\):\n\\[\n\\mu(Y \\mid X_1, \\text{pred}_2 = 1) = \\beta_0 + \\beta_1 X_1 + \\beta_2(1) = (\\beta_0 + \\beta_2) + \\beta_1 X_1\n\\]\nInterpretation:\n\nSlope: \\(\\beta_1\\) (same for both categories).\n\nIntercept: Adjusted by \\(\\beta_2\\) between the two groups.\n\nIntercept where \\(\\text{pred}_2 = 0\\) is \\(\\beta_0\\), and intercept where \\(\\text{pred}_2 = 1\\) is \\(\\beta_0 + \\beta_2\\).\n\nThe two lines are separated by a constant vertical distance of \\(\\beta_2\\).\n\nThe coefficient of the indicator variable is the difference between the mean response for the indicated category (1) and the reference category (0), at fixed values of the other explanatory variables.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#indicator-variables-for-categorical-variables-with-3-categories",
    "href": "foundation-chapter11.html#indicator-variables-for-categorical-variables-with-3-categories",
    "title": "Multiple Linear Regression",
    "section": "Indicator Variables for Categorical Variables with 3+ Categories",
    "text": "Indicator Variables for Categorical Variables with 3+ Categories\n\nFor a categorical variable with \\(k\\) levels, \\(k - 1\\) indicator variables are needed.\nThe reference category has no indicator variable.\nA shorthand notation capitalizes the categorical variable name to represent the set of indicator variables (e.g., \\(\\mu\\{\\text{response} \\mid \\text{pred}_1, \\text{PRED}_2\\}\\)).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#product-term-for-interaction",
    "href": "foundation-chapter11.html#product-term-for-interaction",
    "title": "Multiple Linear Regression",
    "section": "Product Term for Interaction",
    "text": "Product Term for Interaction\n\nInteraction occurs when the effect of one explanatory variable depends on another.\nAn interaction term is the product of two explanatory variables.\nExample: Two-level indicator variable:\n\nGeneral model: \\(\\mu(Y \\mid X_1, X_2) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 (X_1 \\times X_2)\\)\nWhen \\(X_2 = 0\\): \\(\\mu(Y \\mid X_1, X_2 = 0) = \\beta_0 + \\beta_1 X_1\\)\nWhen \\(X_2 = 1\\): \\(\\mu(Y \\mid X_1, X_2 = 1) = \\beta_0 + \\beta_2 + (\\beta_1 + \\beta_3)X_1\\)\nHere, \\((\\beta_1 + \\beta_3)\\) is the slope for \\(X_1\\) when \\(X_2 = 1\\).\nInterpretation (separate slopes model):\n\n\\(\\beta_1\\): Slope at the reference level.\n\\(\\beta_3\\): Difference in slopes between groups.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#example-gender-salary-and-years-model",
    "href": "foundation-chapter11.html#example-gender-salary-and-years-model",
    "title": "Multiple Linear Regression",
    "section": "Example: Gender, Salary, and Years Model",
    "text": "Example: Gender, Salary, and Years Model\nParameter Estimates\n\n\n\nVariable\nDF\nEst\nSE\nt\nPr &gt; |t |\n\n\n\n\nIntercept\n1\n34.19\n1.22\n28.04\n&lt;0.0001\n\n\nGender\n1\n3.35\n1.46\n2.29\n0.0263\n\n\nYears\n1\n1.44\n-1.33\n10.83\n&lt;0.0001\n\n\n\nThe Gender coefficient (3.35) represents the adjustment to the intercept for the reference category (males vs. females).\nGender (Indicator Variable)\n\n0 = Female (reference group)\n\n1 = Male (comparison group)\n\nModel\n\\[\n\\text{Salary} = \\beta_0 + \\beta_1 \\cdot \\text{Years} + \\beta_2 \\cdot \\text{Gender}\n\\]\nAll constants to the left:\n\\[\n\\text{Salary} = \\left( \\beta_0 + \\beta_2 \\cdot \\text{Gender} \\right ) + \\beta_1 \\cdot \\text{Years}\n\\]\n\nFemale intercept: \\(\\beta_0 + \\beta_2 \\cdot 0 = \\beta_0\\)\nMale intercept: \\(\\beta_0 + \\beta_2 \\cdot 1 = \\beta_0 + \\beta_2\\)\n\nSlope for Years: \\(\\beta_1\\) (same for both groups)\n\nPredicted Salary Equations\nParallel lines with different intercepts:\n\nFemale: \\(\\text{Salary} = 34.19 + 1.44 \\cdot \\text{Years}\\)\nMale: \\(\\text{Salary} = (34.19 + 3.35) + 1.44 \\cdot \\text{Years} = 37.54 + 1.44 \\cdot \\text{Years}\\)\n\n\n\n\nParallel lines regression model for salary by gender, controlling for years of experience. The vertical distance between the two lines \\((\\Delta = \\beta_2 = 3.35)\\) represents the estimated average difference in salary between males and females for the same number of years of experience.\n\n\nInterpretation: After accounting for years of experience, the estimated difference in mean salaries between males and females is $3,350, with males earning more on average.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter11.html#example-gender-years-interaction-model",
    "href": "foundation-chapter11.html#example-gender-years-interaction-model",
    "title": "Multiple Linear Regression",
    "section": "Example: Gender × Years Interaction Model",
    "text": "Example: Gender × Years Interaction Model\nParameter Estimates\n\n\n\nVariable\nDF\nEst\nSE\nt\nPr &gt; |t |\n\n\n\n\nIntercept\n1\n35.12\n1.67\n20.97\n&lt;0.0001\n\n\nYears\n1\n1.24\n0.28\n4.38\n&lt;0.0001\n\n\nGender\n1\n1.94\n2.29\n0.85\n0.4021\n\n\nGender × Years\n1\n0.26\n0.08\n3.19\n0.0025\n\n\n\nGender coding (indicator variable)\n\n0 = Female (reference group)\n\n1 = Male (comparison group)\n\nModel\n\\[\n\\mu(\\text{Salary} \\mid \\text{Years}, \\text{Gender})\n= \\beta_0 + \\beta_1 \\cdot \\text{Years} + \\beta_2 \\cdot \\text{Gender}\n+ \\beta_3 \\cdot (\\text{Gender} \\times \\text{Years})\n\\]\nGroup‑specific equations\n\nFemale (\\(\\text{Gender}=0\\)):\n\\[\n\\mu(\\text{Salary} \\mid \\text{Years}, 0) = \\beta_0 + \\beta_1 \\cdot \\text{Years}\n= 35.12 + 1.24 \\cdot \\text{Years}\n\\]\nMale (\\(\\text{Gender}=1\\)):\n\\[\n\\mu(\\text{Salary} \\mid \\text{Years}, 1)\n= (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3)\\cdot \\text{Years}\n\\] \\[\n= (35.12 + 1.94) + (1.24 + 0.26)\\cdot \\text{Years}\n= 37.06 + 1.50 \\cdot \\text{Years}\n\\]\n\nInterpretation\n\nIntercept difference at 0 years (male vs. female): \\(\\beta_2 = 1.94\\).\n\nSlope difference (male vs. female): \\(\\beta_3 = 0.26\\).\n\nVertical difference at a fixed number of years \\(x\\):\n\\(\\Delta(x) = \\beta_2 + \\beta_3 x\\).\nFor example, at 10 years, \\(\\Delta(10) = 1.94 + 0.26(10) = 4.54\\).\n\n\n\n\nInteraction model for salary by gender, controlling for years of experience. Lines are not parallel because the slope differs by gender. The intercept difference at 0 years is \\(\\beta_2=1.94\\); the slope difference is \\(\\beta_3=0.26\\). The vertical gap at a fixed number of years \\(x\\) equals \\(\\Delta(x)=\\beta_2+\\beta_3x\\) (e.g., 4.54 at 10 years).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html",
    "href": "foundation-chapter12.html",
    "title": "Inferences for Multiple Linear Regression",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#objectives",
    "href": "foundation-chapter12.html#objectives",
    "title": "Inferences for Multiple Linear Regression",
    "section": "",
    "text": "Interpret inferential statistics for various types of regression models, including those with indicator variables, quadratic terms, and interaction terms.\nInterpret and communicate results from a multiple regression analysis.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#multiple-linear-regression-mlr-with-a-single-predictor-polynomial-regression",
    "href": "foundation-chapter12.html#multiple-linear-regression-mlr-with-a-single-predictor-polynomial-regression",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Multiple Linear Regression (MLR) with a Single Predictor: Polynomial Regression",
    "text": "Multiple Linear Regression (MLR) with a Single Predictor: Polynomial Regression\n\nThis is still considered a linear model.\n\nIt can capture curvilinear trends.\n\nIt is linear in the \\(\\beta_i X^j\\) term: for every one-unit increase in \\(X^j\\), \\(Y\\) changes by a constant \\(\\beta_i\\).\n\nIf the quadratic coefficient is significant but the linear term is not, the linear (lower-order) terms should still be included because they form a singular idea.\n\nInterpretation can be difficult, especially with higher-order terms.\n\nIn interpreting a quadratic model:\n\nThe vertex (absolute maximum or minimum) can be found using: \\[\nx_{\\text{vertex}} = \\frac{-\\beta_1}{2\\beta_2}\n\\]\nThis value of \\(X\\) represents the point at which \\(Y\\) stops increasing or decreasing, based on the quadratic regression model.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#coefficient-of-determination-r2",
    "href": "foundation-chapter12.html#coefficient-of-determination-r2",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Coefficient of Determination (\\(R^2\\))",
    "text": "Coefficient of Determination (\\(R^2\\))\n\n\\(R^2\\) is a measure of effect size for both simple linear regression (SLR) and MLR.\nIt represents the proportion of variance in the response variable explained by the model.\n\n\nCalculation in MLR\n\nMultiple \\(R^2\\): This is the squared correlation between the observed values of \\(Y\\) and the predicted values of \\(Y\\).\nPartition of sums of squares: The total variation in \\(Y\\) (\\(\\text{SS}_{\\text{total}}\\)) can be split into the variation explained by the model (\\(\\text{SS}_{\\text{regression}}\\)) and the variation left unexplained (\\(\\text{SS}_{\\text{residual}}\\)): \\[\n\\text{SS}_{\\text{total}} = \\text{SS}_{\\text{regression}} + \\text{SS}_{\\text{residual}}\n\\] This partition leads to: \\[\nR^2 = \\frac{\\text{SS}_{\\text{total}} - \\text{SS}_{\\text{residual}}}{\\text{SS}_{\\text{total}}} = \\frac{\\text{SS}_{\\text{regression}}}{\\text{SS}_{\\text{total}}}\n     = 1 - \\frac{\\text{SS}_{\\text{residual}}}{\\text{SS}_{\\text{total}}}\n\\]\n\n\n\nRelationship with the Overall F-test\n\nThe F-test statistic can be rewritten in terms of \\(R^2\\).\n\nTesting whether all parameters equal zero is equivalent to testing whether \\(R^2 = 0\\).\n\n\n\n\\(R^2\\) and Parsimony\n\nAdding more predictors will always increase \\(R^2\\).\n\nAn oversaturated model can have \\(R^2 = 1\\) even if the predictors do not contribute meaningfully.\n\nThe goal is to create a parsimonious model—one that is as simple as possible while still maximizing \\(R^2\\).\n\n\n\nAdjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) accounts for the number of predictors (\\(k\\)) and the sample size (\\(n\\)).\nThe formula is: \\[\nR^2_{\\text{adj}} = R^2 - (1 - R^2) \\frac{k}{n-k-1}\n\\]\nAdjusted \\(R^2\\) penalizes unnecessary predictors and small sample sizes.\n\nIt rewards variables that significantly improve model fit, resulting in a net increase if a predictor explains a substantial proportion of the variance.\n\nIt is generally a better measure of effect size than \\(R^2\\) in MLR.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#overfitting",
    "href": "foundation-chapter12.html#overfitting",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Overfitting",
    "text": "Overfitting\n\nA value of \\(R^2\\) equal to 1 can always be achieved, but this does not indicate good predictive power.\n\nOverfitting occurs when the model fits both the noise and the signal in the sample data.\n\nA high \\(R^2\\) value does not guarantee that the model will generalize well to new data.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#controlling-for-other-variables-in-mlr",
    "href": "foundation-chapter12.html#controlling-for-other-variables-in-mlr",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Controlling for Other Variables in MLR",
    "text": "Controlling for Other Variables in MLR\n\nWhen we hold \\(X_2\\) constant (i.e., look at a subpopulation with similar \\(X_2\\) values), we can examine the effect of changes in \\(X_1\\) on \\(Y\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#overall-f-test",
    "href": "foundation-chapter12.html#overall-f-test",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Overall F-test",
    "text": "Overall F-test\n\nThe overall F-test evaluates whether the model is statistically significant.\nHypotheses:\n\n\\(H_0\\): All slopes are equal to 0 (i.e., \\(R^2 = 0\\)).\n\n\\(H_a\\): At least one slope is not zero.\n\nF-statistic formula: \\[\nF = \\frac{\\text{SS}_{\\text{regression}} / k}{\\text{SS}_{\\text{residual}} / (n - k - 1)} = \\frac{\\text{MS}_{\\text{regression}}}{\\text{MS}_{\\text{error}}}\n\\]\nThis test can also be expressed in terms of \\(R^2\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#partial-f-test-extra-sum-of-squares",
    "href": "foundation-chapter12.html#partial-f-test-extra-sum-of-squares",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Partial F-test (Extra Sum of Squares)",
    "text": "Partial F-test (Extra Sum of Squares)\n\nThe partial F-test is used when a subset of \\(k\\) predictors does not have statistically significant slopes. In other words, it examines a reduced model with \\(g\\) of the \\(k\\) predictors.\nHypotheses:\n\n\\(H_0\\): The extra \\(k-g\\) predictors do not contribute. (All their slopes are zero.)\n\n\\(H_a\\): At least one of the extra predictors has a nonzero slope.\n\nThis test simultaneously evaluates whether additional predictors improve the model.\n\n\nExample: Partial F-test Using Extra Sum of Squares\nFull model:\n\\(\\log(\\text{cost}) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_4 + \\beta_5 X_5 + \\beta_6 X_6\\)\n\n\n\nSource\nDF\nSS\nMS\nF\np-value\n\n\n\n\nModel\n6\n1532\n255\n164\n&lt;0.0001\n\n\nError\n778\n1208\n1.55\n\n\n\n\nTotal\n784\n2740\n\n\n\n\n\n\nReduced model:\n\\(\\log(\\text{cost}) = \\beta_0 + \\beta_3 X_3 + \\beta_5 X_5 + \\beta_6 X_6\\)\n\n\n\nSource\nDF\nSS\nMS\nF\np-value\n\n\n\n\nModel\n3\n1523\n508\n326\n&lt;0.0001\n\n\nError\n781\n1217\n1.56\n\n\n\n\nTotal\n784\n2740\n\n\n\n\n\n\nHypotheses:\n\n\\(H_0\\): The extra coefficients are all zero (e.g., \\(\\beta_1 = \\beta_2 = \\beta_4 = 0\\)).\n\n\\(H_a\\): At least one of the extra coefficients is nonzero.\n\nPartial F-test comparison:\n\n\n\nModel\nError DF\nSSE\nMSE\nF\np-value\n\n\n\n\nModel\n3\n9\n3\n1.94\n0.1216\n\n\nFull (Error)\n778\n1208\n1.55\n\n\n\n\nReduced (Total)\n781\n1217\n\n\n\n\n\n\nPartial F-test results:\n\nCritical value (\\(\\alpha = 0.05\\)): \\(F_{0.05, 3, 778} = 2.62\\)\nObserved statistic: \\(F = 1.94\\)\n\nRight-tail p-value: \\(p = 0.1216\\)\n\nDecision: Since \\(F_{\\text{obs}} &lt; F_{\\text{crit}}\\) and \\(p &gt; 0.05\\), fail to reject \\(H_0\\).\n\nInterpretation:\nThere is not enough evidence to suggest that the extra predictors (e.g., \\(X_1\\), \\(X_2\\), \\(X_4\\)) explain a significant additional portion of variability in \\(\\log(\\text{cost})\\) beyond the reduced model.\n\n\n\nPartial F-test. F-distribution with \\(df_1=3\\) and \\(df_2=778\\) for the partial F-test. The vertical dashed line marks the observed statistic (\\(F = 1.94\\)), and the shaded region shows the right-tail p-value. For \\(\\alpha = 0.05\\), the critical value is \\(F_{0.05, 3, 778} \\approx 2.62\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#significance-tests-for-each-predictor-t-tests",
    "href": "foundation-chapter12.html#significance-tests-for-each-predictor-t-tests",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Significance Tests for Each Predictor (t-tests)",
    "text": "Significance Tests for Each Predictor (t-tests)\n\nHypotheses:\n\n\\(H_0: \\beta_i = 0\\) (the predictor has no effect).\n\n\\(H_a: \\beta_i \\neq 0\\) (the predictor has an effect).\n\nTest statistic: \\[\nt = \\frac{b_i}{SE_{b_i}}, \\quad df = n - k - 1\n\\]\nStandard error calculation: \\[\nSE = \\frac{\\hat{\\sigma}}{\\sqrt{\\sum_{i=1}^{n} (X_i - \\bar{X})^2}}, \\quad \\hat{\\sigma} = \\sqrt{\\frac{\\text{SSR}}{n - k - 1}}\n\\]",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#prediction-in-mlr",
    "href": "foundation-chapter12.html#prediction-in-mlr",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Prediction in MLR",
    "text": "Prediction in MLR\n\nPredicted values in MLR are the same as estimated means.\n\nTo obtain confidence intervals for the mean or prediction intervals for individual predictions, statistical software must be used because all variables in the model must be specified.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#least-squares-estimates-and-standard-errors",
    "href": "foundation-chapter12.html#least-squares-estimates-and-standard-errors",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Least Squares Estimates and Standard Errors",
    "text": "Least Squares Estimates and Standard Errors\n\nThe least squares estimates of the \\(\\beta\\)s appear in the coefficient column of the parameter estimate table.\nThe estimate of \\(\\sigma^2\\) is calculated as: \\[\n\\frac{\\text{sum of squared residuals (SSE)}}{\\text{df} (n-p)} = \\text{MSE}\n\\]\nThe square root of MSE gives the residual standard error (or RMSE).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter12.html#testing-intercept-and-slope-differences-in-regression-models-bat-echolocation-example",
    "href": "foundation-chapter12.html#testing-intercept-and-slope-differences-in-regression-models-bat-echolocation-example",
    "title": "Inferences for Multiple Linear Regression",
    "section": "Testing Intercept and Slope Differences in Regression Models (Bat Echolocation Example)",
    "text": "Testing Intercept and Slope Differences in Regression Models (Bat Echolocation Example)\n\nQuestion of Interest 1: Equality of Slopes Across All Groups\nQuestion: Are the slopes equal across all three groups—birds, echolocating bats (Ebat), and non-echolocating bats (NEbat)—after accounting for body size?\nApproach:\nWe use an Extra Sum of Squares F-test. If slopes are equal (holding body mass constant), the estimated difference in energy expenditure should be the same across groups.\nFull model: \\[\n\\begin{aligned}\n\\mu(\\text{lenergy} \\mid \\text{lmass}, \\text{TYPE})\n&= \\beta_0 + \\beta_2 \\,\\text{bird} + \\beta_3 \\,\\text{Ebat} + \\beta_1 \\,\\text{lmass} \\\\\n&\\quad + \\beta_4 (\\text{lmass} \\times \\text{bird}) + \\beta_5 (\\text{lmass} \\times \\text{Ebat})\n\\end{aligned}\n\\]\nAlternative expression: \\[\n\\mu(\\text{lenergy} \\mid \\text{lmass}, \\text{TYPE}) =\n(\\beta_0 + \\beta_2 \\,\\text{bird} + \\beta_3 \\,\\text{Ebat}) +\n(\\beta_1 + \\beta_4 \\,\\text{bird} + \\beta_5 \\,\\text{Ebat}) \\,\\text{lmass}\n\\]\nGroup-specific models: \\[\n\\begin{aligned}\n\\text{NEbat:} & \\quad \\mu = \\beta_0 + \\beta_1\\,\\text{lmass} &\\quad &\\text{slope: } \\beta_1 \\\\\n\\text{Ebat:}  & \\quad \\mu = (\\beta_0 + \\beta_3) + (\\beta_1 + \\beta_5)\\,\\text{lmass} &\\quad &\\text{slope: } \\beta_1 + \\beta_5 \\\\\n\\text{bird:}  & \\quad \\mu = (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_4)\\,\\text{lmass} &\\quad &\\text{slope: } \\beta_1 + \\beta_4\n\\end{aligned}\n\\]\nHypotheses:\n\\[\n\\begin{aligned}\nH_0 &: \\text{The slopes are equal}\n      &&\\Leftrightarrow \\beta_1 = \\beta_1 + \\beta_5 = \\beta_1 + \\beta_4 \\\\\n     & &&\\implies \\beta_4 = \\beta_5 = 0 \\quad\\text{(lines are parallel)} \\\\\nH_a &: \\text{The slopes are not all equal}\n      &&\\Leftrightarrow \\beta_4 \\text{ and } \\beta_5 \\text{ are not both zero}\n\\end{aligned}\n\\]\n\nExtra Sum of Squares F-test\nThe tables below show the full model, reduced model, and Extra Sum of Squares results used to test whether slopes differ among birds, Ebats, and NEbats.\nFull Model ANOVA Table\n\n\n\n\n\n\n\n\n\n\n\nSource\nDF\nSum of Squares\nMean Square\nF Value\nPr &gt; F\n\n\n\n\nModel\n5\n29.4699\n5.8940\n163.44\n&lt;.0001\n\n\nError\n14\n0.5049\n0.0361\n\n\n\n\nCorrected Total\n19\n29.9748\n\n\n\n\n\n\nReduced Model ANOVA Table\n\n\n\n\n\n\n\n\n\n\n\nSource\nDF\nSum of Squares\nMean Square\nF Value\nPr &gt; F\n\n\n\n\nModel\n3\n29.4215\n9.8072\n283.59\n&lt;.0001\n\n\nError\n16\n0.5533\n0.0346\n\n\n\n\nCorrected Total\n19\n29.9748\n\n\n\n\n\n\nExtra Sum of Squares Table\n\n\n\n\n\n\n\n\n\n\n\nSource\nDF\nSum of Squares\nMean Square\nF Value\nPr &gt; F\n\n\n\n\nModel\n2\n0.0484\n0.0242\n0.6704\n0.5272\n\n\nError (Full)\n14\n0.5049\n0.0361\n\n\n\n\nTotal (Reduced)\n16\n0.5533\n\n\n\n\n\n\nInterpretation: From the output, there is not enough evidence to suggest that the lines are not parallel and have different slopes, p-value = 0.5272 from the Extra Sum of Squares F-test.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Inferences for Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html",
    "href": "foundation-chapter13.html",
    "title": "Model Selection and Validation",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#objectives",
    "href": "foundation-chapter13.html#objectives",
    "title": "Model Selection and Validation",
    "section": "",
    "text": "Describe the proper order for a regression analysis.\nUse residuals to check regression assumptions.\nApply the necessary remedies when the assumptions are violated.\nApply variable selection algorithms and interpret the results.\nUnderstand statistical and conceptual issues for automatic variable selection in multiple linear regression.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#parameter-estimates-are-highly-context-dependent.",
    "href": "foundation-chapter13.html#parameter-estimates-are-highly-context-dependent.",
    "title": "Model Selection and Validation",
    "section": "Parameter estimates are highly context dependent.",
    "text": "Parameter estimates are highly context dependent.\n\nThe magnitude of a correlation coefficient can vary depending on factors such as:\n\nThe range of values observed for the variables.\nThe precision and reliability of the measurement instruments or techniques.\nThe characteristics of the units being studied.\n\nA specific slope estimate in a regression model can be affected by:\n\nThe range of \\(x\\) and \\(y\\) values in the data.\nThe characteristics of the units or cases in the sample.\nThe context provided by the specific set of predictor variables included in the model.\n\nExample: A tentative model for alcohol metabolism in men and women should:\n\nContain variables whose values best answer the research questions in a straightforward manner.\nInclude potentially confounding variables.\nInclude features that capture important relationships found in the initial graphical analysis (e.g., variables that are highly correlated with the response in a scatterplot matrix).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#inferences-on-partial-slopes",
    "href": "foundation-chapter13.html#inferences-on-partial-slopes",
    "title": "Model Selection and Validation",
    "section": "Inferences on Partial Slopes",
    "text": "Inferences on Partial Slopes\n\nExamine individual tests for each slope in the model to determine statistical significance.\nVariables may be excluded if the slope is not statistically significant, but check for potential collinearity before removal (see Collinearity and Variance Inflation Factor section).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#first-pass-model",
    "href": "foundation-chapter13.html#first-pass-model",
    "title": "Model Selection and Validation",
    "section": "First-Pass Model",
    "text": "First-Pass Model\n\nLook for variables that are not statistically significant. These could be three-way interactions, two-way interactions, or single variables.\nBefore removing a variable, check its Variance Inflation Factor (VIF) (see Collinearity and Variance Inflation Factor section) to see if it is highly correlated with others.\nInvestigate further with a partial residual plot.\n\nFit the model with \\(x_1\\) and \\(x_2\\).\nCalculate partial residuals for \\(x_2\\):\n\\[\n\\text{p}_{\\text{res}} = y - \\left(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_1\\right)\n\\]\nwhere \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) are estimated from the model fit with both \\(x_1\\) and \\(x_2\\).\nCreate a new dataset with \\(\\text{p}_{\\text{res}}\\) as the response and \\(x_2\\) as the predictor.\nFit a simple linear regression of \\(\\text{p}_{\\text{res}}\\) on \\(x_2\\) to assess the relationship.\nIf the plot looks linear, keep \\(x_2\\); if not, consider removing it.\n\n\n\n\n\n\n\n\nComputing Partial Residuals for an SLR\n\n\n\nTo create the dataset for the simple linear regression of \\(\\text{p}_{\\text{res}}\\) on \\(x_2\\):\n\nFit the full multiple linear regression model with \\(x_1\\) and \\(x_2\\):\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon\n\\]\nCompute partial residuals for \\(x_2\\):\n\\[\n\\text{p}_{\\text{res}} = y - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_1\n\\]\nForm a new dataset:\n\nResponse: \\(\\text{p}_{\\text{res}}\\)\nPredictor: \\(x_2\\)\n\nFit a simple linear regression of \\(\\text{p}_{\\text{res}}\\) on \\(x_2\\):\n\\[\n\\text{p}_{\\text{res}} = \\beta_0 + \\beta_1 x_2 + \\varepsilon\n\\]\nThe slope from this regression should match the \\(\\hat{\\beta}_2\\) from the full model.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#example-partial-residuals-mammal-brain-data",
    "href": "foundation-chapter13.html#example-partial-residuals-mammal-brain-data",
    "title": "Model Selection and Validation",
    "section": "Example: Partial Residuals — Mammal Brain Data",
    "text": "Example: Partial Residuals — Mammal Brain Data\nWe want to understand what is happening after accounting for another variable.\nSuppose we fit the multiple linear regression model:\n\\[\n\\mu(\\text{logBrain} \\mid \\text{logBody}, \\text{logGest}) = \\beta_0 + \\beta_1 \\text{logBody} + \\beta_2 \\text{logGest}.\n\\] To examine the partial effect of logGest, we remove the variation explained by logBody:\n\\[\n\\mu(\\text{logBrain} \\mid \\text{logBody}, \\text{logGest}) = \\beta_0 + \\beta_1 \\text{logBody} + f(\\text{logGest}),\n\\]\nwhich can be rewritten as:\n\\[\nf(\\text{logGest}) = \\mu(\\text{logBrain} \\mid \\text{logBody}, \\text{logGest}) - (\\beta_0 + \\beta_1 \\text{logBody}).\n\\]\nWe estimate this by looking at the residuals:\n\\[\n\\text{p}_{\\text{res}} = \\text{logBrain} - \\beta_0 - \\beta_1 \\text{logBody}.\n\\]\nHere, \\(\\text{p}_{\\text{res}}\\) represents what is left after we take out the effect with respect to body size.\nParameter estimates for the full model:\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDF\nParameter Estimate\nStandard Error\nt Value\nPr &gt; |t|\n\n\n\n\nIntercept\n1\n-0.4573\n0.4585\n-1.00\n0.3212\n\n\nlogGest\n1\n0.6678\n0.1088\n6.14\n&lt;0.0001\n\n\nlogBody\n1\n0.5512\n0.0324\n17.03\n&lt;0.0001\n\n\n\nThe partial residuals are computed as:\n\\[\n\\text{p}_{\\text{res}} = \\text{logBrain} - (-0.4573) - 0.5512(\\text{logBody}).\n\\]\nForming the SLR dataset:\n\nResponse variable: \\(\\text{p}_{\\text{res}}\\) (one value per observation, from the above formula)\nPredictor variable: logGest (same values as in the original dataset)\n\nWe then fit a SLR of \\(\\text{p}_{\\text{res}}\\) on logGest:\n\\[\n\\text{p}_{\\text{res}} = \\beta_0 + \\beta_1(\\text{logGest}).\n\\]\nParameter estimates for the SLR:\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDF\nParameter Estimate\nStandard Error\nt Value\nPr &gt; |t|\n\n\n\n\nIntercept\n1\n0.00005\n0.2767\n0.00\n0.9999\n\n\nlogGest\n1\n0.6678\n0.0578\n11.56\n&lt;0.0001\n\n\n\nThis shows that the information in the partial residuals can be explained by logGest.\n\n\n\nScatterplot of partial residuals vs. logGest. This plot shows the relationship between logGest and the residual variation in logBrain after accounting for logBody.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#dealing-with-outliers",
    "href": "foundation-chapter13.html#dealing-with-outliers",
    "title": "Model Selection and Validation",
    "section": "Dealing With Outliers",
    "text": "Dealing With Outliers\n\nLeast squares is not resistant to outliers.\nA robust regression procedure is useful when extreme values in the response variable (outliers) are still a problem, even after trying common remedies such as transformations, removing data entry errors, or using weighted least squares. Robust methods reduce the influence of these outliers on the fitted model.\nIf using least squares, examine outliers and influential points:\n\nAre the suspect observations influential, and why?\nDo they provide interesting information about the process under study?",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#guidelines",
    "href": "foundation-chapter13.html#guidelines",
    "title": "Model Selection and Validation",
    "section": "Guidelines",
    "text": "Guidelines\n\nIf the observation differs from the rest of the data in a sparsely represented region (i.e., not many values of \\(y\\) measured for a range of \\(x\\) values), restrict the range.\n\nThose few points will influence the regression.\nDocument that the range was restricted and explain why.\n\nIf the observation is not unusual and no other explanation can be found, do not omit it. Report results with and without the observation.\nIf there is strong reason to believe that the case belongs to a different population, omit it.\nIf there is no reason to believe it belongs to a different population, consider whether anything can be learned from it. A rare value can reveal information that would have otherwise been overlooked.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#identifying-influential-cases",
    "href": "foundation-chapter13.html#identifying-influential-cases",
    "title": "Model Selection and Validation",
    "section": "Identifying Influential Cases",
    "text": "Identifying Influential Cases\n\nOutlier influence can be tested with measurements that use the “leave one out” strategy. A large change after leaving one case out means that case is influential.\n\nDFFITS (difference in the fits): Measures the difference in fitted values for the \\(i\\)th case when all \\(n\\) cases are used versus when the \\(i\\)th case is excluded.\n\\[\n\\text{DFFITS}_i = \\frac{\\hat{Y}_i - \\hat{Y}_{i(i)}}{\\sqrt{\\text{MSE} \\cdot h_{ii}}}\n\\]\nwhere \\(h_{ii}\\) is the leverage statistic. There is an alternate calculation that relates it to the studentized residual.\nDFBETAS (difference in the betas): Measures the difference in slopes when all \\(n\\) cases are used versus when the \\(i\\)th case is excluded.\nCook’s distance (Cook’s \\(D\\)): Measures the distance of the outlier and leverage at the same time (joint influence).\n\nPlot \\(D_i\\) to identify large values.\nRemoving an influential point may have little effect because there may be another influential point nearby. This could also worsen the fit if there is another influential point on the opposite side.\nHigh VIF may be due to influential points (see Collinearity and Variance Inflation Factor section). Check before removing variables.\n\n\nCovariance ratio: If the covariance ratio \\(&gt; 1 + (3k/n)\\), deleting the observation adversely affects the accuracy of at least one of the parameter estimates.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#testing-slopes-for-statistical-significance",
    "href": "foundation-chapter13.html#testing-slopes-for-statistical-significance",
    "title": "Model Selection and Validation",
    "section": "Testing Slopes for Statistical Significance",
    "text": "Testing Slopes for Statistical Significance\n\nA key assumption in regression is that the explanatory variables (terms in the model) sufficiently describe the process under study.\n\nIt is misleading to omit important variables or include terms that are not needed.\nThe goal is to find the smallest model that adequately explains the relationship and includes all important predictors.\n\n\nStrategies\n\nExamine the data for outliers and influential observations, and decide whether to include them.\nUse partial residual plots to assess linearity for each term. Remove terms that do not have a linear relationship with the response.\nKeep in mind that removing a non-statistically significant term can change the significance of other terms.\nRemove nuisance variables, terms that do not help answer the research questions.\nCheck model diagnostics after each change.\n\n\n\nStrategies for Numerous Outliers or Nonconstant Variance\n\nWeighted least squares (WLS) assigns less weight to observations with higher variance, so less precise measurements influence the fit less.\nMeasurement error models are appropriate when both \\(X\\) and \\(Y\\) are measured with error. This is generally not a concern if the purpose of the model is prediction.\n\n\n\nCollinearity and Variance Inflation Factor (VIF)\nSome explanatory variables can be well explained by other explanatory variables in the model, making them redundant.\nCollinearity occurs when two or more explanatory variables are highly correlated, making it difficult to estimate their individual effects in a regression model. When collinearity is present:\n\nRegression coefficients can become unstable.\n\nStandard errors inflate, reducing statistical power.\n\nt-tests may show predictors as non-significant even if they are important.\n\nSmall changes in the data can cause large swings in estimated coefficients.\n\nIt can be hard to determine which predictors are truly important.\n\nWhy it matters:\n\nInflated standard errors make it harder to detect real effects.\n\nCan lead to misleading or counterintuitive coefficient signs.\n\nMay mask or exaggerate relationships.\n\nDetecting collinearity:\n\nVariance Inflation Factor (VIF):\n\nMeasures how well a variable can be predicted by all other variables in the model.\n\nAn \\(R^2\\) value close to 1 means the variable is largely explained by others and may be statistically redundant; a small \\(R^2\\) means it is not well predicted and is more likely to add unique information.\n\nFor predictor \\(X_j\\): \\[\n\\text{VIF}_j = \\frac{1}{1 - R_j^2}\n\\] where \\(R_j^2\\) comes from regressing \\(X_j\\) on all other predictors.\nInterpretation:\n\n\\(\\text{VIF} = 1\\): No correlation with other predictors.\n\n\\(\\text{VIF} &gt; 5\\): Moderate concern.\n\n\\(\\text{VIF} &gt; 10\\): Serious concern.\n\n\nA high VIF means \\(X_j\\) is highly correlated with other predictors and may not add new statistical information, though subject-matter considerations should guide the decision to keep or remove it.\n\nPartial residual plots:\n\nVisual method for checking whether a predictor still has an independent relationship with the response after accounting for others.\n\nCan reveal whether a predictor’s relationship is obscured by collinearity.\n\n\nAddressing collinearity:\n\nRemove or combine correlated predictors.\n\nReconsider the model in light of subject-matter knowledge.\n\nOther techniques, such as penalized regression, will be discussed later in Part 2 of the book.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#proving-causality",
    "href": "foundation-chapter13.html#proving-causality",
    "title": "Model Selection and Validation",
    "section": "Proving Causality",
    "text": "Proving Causality\n\nCausality can be established only in randomized experiments.\n\nA well-fitting regression model with a high \\(R^2\\) value demonstrates association, not causation. Important variables may still be missing from the model.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#guidelines-for-putting-it-together",
    "href": "foundation-chapter13.html#guidelines-for-putting-it-together",
    "title": "Model Selection and Validation",
    "section": "Guidelines for Putting It Together",
    "text": "Guidelines for Putting It Together\nWhen building and evaluating a model:\n\nPlot the data (e.g., scatterplots, boxplots) to understand relationships and detect anomalies.\nDevelop tentative models that:\n\nAddress the questions of interest (QOIs).\nAccount for potential confounders and important relationships identified in exploratory analysis.\n\nFit the model using the selected explanatory variables.\nEvaluate model fit (if applicable):\n\nCheck residual plots for constant variance, normality, and zero mean.\nIdentify influential observations (e.g., Cook’s \\(D\\)).\n\nRefine the model:\n\nConsider transformations or interaction terms.\nRemove unnecessary predictors if justified.\nEnsure final model addresses the QOIs.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#example-alcohol-metabolism-first-pass-metabolism",
    "href": "foundation-chapter13.html#example-alcohol-metabolism-first-pass-metabolism",
    "title": "Model Selection and Validation",
    "section": "Example: Alcohol Metabolism — First-Pass Metabolism",
    "text": "Example: Alcohol Metabolism — First-Pass Metabolism\nFirst-pass metabolism is the reduction in alcohol reaching the bloodstream after oral ingestion due to metabolism in the stomach lining and liver before entering systemic circulation.\nIn this study, it is estimated as the difference in alcohol levels between intravenous (IV) and oral administration.\nThis study compares oral and IV alcohol administration, focusing on gastric alcohol dehydrogenase (AD) activity.\n\nQuestions of Interest (QOIs)\n\nCompare levels of first-pass metabolism for men vs. women.\n\nTest whether men have greater AD activity.\n\nExplore whether alcoholism is related to differences in gastric AD activity.\n\n\n\nTentative Models\nFull model:\n\\[\n\\begin{aligned}\n\\text{metab} &= \\beta_0 + \\beta_1 \\text{Gastr} + \\beta_2 \\text{Gender} + \\beta_3 \\text{Alc} \\\\\n&\\quad + \\beta_4 (\\text{Gender} \\times \\text{Alc}) + \\beta_5 (\\text{Gender} \\times \\text{Gastr}) + \\beta_6 (\\text{Alc} \\times \\text{Gastr}) \\\\\n&\\quad + \\beta_7 (\\text{Gender} \\times \\text{Alc} \\times \\text{Gastr})\n\\end{aligned}\n\\]\n\nmetab = first-pass metabolism (IV – oral)\nGastr = gastric AD activity level (continuous)\nGender = male or female\n\nAlc = alcoholic (yes or no)\n\n\n\nQOI 3: Is Alcoholism Complicating the Answer?\nWe test whether alcohol-related variables jointly contribute to the model using the Extra Sum of Squares approach.\nFull model: Same as above.\nReduced Model: \\[\n\\text{metab} = \\beta_0 + \\beta_1 \\text{Gastr} + \\beta_2 \\text{Gender} + \\beta_5 (\\text{Gender} \\times \\text{Gastr})\n\\]\nANOVA Results — Full Model\n\n\n\n\n\n\n\n\n\n\n\nSource\nDF\nSum of Squares\nMean Square\nF Value\nPr &gt; F\n\n\n\n\nModel\n7\n42.3502\n6.0500\n6.83\n0.0002\n\n\nError\n22\n19.4835\n0.8856\n\n\n\n\nCorrected Total\n29\n61.8337\n\n\n\n\n\n\nANOVA Results — Reduced Model\n\n\n\n\n\n\n\n\n\n\n\nSource\nDF\nSum of Squares\nMean Square\nF Value\nPr &gt; F\n\n\n\n\nModel\n3\n41.6101\n13.8700\n17.83\n&lt;0.0001\n\n\nError\n26\n20.2236\n0.7778\n\n\n\n\nCorrected Total\n29\n61.8337\n\n\n\n\n\n\nExtra Sum of Squares Calculation\n\n\n\nSource\nDF\nSS\nMS\nF\np-value\n\n\n\n\nModel\n4\n0.74\n0.185\n0.209\n0.93\n\n\nError\n22\n19.48\n0.885\n\n\n\n\nTotal\n26\n20.22\n\n\n\n\n\n\n\nNote: Model fit was restricted to a narrowed range of gastric levels {0, 3}.\n\nInterpretation:\n\nThe Extra Sum of Squares test for the alcohol-related variables (Alc and its interactions) shows no significant improvement in model fit (p = 0.93).\n\nAfter accounting for Gender and Gastr, alcoholism status does not meaningfully explain additional variation in metab.\n\nIn QOI 2, we can simplify the model by removing the alcohol-related terms, focusing only on Gender, Gastr, and their interaction.\n\nThis simplification reduces the number of predictors and increases the degrees of freedom for estimating error, which can improve the stability of the parameter estimates in QOI 2.\n\n\n\nQOI 2: Do Men Have More AD Than Women?\nBecause no enzyme = no metabolism, we use a regression through the origin by setting \\(\\beta_0 = 0\\):\n\\[\n\\text{metab} = \\beta_1 \\text{Gastr} + \\beta_2 \\text{Gender} + \\beta_5 (\\text{Gender} \\times \\text{Gastr})\n\\]\nReference category: male\nParameter Estimates\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDF\nParameter Estimate\nStandard Error\nt Value\nPr &gt; |t|\n\n\n\n\nGastr\n1\n1.5989\n0.1249\n12.80\n&lt;0.0001\n\n\nGender\n1\n-0.8732\n0.1740\n-5.02\n&lt;0.0001\n\n\n\nInterpretation:\n\nSlope for males: \\(\\beta_1 = 1.5989\\)\nSlope for females: \\(\\beta_1 + \\beta_3 = 1.5989 - 0.8732 = 0.7257\\)\nThe change in metabolism for females for a 1-unit increase in AD is 0.87 units lower than for males (p &lt; 0.0001).\nThe male slope is about 2.2 times higher than the female slope (\\(\\text{ratio of slopes} = 1.5989 / 0.7257 \\approx 2.2\\)).\n\nIf males have more AD than females, this greater slope per unit of AD explains their higher first-pass metabolism.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#variable-selection",
    "href": "foundation-chapter13.html#variable-selection",
    "title": "Model Selection and Validation",
    "section": "Variable Selection",
    "text": "Variable Selection\n\nUnrelated or “garbage” predictors can inflate \\(R^2\\), creating a false impression of predictive accuracy.\nThe challenge is determining which predictors to include.\nAdding or removing variables can change the estimated effects of other variables, sometimes in unexpected ways.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#automatic-variable-selection-techniques",
    "href": "foundation-chapter13.html#automatic-variable-selection-techniques",
    "title": "Model Selection and Validation",
    "section": "Automatic Variable Selection Techniques",
    "text": "Automatic Variable Selection Techniques\n\nCommon methods include:\n\nForward selection.\nBackward elimination.\nStepwise regression.\n\nThese methods may produce the same model or different ones.\nModel choice should consider:\n\nStatistical measures (e.g., \\(R^2\\)).\nModel diagnostics for influential points or variables.\nWhether the included variables make conceptual sense.\n\n\n\nForward Selection\n\nProcess:\n\nBegin with no predictors in the model.\nFit simple linear regressions (SLRs) for each potential predictor.\nAdd the predictor with the smallest p-value if it is statistically significant.\nRepeat by adding the next most significant predictor.\nContinue until \\(R^2\\) does not increase significantly.\n\nPros:\n\nEasy to compute and understand.\nCan be used even when \\(n &lt; k\\) (sample size &lt; predictors).\n\nCons:\n\nA poor first choice can lead to a suboptimal final model.\nMay select predictors that are only significant in the absence of others.\nDoes not guarantee the best subset.\nNo check for collinearity—collinear variables may enter randomly.\n\n\n\n\nBackward Elimination\n\nProcess:\n\nBegin with all predictors in the model.\nFor each predictor, compute an \\(F\\)-statistic for its removal, indicating how much the overall \\(F\\) decreases when a variable is dropped from the model.\nRemove variables that are not statistically significant and do not cause a large change in \\(R^2\\).\nStop removing variables when further removal causes a significant drop in model fit.\n\nPros:\n\nStarts with a potentially good fit (all variables included).\nGood initial estimate of \\(\\sigma^2\\) when \\(n\\) is large.\nOnly removes noninfluential predictors.\n\nCons:\n\nCannot be used when \\(n &lt; k\\).\nStarting with many predictors leaves few error degrees of freedom. This reduces statistical power in the early steps, making it harder to detect and remove weak predictors.\nDoes not guarantee the best subset.\nCollinear variables may be removed arbitrarily.\nNo residual checks at intermediate steps.\n\n\n\n\nStepwise Selection\n\nProcess:\n\nStart with no predictors.\nAdd the most significant predictor from an SLR.\nAfter adding a variable, remove the single variable with the highest p-value (or other criterion) if it is no longer significant.\nContinue adding and removing one variable at a time until all terms in the model are statistically significant.\nRequires setting:\n\np-value-to-enter (\\(p_E\\), e.g., 0.15).\np-value-to-remove (\\(p_R\\), e.g., 0.15).\np-value is only one possible criterion; other statistics may be used.\n\n\nLimitations:\n\nMay miss important predictors (Type II error).\nMay keep unimportant predictors (Type I error).\n\nCautions:\n\np-value thresholds can be adjusted, or alternative selection techniques can be used to generate candidate models.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#select-a-selection-procedure",
    "href": "foundation-chapter13.html#select-a-selection-procedure",
    "title": "Model Selection and Validation",
    "section": "Select a Selection Procedure",
    "text": "Select a Selection Procedure\n\nNo single procedure is universally best.\n\nVariable selection involves multiple comparisons: the more variables tested, the greater the chance of a Type I error.\n\nUse subject-matter knowledge (“human in the loop”) to guide final model selection.\n\nExamine:\n\nVariables included in the model.\nRegression diagnostics.\nInfluence statistics.\n\nEnsure that assumptions are met and that the included variables make sense for the study context.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#variable-selection-criteria",
    "href": "foundation-chapter13.html#variable-selection-criteria",
    "title": "Model Selection and Validation",
    "section": "Variable Selection Criteria",
    "text": "Variable Selection Criteria\n\np-values.\nAkaike Information Criterion (AIC): Penalized for number of parameters; smaller is better.\nBayesian Information Criterion (BIC) or Schwarz Bayesian Criterion (SBC): More heavily penalized for number of parameters; smaller is better.\nPRESS: Leave-one-out statistic. Fit the model on all but one observation, compute the residual for the excluded case, and repeat for all \\(n\\) observations. Sum of squared residuals is the PRESS statistic; smaller is better.\nMallows’ \\(C_p\\): Smaller is better; best when closest to \\(p\\) (number of parameters including the intercept).\n\\(R^2\\): Larger is better, but beware of overfitting.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-chapter13.html#mallows-c_p-best-subset-selection",
    "href": "foundation-chapter13.html#mallows-c_p-best-subset-selection",
    "title": "Model Selection and Validation",
    "section": "Mallows’ \\(C_p\\) – Best Subset Selection",
    "text": "Mallows’ \\(C_p\\) – Best Subset Selection\n\nFormula:\n\\[\nC_p = p + (n - p) \\times \\frac{\\hat{\\sigma}^2 - \\hat{\\sigma}^2_{\\text{full}}}{\\hat{\\sigma}^2_{\\text{full}}}\n\\]\nInterpretation:\n\n\\(p\\) = number of parameters including the intercept.\nModel with \\(C_p\\) closest to \\(p\\) is preferred.\nExpected \\(C_p\\) for a model with no overfitting is \\(p\\).\n\nFor linear regression, \\(C_p\\) is equivalent to the AIC.",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Model Selection and Validation</span>"
    ]
  },
  {
    "objectID": "foundation-review-questions.html",
    "href": "foundation-review-questions.html",
    "title": "Review Questions",
    "section": "",
    "text": "This chapter includes review questions sorted by difficulty. Click on each question to reveal the suggested answer.\n\nEasier\n\nQuestion 1\nQ: Define the terms population and sample. How do they differ?\n\n\nClick to show answer\n\nPopulation refers to the entire group of things that you want to study. It includes all members that fit the criteria of the research question. Sample refers to a smaller subset of the population that you collect the data from for the study. It should be representative of the population to ensure the conclusions about the population are valid. They differ in size; the population is larger. Data is collected from the sample because it is impractical or impossible to collect data from entire population. Assuming the sample is randomly selected from the population, conclusions drawn from the sample are generalized to the population as a whole.\n\n\n\nQuestion 2\nQ: What is the importance of a representative sample in a study? How do we take one?\n\n\nClick to show answer\n\nA representative sample is important to be able to make accurate generalizations about your population of interest based on the sample data. It reduced bias and ensures the conclusions are valid. First it is important that you identify what your population of interest is (for example, to predict the results of a vote, a representative sample would be registered voters rather than all voting age adults). Second you must select a sample randomly from that population to ensure that each member of the population has an equal chance of being included. Also, the sample size must be large enough to be representative of the population and capture the population variability.\n\n\n\nQuestion 3\nQ: Discuss the differences between mean, median, and mode. In which scenarios might one be more appropriate to use than the others?\n\n\nClick to show answer\n\nMean is the average (\\(\\frac{\\text{sum}}{n}\\)). The mean of the population is \\(\\mu\\). The mean of the sample is \\(\\bar{x}\\). A mean is not resistant to extreme values. Median is the middle value when the data is ordered from least to greatest (the 50th percentile). If there is an even number of observations, the median is the average of the middle two values. Mode is the value that appears most frequently. A dataset can have more than one mode or no modes if all the values are unique. If a population is normally distributed these values should be nearly the same. Mean is appropriate to use with normally distributed data. If the population has a skewed distribution or extreme values or you can’t verify normality assumptions, it may be more appropriate to draw inferences about the median. With income data, it can often be better to use the median. Mode can be useful to identify the most common values, for instance in categorical values like shoe size.\n\n\n\nQuestion 4\nQ: Can you explain what a standard deviation is and what it indicates about a data set?\n\n\nClick to show answer\n\nStandard deviation is a measure of the variation. The population standard deviation is represented by \\(\\sigma\\), and the sample standard deviation is represented by \\(s\\). It is calculated by taking the difference between the observed and expected values, squaring them, summing them, and dividing by either the population size or the degrees of freedom. That gives you the variance, and then taking the square root gives you the standard deviation. It indicates the spread of the data and how far data are from the mean.\n\n\n\nQuestion 5\nQ: Assume you want to test the mean score on an exam between males and females. If there is strong evidence to suggest the standard deviations of the distributions of the scores for males and females are different, what should we / can we do?\n\n\nClick to show answer\n\nWe can try a transformation of the data, like a log transformation. If the standard deviations equalize, then we can proceed with a two sample t-test, which pools the standard deviations to calculate the t-statistic. This results in higher degrees of freedom and a more powerful test. We could use Welch’s t-test, which assumes normality but not equal standard deviations. It uses each sample’s individual standard deviation to calculate the t-statistic. This adjusts the degrees of freedom down to account for unequal variances. If transformations do not equalize the standard deviation and the distributions are not normal, or we just don’t want to make assumptions about either, we can use a non-parametric test, either a permutation test, which allows for inference on the mean, or a rank sum test for inference on the median.\n\n\n\nQuestion 6\nQ: Review the following model and parameter estimate table. Interpret the slope of the Age variable from the following regression model: \\[\n\\text{Score} = \\beta_0 + \\beta_1\\text{Age} + \\beta_2 \\text{Green} + \\beta_3\\text{Red} + \\beta_4\\text{Yellow}\n\\] Follow up: interpret \\(\\beta_3\\):\n\n\n\nClick to show answer\n\nThere is strong evidence at the \\(\\alpha = 0.05\\) level of significance that regardless of group membership, for every 1 year increase in age, the estimated mean score increases by 0.44 points (\\(p\\)-value = 0.0046).\nAdditionally, there is overwhelming evidence at the \\(\\alpha = 0.05\\) level of significance that the estimated mean score of the red group will be 6.40 points lower than the reference group (\\(p\\)-value &lt; 0.0001), holding age constant. This interpretation applies across all practical ages within the scope of the study. As ages beyond the range of individuals in this sample are extrapolated estimates, they should be evaluated cautiously.\n\n\n\n\n\nMedium\n\nQuestion 7\nQ: What is a confidence interval, and how does it relate to hypothesis testing?\n\n\nClick to show answer\n\nA confidence interval is a range of plausible values that is likely to capture the true population mean with a specified probability (the confidence level). For example, if we were to take 100 samples and our confidence level was 95%, we would expect to capture the true population mean within the confidence interval 95 out of the 100 times. It is calculated by estimating the mean from the sample data and adding and subtracting a margin of error (i.e t-multiplier \\(\\times\\) the standard error). In hypothesis testing, we test the assumption that the population mean equals the null hypothesis. If the value in the null hypothesis is within the confidence interval, then we fail to reject, and if it is not, then we reject the null hypothesis.\n\n\n\nQuestion 8\nQ: What is a Type I error and a Type II error in the context of hypothesis testing?\n\n\nClick to show answer\n\nA Type I error is when you reject the null hypothesis when it is true. This is a false positive, where you conclude there is an effect when there is none. The probability of making a Type I error is \\(\\alpha\\) (i.e the significance level of the test). A Type II error is when you fail to reject the null hypothesis when it is false. This is a false negative, where you conclude there is no effect when there really is one. The probability of making a Type II error is \\(\\beta\\). The power of a test, \\(1 – \\beta\\), is the probability of correctly rejecting a false null hypothesis.\n\n\n\nQuestion 9\nQ: Can you explain the concept of the \\(p\\)-value and its significance in hypothesis testing?\n\n\nClick to show answer\n\nA \\(p\\)-value is the probability of observing by random chance a result as or more extreme than you observed under the assumption that the null hypothesis is true. The smaller the \\(p\\)-value the stronger the evidence against the null hypothesis. It allows researchers to determine the significance of their results based on a pre-defined significance level, \\(\\alpha\\). If the \\(p\\)-value is \\(&lt; \\alpha\\), then we reject the null hypothesis. If the \\(p\\)-value is \\(&gt; \\alpha\\), it is evidence that there is not a statistically significant result, and we fail to reject. A \\(p\\)-value determines statistical significance, but not necessarily practical significance. \\(\\alpha\\) allows the researcher to define the significance level required to reject or fail to reject the null hypothesis for each particular problem potentially depending on the risk if you were to draw the wrong conclusion. In other words, if you find that you would expect to see a result as or more extreme than the one you observed in fewer than 1 out of every 100 times or with a \\(p\\)-value of 0.01. This is convincing evidence that the null hypothesis is false, and you can reject it.\n\n\n\nQuestion 10\nQ: What is a box plot, and what information can it tell us about a data set?\n\n\nClick to show answer\n\nA box plot is a graphical representation of the distribution of a sample based on a five-number summary. It is useful to visualize the central tendency, spread, and sometimes the outliers in the data. It can also be called a box-and-whisker plot. The box represents the interquartile range (IQR) of the data. The outsides of the box tell us the 25th and 75th percentile of the data, and the line through the box tells us the median (i.e the 50th percentile). The whiskers extend sometimes to the min and max of the the dataset, but there are other variations. Commonly the whiskers will extend to \\(1.5 \\times\\) the IQR on both sides and display the data beyond that as points representing the outliers. A box plot give us the five-number summary and potentially tell us about outliers. It shows us the range and skewness of the data as well. If one whisker is longer, it suggests the data are skewed in that direction. If the median line is closer to one quartile, it suggests skewness and a larger spread on the opposite side.\n\n\n\nQuestion 11\nQ: What is the Central Limit Theorem, and why is it important in statistics?\n\n\nClick to show answer\n\nThe Central Limit Theorem says that the distribution of sample means will approach a normal distribution regardless of the shape of the population distribution as sample sizes get sufficiently large. It is important because it helps make tests that assume normality, like \\(t\\)-tests, ANOVA, and linear regression, robust to deviations in normality in the population distribution with sufficient sample size. It is also important when we don’t know the population distribution.\n\n\n\nQuestion 12\nQ: What does it mean to have a high Cook’s D? Which point on the scatter plot below has the highest Cook’s D?\n\n\n\nClick to show answer\n\nA point with a high Cook’s D has both a high residual value and high leverage, meaning it is an influential point in determining the regression equation. A high residual value results when the observed value is far from the predicted value (the value on the regression line when calculated without that point, or the mean of the distribution of \\(y\\) for that value of \\(x\\)). A high leverage value results when the \\(x\\) value of the point is far from the mean of the \\(x\\) values. The point on the scatterplot with a high Cook’s D is the point in the lower right box (with a leverage of ~0.02, and a studentized residual of ~-2.75).\n\n\n\nQuestion 13a\nQ: We want to test for an effect of a test prep program on student scores on a test. To test for this effect, we randomly select 100 students, give those students a form of the test, and record their scores. At the same time, we randomly select 100 different students from the same population and give them the test prep program. Upon completion of the program, we have the second group of students take the same test as the first group and record their score. What statistical test would you recommend to test for this effect?\n\n\nClick to show answer\n\nMy answer depends on the standard deviations of test scores for each sample. If there is no evidence against equal standard deviation, as the sample sizes of both groups are reasonably large, even if the distributions deviate somewhat from normality, I think a two-sample \\(t\\)-test would be robust to those deviations and would be an appropriate choice. If there is evidence of unequal standard deviation, and as the sample sizes are equal and are sufficiently sized, a Welch’s two-sample \\(t\\)-test would be the most appropriate choice. If you were more interested in comparing the medians of the groups, then a non-parametric test, like a rank sum test would be a good choice.\n\n\n\nQuestion 13b\nQ: Now we want to test for an effect of a test prep program on student scores on a test. To test for this effect we give the students a form of the test and record their scores. During the next week, we give them the test prep program. Immediately after completing the program, we have them take the test again and record their score again. What statistical test would you recommend to test for this effect?\n\n\nClick to show answer\n\nAs these are paired data, I would choose a test for this situation. Again, the answer depends on the standard deviation. Assuming no evidence against equal standard deviation, I would recommend a paired \\(t\\)-test. If there was evidence against equal standard deviation or we were interested in comparing median scores, I would choose a signed rank test.\n\n\n\n\n\nHarder\n\nQuestion 14\nQ: Explain the difference between parametric and non-parametric statistical methods and when you would use one method over another. Provide examples in your explanation.\n\n\nClick to show answer\n\nParametric methods have the assumption that the population is normally distributed. Non-parametric tests do not make assumptions about the population distribution. Parametric tests are preferred when the assumption of normality and equal variances are met and the sample size is large enough to apply the CLT. They tend to be more powerful when assumptions are satisfied. If you were comparing two independent normally distributed populations with roughly equal standard deviation, you would prefer a parametric two-sample \\(t\\)-test, which is a very powerful test. If the groups didn’t have equal standard deviation you could still use a parametric test, but should choose the Welch’s \\(t\\)-test. Both of these choices assume the sample size is large enough for you to make assumptions about the population or rely on the CLT. If you have very small sample sizes and/or cannot assume the populations are equally distributed, you should use a non-parametric test such as a rank sum test for inferences on the population median or a permutation test. Additionally if you are interested in the medians or have censored data, a rank sum test is a good choice. The same rational goes for paired samples. Choose a paired \\(t\\)-test if you can assume normality and choose a signed rank test for inference on the median if not. Ditto for comparisons of more than two groups. Choose an ANOVA or Welch’s ANOVA if you can assume normality and choose a Kruskall-Wallis if not. There is also a parametric and non-parametric test for equal variance, the F-test for equal variance and the Brown-Forsythe test that that doesn’t make assumptions about the population normality.\n\n\n\nQuestion 15\nQ: Consider the plot and the corresponding ANOVA table below. What number represents the variances of the assumed normal distributions of Y for each group?\n\n\n\n\n\n\n\n\n\n\n\n\nClick to show answer\n\nThe Mean Sq Residuals (also called the mean squared error) equal \\(\\sigma^2\\), the shared variances, which in this case is 2.083.\n\n\n\nQuestion 16\nQ: Explain the concept of statistical power and how sample size may affect it? Follow up: What is \\(\\alpha\\) and \\(\\beta\\) in the context of statistical power?\n\n\nClick to show answer\n\nStatistical power is the probability that a test will correctly reject the null hypothesis when it is false. It is the likelihood that a test will detect an effect if there is one. It is equivalent to \\(1 - \\beta\\), where \\(\\beta\\) is the probability of a Type II error, of failing to reject when the null hypothesis is false. As sample size increases, \\(\\sigma_\\bar{x}\\) (the standard error of the mean) decreases, which narrows the distribution of the sample mean, increasing the likelihood that the sample mean will fall in the rejection region and of detecting an effect. A higher sample size can also lead to higher degrees of freedom. This brings the critical value closer to the null hypothesis, making it easier to reject. It also increases the chance that \\(\\bar{x}\\) is closer to the true population mean, increasing the chance that it is in the rejection zone. \\(\\alpha\\) is the significance level of the test. It represents the probability of making a Type I error or of rejecting the null hypothesis when it is true. Increasing \\(\\alpha\\) increases the likelihood of rejecting the null hypothesis, which increases the ability of detecting an effect. As \\(\\alpha\\) increases, so does power, and as those go up, \\(\\beta\\) goes down.\n\n\n\nQuestion 17\nQ: Write a null hypothesis that describes a contrast in which the average of the means of the A and D groups are tested for equality of the C and E groups? What set of contrast weights reflects this contrast (assume they are ordered alphabetically)?\n\n\nClick to show answer\n\n\\(\\frac{(\\mu_A + \\mu_D)}{2} = \\frac{(\\mu_C + \\mu_E)}{2}\\)\n1 0 -1 1 -1 divisor 2 or .5 0 -.5 .5 -.5\n\n\n\nQuestion 18\nQ: Assume we want to test the mean of group A and D for equality. Would it be better to filter the data to get only the As and Ds and then do a two sample \\(t\\)-test (assuming the assumptions are met) or include all the data including groups B,C and E in the analysis? Why?\n\n\nClick to show answer\n\nIt is better to include all the data and do a linear contrast. That approach gives us higher degrees of freedom. Using the pooled standard deviation with higher degrees of freedom often results in lower standard error. The higher degrees of freedom also brings the critical value closer to the null mean, making it easier to reject or making the test more sensitive. Pooling the standard deviation means the estimate of variability is likely more stable. Both of these factors increase the power of the test, enhancing the likelihood of correctly reject the null hypothesis and detecting a true difference if one exists.\n\n\n\nQuestion 19\nQ: An analyst suggested that a SLR model would not be appropriate here because both the response and predictor variables are not normally distributed. Do you agree with the analyst, or do you have something else to say about it?\n\n\n\n\n\n\n\n\n\n\n\n\nClick to show answer\n\nI would disagree that SLR is not appropriate. The assumption of normality is not for the distribution of \\(x\\) or the distribution of \\(y\\) overall, but for the distribution of \\(y\\) at each value of \\(x\\). The scatterplots of \\(x\\) vs \\(y\\) and \\(y\\) vs \\(x\\) indicate a strong linear trend. The residual plots also support the appropriateness of SLR. The residuals look normally distributed in the QQ plot. The residual scatterplot is randomly scattered around zero with no evidence against equal standard deviation. The standardized residual plot is randomly scattered and within normal values, showing no evidence of high residual points. The Cook’s D plot has a few higher leverage points but no points with high Cooks D to indicate influential outliers.\n\n\nAdditional notes:\nCorrelation coefficient \\(r\\) estimates the population correlation, \\(\\rho\\). \\(R^2\\) = the proportion of the variation in \\(y\\) that is explained by the linear relationship between \\(x\\) and \\(y\\).",
    "crumbs": [
      "Statistical Foundations",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Review Questions</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html",
    "href": "applied-chapter01.html",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#objectives",
    "href": "applied-chapter01.html#objectives",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "",
    "text": "Understand regression problems and distinguish them from classification problems.\nIdentify when to use explanatory versus predictive modeling.\nCompare parametric and nonparametric regression models and their trade-offs.\nReview multiple linear regression (MLR) and its applications.\nEvaluate key assumptions of MLR and correctly interpret model coefficients.\nExplore techniques to increase model complexity when needed.\nDetect and address multicollinearity in regression models.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#key-terms",
    "href": "applied-chapter01.html#key-terms",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "Key Terms",
    "text": "Key Terms\n\nThe response variable (dependent variable) is what we aim to explain or predict.\n\nExplanatory variables (independent variables) are the factors that may influence the response.\nRegression: The response is a continuous numeric variable (e.g., predicting car mileage).\n\nClassification: The response variable is categorical and can have two (binary) or more than two levels (e.g., predicting where a car was made: North America, Asia, or Europe).\n\n\nExample: Regression Problem - MPG Dataset\nA common regression problem is predicting a car’s miles per gallon (MPG) using various features:\n\nResponse Variable: mpg (miles per gallon)\nExplanatory Variables: cylinders, horsepower, origin (3 levels), year, etc.\n\n\n\nRegression Modeling Workflow\nWhen analyzing a regression problem, we typically follow these steps:\n\nExploratory Data Analysis (EDA)\n\nVisualize relationships between the response and each explanatory variable.\nIdentify potential trends, outliers, and transformations.\n\nKey Questions to Consider\n\nWhich variables explain mpg, and how strong are these relationships?\n\nAre there specific hypotheses to test (e.g., does a car’s origin significantly impact mpg)?\n\nCan we use this model to predict the mpg of a new car?",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#regression-problems",
    "href": "applied-chapter01.html#regression-problems",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "Regression Problems",
    "text": "Regression Problems\nA regression problem occurs when the response variable is continuous. The goal can either be explanation (understanding relationships) or prediction (making accurate future estimates).\n\nTo Explain or To Predict?\n\nExplaining Relationships\n\nHypothesis testing and confidence intervals\n\nIdentifying relationships between response and predictors\n\nAdjusting for confounding (lurking) variables\n\nPredicting Future Outcomes\n\nFocused on accuracy, not interpretation\n\nMore complex models can be used\n\n\nTo determine the appropriate approach, ask what is the primary goal—explanation, prediction, or both?",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#parametric-vs.-nonparametric-regression-tools",
    "href": "applied-chapter01.html#parametric-vs.-nonparametric-regression-tools",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "Parametric vs. Nonparametric Regression Tools",
    "text": "Parametric vs. Nonparametric Regression Tools\n\nGeneral Regression Model Structure\nThe regression model follows:\n\\[\nY = f(X) + \\varepsilon\n\\] where:\n\n\\(X = (x_1, x_2, ..., x_p)\\) represents the explanatory variables.\n\n\\(f(X)\\) is the deterministic component.\n\n\\(\\varepsilon\\) is the random error.\n\n\n\nKey Terminology\n\nPopulation function: \\(f\\) (true but unknown function in the population).\n\nSample function: \\(\\hat{f}\\) (estimate of \\(f\\) using observed data).\n\n\n\nEstimating \\(f\\): Parametric vs. Nonparametric Approaches\nThere are two primary approaches for estimating \\(f\\):\n\nParametric\n\nNonparametric\n\nThe choice depends on how the response and predictor variables relate mathematically.\nFor example:\n\nA numeric predictor like horsepower may follow a quadratic function.\n\nA categorical predictor like cylinders may follow a piecewise function.\n\n\n\nParametric Approach\n\nRequires specifying the functional form of \\(f(X)\\).\n\nAssumes additional conditions about the error term.\n\nAllows hypothesis testing.\n\nWorks well when the model is correctly specified.\n\nSimpler models can be more interpretable.\n\n\n\nNonparametric Approach\n\nNo need to specify \\(f(X)\\).\n\nFully data-driven and flexible.\n\nCan capture complex relationships.\n\nMore difficult to interpret.\n\nMay require larger datasets for reliable estimation.\n\nDoes not support traditional hypothesis testing frameworks.\n\n\n\nTradeoffs: Interpretability vs. Flexibility\n\n\n\n\n\n\n\n\nApproach\nPros\nCons\n\n\n\n\nParametric\nInterpretable  Allows hypothesis testing  Works well for small datasets  Easier for high \\(p\\), low \\(n\\) settings\nCannot model complex relationships well  Sensitive to misspecification\n\n\nNonparametric\nAdapts to complex patterns  Less restrictive assumptions  Often performs better for large datasets\nRequires large datasets  No hypothesis testing  Harder to interpret\n\n\n\n\n\nChallenges with Parametric Models\n\nSpecifying highly complex forms of \\(f(X)\\) is difficult.\n\nFor large datasets, nonparametric models often perform as well or better.\n\nAdditional diagnostic checks are required, such as:\n\nChecking model assumptions (linearity, normality, independence).\n\nAddressing multicollinearity and influential points.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#a-review-of-multiple-linear-regression-mlr",
    "href": "applied-chapter01.html#a-review-of-multiple-linear-regression-mlr",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "A Review of Multiple Linear Regression (MLR)",
    "text": "A Review of Multiple Linear Regression (MLR)\n\nModel Structure\n\\[\nY = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p + \\varepsilon\n\\]\nwhere:\n\n\\(Y\\) is the response variable.\n\n\\(X_1, X_2, ..., X_p\\) are the explanatory variables.\n\n\\(\\varepsilon\\) is the random error term.\n\n\n\nAssumptions of MLR\n\nLinearity: The relationship between predictors and response is linear.\n\nIndependence: Errors are independent.\n\nHomoscedasticity: Errors have constant variance.\n\nNormality: Errors follow a normal distribution.\n\n\n\nResidual Diagnostic Checks\nThese checks help assess whether assumptions hold:\n\nResidual vs. Fitted Plot – Examines constant variance (homoscedasticity).\n\nQ-Q Plot and/or Histogram – Assesses whether residuals follow a normal distribution.\n\nVariance Inflation Factor (VIF) – Identifies multicollinearity among predictors.\n\nData Collection Process Review – Ensures independence.\n\nViolations often occur in repeated measures on the same subject or in time series data.\n\n\n\nBasic Interpretations\nWhen each predictor is included in the model only once, interpretations follow these general rules:\n\nContinuous predictors: A one-unit increase in \\(X\\) results in a change of \\(\\beta\\) in \\(Y\\), holding all other variables constant.\nCategorical variables: Represented using dummy variables.\n\nExample: Suppose \\(X_1\\) is categorical with three levels (A, B, C), while \\(X_2\\) and \\(X_3\\) are continuous. The model:\n\\[\nY = \\beta_0 + \\beta_1\\text{LevelB} + \\beta_2\\text{LevelC} + \\beta_3X_2 + \\beta_4X_3\n\\]\n\n\\(\\beta_1\\): Difference in mean response between group B and reference group A, holding other variables constant.\n\n\\(\\beta_2\\): Difference in mean response between group C and reference group A, holding other variables constant.\n\nThe reference group A is not specifically listed in the model.\n\nWhy “holding all other variables constant” is important\nA key advantage of MLR is its ability to control for confounding variables.\nExample: Sex discrimination in pay\n\nIf we suspect a gender-based wage gap, we should control for factors like position level, education, and job role.\n\nA more precise interpretation:\n“A male with the same IQ and education level (instead of generically ‘holding all other variables constant’) is estimated to earn $28,463 more than a female counterpart.”",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#adding-model-complexity",
    "href": "applied-chapter01.html#adding-model-complexity",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "Adding Model Complexity",
    "text": "Adding Model Complexity\n\nTransformations\nWhen to transform variables:\n\nNon-constant variance → Transform \\(Y\\).\nNonlinear trends in residual plots → Transform \\(X\\) or add polynomial or interaction terms.\n\n\n\nPros and Cons of Transformations\n\nHelps satisfy model assumptions.\n\nAllows reliable statistical inference on regression coefficients.\n\nLog transformations retain interpretability.\n\nMore complex transformations may hinder interpretation (less of a concern for predictive models).\n\nExample: Polynomial regression\n\n\nCode\nlm(y ~ poly(x1, 3), data=mydata) # poly(predictor, degree)\n\n\n\n\nWays to Increase Model Complexity\n\nModeling nonlinear trends: Introducing higher-order terms (with multiple coefficients) for a single predictor (e.g., \\(X^2\\) or \\(X^3\\)).\nMultiple linear trends by category: Using interaction terms to model relationships (between multiple predictors) that vary by group.\nAdding predictors one at a time: Results in an additive model where the intercept changes, but the slope remains the same.\nAdding interactions: Results in a non-additive model where both the intercept and slope change depending on another variable.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#interactions-in-mlr",
    "href": "applied-chapter01.html#interactions-in-mlr",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "Interactions in MLR",
    "text": "Interactions in MLR\nIf \\(X_1\\) is numeric and \\(X_2\\) is categorical with two levels:\n\nReference group (where \\(X_2=0\\)): \\(Y = \\beta_0 + \\beta_1 X_1\\)\nNon-reference group (where \\(X_2=1\\)): \\(Y = (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3)X_1\\)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#hypothesis-testing-for-interactions",
    "href": "applied-chapter01.html#hypothesis-testing-for-interactions",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "Hypothesis Testing for Interactions",
    "text": "Hypothesis Testing for Interactions\nTo test for the significance of an interaction term and generate a confidence interval around the non-reference category, we use a contrast test:\n\\[\nH_0: c_0\\beta_0 + c_1\\beta_1 + c_2\\beta_2 + c_3\\beta_3 = 0\n\\]",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#multicollinearity",
    "href": "applied-chapter01.html#multicollinearity",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "Multicollinearity",
    "text": "Multicollinearity\nMulticollinearity occurs when two or more explanatory variables are highly correlated, leading to:\n\nDifficulty in holding other variables fixed.\nIncreased uncertainty in coefficient estimates (wider intervals, larger p-values).\nDrastic changes in conclusions when variables are added or removed.\n\n\nVariance Inflation Factor (VIF)\nVIF measures how much a predictor is correlated with other predictors:\n\nHigher correlation between predictors results in a higher VIF and larger standard errors (\\(SE(\\beta)\\)).\n\\(SE(\\beta)\\) is a function of the relationship between the variability of the response, predictors, and the VIF.\nVIF \\(\\approx\\) 1: No collinearity.\n\\(5 &lt; \\text{VIF} &lt; 10\\): Mild collinearity, investigate further.\nVIF &gt; 10: Severe collinearity, investigate adjustments.\n\nHigh VIFs are not always concerning.\n\nExpected with polynomial terms and interaction terms.\nCommon for categorical variables with with more than two levels.\nIf interpreting only one coefficient, and it has a low VIF, multicollinearity may not be an issue (i.e., if you are just accounting for the other variables).",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter01.html#addressing-multicollinearity",
    "href": "applied-chapter01.html#addressing-multicollinearity",
    "title": "Multiple Linear Regression (MLR) Revisited",
    "section": "Addressing Multicollinearity",
    "text": "Addressing Multicollinearity\n\nScenario 1: Predefined Research Questions\n\nStart with a hypothesis and a plan to test it.\nFit model and check assumptions.\nCheck for multicollinearity using VIFs and graphics. Consider secondary analysis if multicollinearity is a concern.\nReport findings including and excluding variables with multicollinearity concerns.\nPossible solutions:\n\nAggregate correlated variables into a single variable.\nUse data reduction strategies such as Principal Component Analysis (PCA).\n\n\n\n\nScenario 2: Exploratory Model Building\n\nUsed when the goal is an interpretable model, but no predefined hypothesis exists.\nIdentify key predictors.\nUse model selection techniques to minimize collinearity.\n\n\n\nScenario 3: Predictive Modeling\n\nMulticollinearity is not a concern when the goal is pure prediction.\nIt only affects coefficient standard errors (SE) and the hypothesis testing framework.\nThe focus is on model performance, not coefficient interpretation.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Multiple Linear Regression (MLR) Revisited</span>"
    ]
  },
  {
    "objectID": "applied-chapter02.html",
    "href": "applied-chapter02.html",
    "title": "The Bias Variance Trade-off",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>The Bias Variance Trade-off</span>"
    ]
  },
  {
    "objectID": "applied-chapter02.html#objectives",
    "href": "applied-chapter02.html#objectives",
    "title": "The Bias Variance Trade-off",
    "section": "",
    "text": "Understand challenges in building models.\nRecognize and explain the bias-variance trade-off.\nUnderstand the basics of feature selection.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>The Bias Variance Trade-off</span>"
    ]
  },
  {
    "objectID": "applied-chapter02.html#challenges-with-building-models",
    "href": "applied-chapter02.html#challenges-with-building-models",
    "title": "The Bias Variance Trade-off",
    "section": "Challenges with Building Models",
    "text": "Challenges with Building Models\nWhen faced with a large number of possible predictor variables, deciding where to start and how to choose can be challenging. Important considerations include:\n\nMany predictors may not be relevant.\nIn some domains, such as medicine, prediction accuracy is critical.\nSample size limitations—having many variables but a small sample size—can lead to overfitting.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>The Bias Variance Trade-off</span>"
    ]
  },
  {
    "objectID": "applied-chapter02.html#model-reproducibility",
    "href": "applied-chapter02.html#model-reproducibility",
    "title": "The Bias Variance Trade-off",
    "section": "Model Reproducibility",
    "text": "Model Reproducibility\nFor regression models, the most common accuracy measure is mean squared error (MSE), calculated as the sum of squared error divided by the sample size. \\[\nMSE = \\frac{\\sum (y_i - \\hat{y}_i)^2}{n}\n\\]\n\nPitfalls of Using Training Data for MSE\nIf we calculate MSE on the same data used to build the model:\n\nThe MSE values are unreliable for comparing models:\n\nThey favor overly complex models.\nThey can be driven artificially to zero.\n\nThere is no guarantee that MSE will generalize to new data.\n\n\n\nEnsuring Reproducibility\nA common approach is:\n\nSplitting the data into a training set (70-80%) and a validation set.\n\nAnother best practice is to split the data into a training and holdout testing set.\n\nThen split the training set into a training and validation set for CV and/or hyperparameter tuning.\n\nUsing the training set to fit the model.\nPredicting on the validation set and computing the validation MSE.\n\n\nMetrics like \\(R^2\\), Adjusted \\(R^2\\), and Information Criteria\n\nThese are computed on the training data and tend to favor complex models.\nPreferred metrics derived from the training data include AIC and BIC for model selection.\n\n\n\nKey Takeaways\n\nModel evaluation should always be based on an independent validation dataset.\nPlotting validation MSE for models from least to most complex helps identify the best fit without performance issues.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>The Bias Variance Trade-off</span>"
    ]
  },
  {
    "objectID": "applied-chapter02.html#bias-variance-trade-off",
    "href": "applied-chapter02.html#bias-variance-trade-off",
    "title": "The Bias Variance Trade-off",
    "section": "Bias-Variance Trade-Off",
    "text": "Bias-Variance Trade-Off\n\nUnderstanding the Trade-Off\nComparing models from least to most complex:\n\nTraining MSE always decreases with complexity.\nValidation MSE follows a U-shape (this is the bias-variance trade-off).\n\n\n\nDecomposing MSE\nThe expected validation MSE can be decomposed as: \\[\nE[\\text{MSE}_{\\text{valid}}] = \\text{Var}(\\hat{f}) + \\text{Bias}(\\hat{f})^2 + \\text{Var}(\\epsilon)\n\\] where:\n\n\\(\\text{Var}(\\hat{f})\\) measures how much the model changes across different datasets.\n\\(\\text{Bias}(\\hat{f})\\) measures how far the model’s predictions are from the true values on average.\n\\(\\text{Var}(\\epsilon)\\) is the irreducible error due to natural variation (variation around true trend line).\n\n\n\nScenarios:\n\nHigh Bias / Low Variance: Simple models (e.g., linear regression on a cubic relationship) consistently make errors (bias) but are stable across datasets.\nModerate Bias / Moderate Variance: Quadratic fits for a cubid relationship still have bias but are more stable (fits are consistent).\nLow Bias / Low Variance: Cubic fits (the true model) perform well and are stable.\nNo Bias / Moderate Variance: Overly complex models predict well on average but vary significantly across datasets. Poor generalization results in poor accuracy.\nNo Bias / High Variance: Extreme complexity leads to models that fit each dataset uniquely but fail to generalize.\n\nOverfitting: When a model has poor validation MSE due to high variance. It fits the training dataset well, but it can’t generalize to other datasets.\nUnderfitting: When a model has high bias and fails to capture the true trend.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>The Bias Variance Trade-off</span>"
    ]
  },
  {
    "objectID": "applied-chapter02.html#k-fold-cross-validation",
    "href": "applied-chapter02.html#k-fold-cross-validation",
    "title": "The Bias Variance Trade-off",
    "section": "K-Fold Cross Validation",
    "text": "K-Fold Cross Validation\n\nIssues with Train/Validation Splitting\n\nSmall datasets may not allow for a reliable split.\nValidation MSE varies depending on the chosen train/validation sets.\n\n\n\nK-Fold Cross Validation Process\n\nPartition the dataset into \\(k\\) disjoint subsets.\nFor each subset (fold):\n\nLeave it out as a test set.\nTrain on the remaining \\(k-1\\) folds.\nCompute validation MSE.\n\nCompute the average validation MSE.\n\n\nNote: In practice, typically 5-10 folds are used to keep computational cost down.\n\n\n\nAdvantages of K-Fold Cross Validation\n\nProvides a better estimate of true MSE.\nReduces dependence on any single train/validation split.\nCommonly implemented in statistical software to assess the bias-variance trade-off.\n\n\nLeave-One-Out Cross Validation (LOOCV)\n\nA special case where \\(k=n\\) (each observation is left out once), which is common in statistical methodology.\nComputationally expensive but useful for very small datasets.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>The Bias Variance Trade-off</span>"
    ]
  },
  {
    "objectID": "applied-chapter02.html#feature-selection-via-penalized-regression",
    "href": "applied-chapter02.html#feature-selection-via-penalized-regression",
    "title": "The Bias Variance Trade-off",
    "section": "Feature Selection via Penalized Regression",
    "text": "Feature Selection via Penalized Regression\n\nWhy Feature Selection?\n\nFeature selection helps balance the bias-variance trade-off by reducing complexity while maintaining predictive power.\nIt is the process of using an automated procedure to determine what explanatory variable should or should not be in a model.\n\n\n\nFeature Selection Methods of Modeling Tools\nWhen using a new tool, it’s important to consider if and how it handles feature selection.\n\nMultiple Linear Regression (MLR): Stepwise selection (forward, backward, best subset, hybrids) and penalized regression\n\nStepwise feature selection, the original approach, sequentially adds and/or removes predictors looking for the best subset, usually comparing model fits with some criteria (minimize AIC, BIC, validation MSE, or k-fold CV).\nPenalized regression effectively forces some of the coefficients zero, so the predictor is multiplied by zero and removed from the model.\n\nTree-based methods (Random Forests): Built-in feature selection\nK-Nearest Neighbors (K-NN): No direct feature selection\n\n\n\nPenalized Regression Approaches\n\nRidge Regression (older method)\nLasso Regression (forces some coefficients to zero)\nElastic Net (GLM-NET) (combines Ridge and Lasso)\n\n\nKey Idea\nInstead of minimizing just the residual sum of squares (RSS) to estimate coefficients, penalized regression minimizes the RSS plus a penalty term controlled by its own parameter, \\(\\lambda\\). \\[\nRSS + \\lambda \\sum |\\beta_j|^p\n\\] where:\n\n\\(p=1\\) for Lasso\n\n\\(p=2\\) for Ridge\n\n\\(\\lambda\\) is a penalty parameter\n\nFor Elastic Net, the penalty equation is: \\[\nRSS + \\lambda \\left[ (1 - \\alpha) \\sum \\beta_j^2 + \\alpha \\sum |\\beta_j| \\right]\n\\] where \\(\\alpha\\), the mixing parameter, determines the mix between Ridge (\\(\\alpha=0\\)) and Lasso (\\(\\alpha=1\\)).\n\n\n\nHow Penalized Regression Works\n\nLow penalty: Similar to standard MLR (all coefficients remain).\nHigh penalty: Coefficients shrink towards zero (some are removed).\n\nForces the fit to be worse on the training set to improve generalization on future datasets.\n\n\n\nChoosing the Penalty (\\(\\lambda\\))\n\nDetermined using k-fold cross-validation.\n\nUse an MSE plot to compare different values of \\(\\lambda\\).\n\nLarger penalties lead to smaller, simpler models.\nThe penalty is a function of both the penalty term and the coefficient values.\n\nA larger penalty term increases the total penalty, and the only way to minimize RSS + penalty is to shrink or eliminate some coefficients.\n\n\n\n\n\nRidge vs. Lasso vs. GLM-NET\n\nLasso (\\(\\alpha=1\\)): Performs true feature selection by forcing some coefficients to zero.\nRidge (\\(\\alpha=0\\)): Shrinks coefficients but does not eliminate them.\nElastic Net (\\(0 &lt; \\alpha &lt; 1\\)): A compromise between Lasso and Ridge.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>The Bias Variance Trade-off</span>"
    ]
  },
  {
    "objectID": "applied-chapter02.html#recap-and-considerations",
    "href": "applied-chapter02.html#recap-and-considerations",
    "title": "The Bias Variance Trade-off",
    "section": "Recap and Considerations",
    "text": "Recap and Considerations\n\nModel Selection Strategies\n\nThe bias-variance trade-off explains why some models generalize and predict better on future datasets.\nValidation and k-fold cross-validation both assess and compare model performance.\nPenalized regression helps eliminate unimportant predictors.\n\n\n\nChoosing the Right Approach\n\nPenalized regression works well if many candidate variables are unimportant.\n\nLasso: Best for feature selection (drops predictors entirely) and reduces multicollinearity (dampens VIFs).\nRidge: Reduces multicollinearity (dampens VIFs) but retains all predictors (does not force coefficients to zero).\n\nStepwise Selection: Still valid but should be based on AIC, validation sets, or k-fold CV, not p-values or \\(R^2\\).\n\n\n\nFeature Selection and Hypothesis Testing\n\nPenalized regression does not provide t-statistics, p-values, or confidence intervals.\nCommon approach:\n\nIdentify dropped predictors.\nRefit MLR with only the selected predictors.\nReport p-values and confidence intervals.\n\n\n\n\nCaution: Multiple Testing Issues\n\nConducting hypothesis tests after feature selection inflates Type I error rates.\n\nMultiple testing issues result in a family-wise error rate.\nThe interpretation isn’t conservative enough. The CIs are too narrow, and the p-values are too small.\n\nSolutions:\n\nTreat feature selection as part of the train/validation process, which reduces sample size and raises the threshold for significance.\n\nUse the training set for feature selection.\nFit the model and report p-values using the validation set.\n\nUse specialized inference methods (e.g., R package selectionInference for LASSO).\n\n\n\n\nFinal Considerations\n\nFeature selection is a tool that improves model interpretability.\nStatistical assumptions must still be checked.\nEDA remains crucial in model building.\nGraphical assessment is necessary to determine whether additional complexity terms are needed, such as polynomials and interaction terms to fit different slopes.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>The Bias Variance Trade-off</span>"
    ]
  },
  {
    "objectID": "applied-chapter03.html",
    "href": "applied-chapter03.html",
    "title": "The Bootstrap",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>The Bootstrap</span>"
    ]
  },
  {
    "objectID": "applied-chapter03.html#objectives",
    "href": "applied-chapter03.html#objectives",
    "title": "The Bootstrap",
    "section": "",
    "text": "Understand the bootstrap procedure.\n\nRecognize its benefits for inference and prediction.\n\nApply the bootstrap to estimate uncertainty.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>The Bootstrap</span>"
    ]
  },
  {
    "objectID": "applied-chapter03.html#bootstrap-procedure",
    "href": "applied-chapter03.html#bootstrap-procedure",
    "title": "The Bootstrap",
    "section": "Bootstrap Procedure",
    "text": "Bootstrap Procedure\n\nOverview\nThe bootstrap is a resampling method that allows us to:\n\nEstimate the variability (uncertainty) of statistical estimators.\n\nPerform statistical inference, such as hypothesis testing and confidence intervals.\n\nEnhance predictive modeling by stabilizing estimates in high-variance models.\n\n\n\nKey Benefits\nDifficulties in Multiple Linear Regression (MLR) that bootstrap addresses:\n\nNo transformation adequately satisfies model assumptions.\n\nTransformations that improve assumptions reduce interpretability, which is needed for the situation.\n\nA complex model is required but introduces high variance (overfitting).\n\nThe bootstrap is heavily used in nonparametric predictive modeling, such as random forests, where high variance is common, and it can be used in many statistical procedures.\n\n\nConceptual Understanding\n\nStandard Errors and Uncertainty\n\nWhen assumptions are not met, standard errors (SE) are often incorrect.\n\nSE is critical for quantifying the variability of estimators like the mean.\n\nExample: The standard error of the mean is:\n\\[  \nSE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}  \n\\]\n\nHowever, for statistics like the median or trimmed mean, there is no simple theoretical SE formula. This makes bootstrap-based estimation particularly valuable.\n\n\n\n\nImpact of Outliers on SE\n\nThe mean is highly sensitive to outliers, while the median is more robust.\n\nThe standard error of the mean has a known formula: \\[\nSE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\n\\] whereas the SE for the median is unknown.\n\nThe bootstrap provides a way to estimate SE for any statistic, even when no closed-form solution exists.\n\n\n\nKey Analogy\n\nThe population is to the sample as the sample is to the bootstrap samples.\n\n\n\nMain Idea\n\nThe bootstrap mimics the process of generating a sampling distribution.\n\nThe resulting bootstrap distribution allows:\n\nEstimation of SE for any statistic.\n\nComputation of confidence intervals (CIs).\n\n\nThe standard deviation of the bootstrap distribution directly serves as an estimate of the standard error of the statistic, because each bootstrap sample has the same size as the original dataset.\n\n\n\nPseudo-Code for Bootstrap Sampling\n\nDetermine the sample size \\(n\\).\n\nRandomly sample \\(n\\) observations with replacement from the dataset to obtain a bootstrap sample.\n\nCompute the statistic of interest (e.g., mean, median).\n\nRepeat steps 2 and 3 \\(B\\) times (typically \\(B = 1000\\) or more).\n\nUse the resulting bootstrap distribution for inference.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>The Bootstrap</span>"
    ]
  },
  {
    "objectID": "applied-chapter03.html#statistical-inference-using-the-bootstrap",
    "href": "applied-chapter03.html#statistical-inference-using-the-bootstrap",
    "title": "The Bootstrap",
    "section": "Statistical Inference Using the Bootstrap",
    "text": "Statistical Inference Using the Bootstrap\n\nBootstrap Confidence Intervals\nThe bootstrap is commonly used to construct confidence intervals (CIs). There are five major approaches:\n\nPercentile Bootstrap (Basic)\n\nEmpirical Bootstrap\n\nBootstrap \\(t\\)-Intervals\n\nBias-Corrected and Accelerated (BCa) Bootstrap\n\nABC Method\n\n\nPercentile Bootstrap Intervals\n\nUses the empirical distribution of the bootstrap samples, which is the most intuitive approach and easiest to implement.\n\nFor a 95% CI, take the 2.5th and 97.5th percentiles from the bootstrap distribution.\n\nNo parametric assumptions of the distribution of data are required.\n\n\nIssues\n\nMay not achieve the nominal coverage probability (e.g., a 95% CI may only contain the true parameter 90% of the time).\n\nCauses:\n\nBias in the center of the bootstrap distribution.\n\nSkewness in the bootstrap distribution.\n\n\nProblems arise when dealing with nuisance parameters (e.g., variance in regression models).\n\n\n\n\nAlternative Approaches\nSeveral adjustments improve upon the percentile bootstrap:\n\nEmpirical Bootstrap (addresses bias only).\n\nBootstrap \\(t\\)-intervals.\n\nBCa Bootstrap (corrects for both bias and skewness).\n\nABC Method (can be computationally demanding).",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>The Bootstrap</span>"
    ]
  },
  {
    "objectID": "applied-chapter03.html#bootstrapping-in-multiple-linear-regression",
    "href": "applied-chapter03.html#bootstrapping-in-multiple-linear-regression",
    "title": "The Bootstrap",
    "section": "Bootstrapping in Multiple Linear Regression",
    "text": "Bootstrapping in Multiple Linear Regression\nThere are two main bootstrap approaches for MLR:\n\nBootstrapping Pairs handles violations of normality and constant variance.\n\nBootstrapping Residuals:\n\nAssumes normality of residuals.\n\nAddresses high leverage points by resampling residuals rather than entire observations.\n\nNot recommended when there are violations of constant variance. A special type, the wild bootstrap, is effective for handling heteroskedasticity.\n\n\n\nBootstrapping Pairs\n\nProcess\n\nSample entire rows of data (predictor-response pairs) with replacement.\n\nEach observed response value remains paired with its corresponding predictor values (i.e., values in the whole row stay together).\n\nFit the regression model on each resampled dataset (bootstrap sample).\n\nObtain a sampling distribution of regression coefficients.\n\n\n\nKey Benefit\n\nPreserves the original structure of the data, including any existing nonconstant variance.\n\n\n\n\nBootstrapping Residuals\n\nProcess\n\nFit the model \\(Y = f(X) + \\epsilon\\) to obtain residuals.\n\nResample the residuals with replacement.\n\nCreate new responses using: \\(Y^* = \\hat{Y} + \\text{bootstrap residual}\\)\n\nThe new bootstrapped response is created by adding bootstrapped errors to the predicted values from the original fit.\n\n\nFit the model to the new dataset and store coefficients to build the sampling distribution.\n\n\n\nLimitations\n\nAssumes independence.\n\nNot recommended when variance is nonconstant, as the nonconstant variance property is lost.\n\nMay drop low-frequency categorical levels:\n\nConsider collapsing levels before bootstrapping.\n\nOtherwise, a level might be missing, causing the corresponding coefficient to be omitted—this is especially problematic when coding your own bootstrap procedure.\n\n\n\n\nImplementation\n\nThe lmboot R package provides tools for bootstrapping residuals.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>The Bootstrap</span>"
    ]
  },
  {
    "objectID": "applied-chapter03.html#bootstrap-in-predictive-modeling-ensembling-and-bagging",
    "href": "applied-chapter03.html#bootstrap-in-predictive-modeling-ensembling-and-bagging",
    "title": "The Bootstrap",
    "section": "Bootstrap in Predictive Modeling: Ensembling and Bagging",
    "text": "Bootstrap in Predictive Modeling: Ensembling and Bagging\nThe bootstrap plays a crucial role in predictive modeling, particularly in ensemble methods.\n\nLeo Breiman developed bagging and was one of the first to use the bootstrap in a non-classical way of developing confidence intervals.\n\n\nEnsembling\n\nTrain multiple models (of different types) on a training data set.\n\nMake predictions for the same observation across all models.\n\nAverage the predictions to reduce variance.\n\n\nWhy It Works\n\nEach model’s predictions have their own mean squared error (MSE), which includes both bias and variance.\n\nAveraging predictions primarily reduces the variance component — the ensemble’s variance is generally smaller than that of individual models, so overall MSE tends to decrease in larger ensembles.\nThis helps smooth out overfitting by reducing variance and leads to more stable predictions.\n\nHowever, the variance reduction is not as strong as in traditional averaging (e.g., averaging independent sample means, \\(\\bar{X}\\)s) because all models are trained on the same dataset.\n\n\n\n\nBias-Variance Trade-off in Ensembling\n\nFit high-variance models intentionally (e.g., deep decision trees or complex models).\n\nAveraging dampens variance while retaining predictive power.\n\nThe final ensemble model can achieve both low bias and lower variance, assuming the base models started with low bias.\n\n\n\nBootstrap Aggregation (Bagging)\n\nBagging (Bootstrap Aggregation) extends ensembling to improve prediction accuracy for a single model type.\n\nInstead of different model types, bagging:\n\nUses bootstrap resampling to create different training datasets.\n\nFits the same model type (e.g., decision trees) on each bootstrap sample.\n\nAverages predictions across all models (e.g., “bag” a decision tree model).\n\n\n\nWhy Bagging Works\n\nA single MLR model trained on the same data always yields the same results.\n\nResampling with replacement introduces variation, enabling bagging to improve performance.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>The Bootstrap</span>"
    ]
  },
  {
    "objectID": "applied-chapter03.html#recap",
    "href": "applied-chapter03.html#recap",
    "title": "The Bootstrap",
    "section": "Recap",
    "text": "Recap\n\nBootstrap Inference\n\nThe bootstrap enables nonparametric estimation of standard errors (SE) without strict distributional assumptions.\n\nThe independence assumption still applies.\n\nBootstrap regression SE estimates tend to be better than MLR SE estimates if the model is too simple and fails to capture the true trend or complexity.\n\n\nSeveral approaches exist for constructing confidence intervals, with BCa and bootstrap \\(t\\)-intervals being more robust than percentile bootstrap.\n\nException: Avoid BCa for small sample sizes, as estimating skewness is unreliable.\n\n\nPaired bootstrap is preferred for regression models with nonconstant variance.\n\nThe bootstrap can provide inference on penalized regression coefficient estimates.\n\nParametric bootstrap methods exist, but they retain model assumptions.\n\nResamples come from a theoretical distribution rather than from the actual dataset (i.e., a simulated dataset).\n\n\nRepresentative samples are crucial for accurate inference.\n\nAlthough bootstrapping is often used in nonparametric small-sample methods, it still requires a representative sample to capture the true distribution.\n\nSmall sample sizes may fail to provide an accurate representation of the population, limiting the effectiveness of bootstrapping.\n\n\n\n\nBagging Recap\n\nBagging is a powerful ensemble technique that stabilizes high-variance models from a single prediction tool.\n\nIt sacrifices interpretability for a gain in predictive performance.\n\nIt is less effective for MLR (since MLR is usually biased rather than high variance).\n\nIt is particularly valuable for:\n\nTree-based models (e.g., decision trees, random forests).\n\nFeature selection in unstable models, where small changes in data can cause significant variation in the selected features.\n\n\n\n\nPractical Considerations\n\nBootstrap for inference: Use 1000-5000 bootstrap samples.\n\nBagging: Typically requires 100-500 bootstrap samples.\n\nOut-of-bag (OOB) error provides an internal validation estimate derived from the observations that weren’t included in the bootstrap sample (similar to cross-validation).\n\n\n\nFinal Thoughts\nThe bootstrap is one of the most impactful contributions to statistics and data science in the past 40 years. Understanding its applications in both statistical inference and machine learning is critical for data scientists.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>The Bootstrap</span>"
    ]
  },
  {
    "objectID": "applied-chapter04.html",
    "href": "applied-chapter04.html",
    "title": "Communicating with Clients",
    "section": "",
    "text": "Objectives\nThis chapter covers key aspects of communicating statistical analyses effectively, including:",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Communicating with Clients</span>"
    ]
  },
  {
    "objectID": "applied-chapter04.html#objectives",
    "href": "applied-chapter04.html#objectives",
    "title": "Communicating with Clients",
    "section": "",
    "text": "Consulting and interacting with clients\nApplying models in practice\nEffective communication strategies\nHandling missing data\nInterpreting Mean Squared Error (MSE)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Communicating with Clients</span>"
    ]
  },
  {
    "objectID": "applied-chapter04.html#consulting",
    "href": "applied-chapter04.html#consulting",
    "title": "Communicating with Clients",
    "section": "Consulting",
    "text": "Consulting\n\nStatistical Toolset\nA consultant’s statistical toolbox includes:\n\nGroup comparisons\nNonparametric methods\nRegression analysis\nFeature selection (penalized regression, stepwise selection)\nBootstrap and bagging\n\n\n\nKey Questions Before Starting\n\nWhat should I consider before beginning the analysis?\nWhat should the overall plan be?\nHow do I communicate my findings effectively?\n\n\n\nChallenges for New Analysts\n\nNot fully understanding client needs\nOverlooking what the dataset offers\n\n\n\nEffective Communication with Clients\nGood opening lines when talking to clients with limited statistical knowledge:\n\n“Tell me about your study/project.”\n\nAvoid asking, “How can I help?” or “What do you need?”, as these may bias your understanding.\n\n\n\nExtracting Key Information\n\nStudy Goals\n\nIs the purpose to explain, predict, or both?\nIs the response variable numerical, categorical, count, or something else?\nAre there specific questions the client wants to answer?\nIf predicting, does the client want to quantify how predictors contribute to response changes?\n\n\n\nPopulation and Data Collection\n\nWhat is the target population, and how was data collected?\nCan conclusions apply to a slightly smaller population?\nAre some variables hard to obtain/measure or unreliable?\nAre measurements repeatable?\nIs each observation independent?\n\n\n\nPractical Considerations\n\nWhat are meaningful differences, slopes, or accuracy metrics?\nWhat actions will be taken based on the results?\n\n\n\nWhy This Information Matters\n\nResponse variable type determines the appropriate method (e.g., regression vs. classification).\nUnderstanding the goal (explanation vs. prediction) helps select appropriate statistical tools.\n\ne.g., selecting a tool that supports hypothesis testing if required\n\nSome people use “predict” loosely, meaning correlation or association tests instead.\nAdjusting population definition can impact:\n\nHandling missing data\nIdentifying population restrictions (e.g., specific patient subsets like lupus patients prior to treatment)\n\n\n\n\nData Reliability and Independence\n\nIs the data an accurate reflection of reality?\n\nConsider biases in reporting (e.g., self-reported data like race).\nInstrument reliability and potential degradation over time.\nIf you measure again, will you get the same value?\n\nHelps identify important explanatory variables and confounding variables.\n\n\nIndependence assumption is influenced by data collection methods:\n\nStudents from the same district may not be independent.\nTime series data may have autocorrelation.\nSpatially close observations may be correlated.\n\n\n\n\n\nPractical vs. Statistical Significance\n\nEnsures results are interpreted correctly and not overemphasized\n\n\n\nConsiderations for Predictive Modeling\n\nModel readiness for deployment\nNeed for additional/better predictors\nRedefining response variables\nCollecting more data for refinement\nIdentifying whether hypothesis testing is needed for decision-making\nComputation needs for model deployment (beyond the scope of this course)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Communicating with Clients</span>"
    ]
  },
  {
    "objectID": "applied-chapter04.html#big-data-considerations",
    "href": "applied-chapter04.html#big-data-considerations",
    "title": "Communicating with Clients",
    "section": "Big Data Considerations",
    "text": "Big Data Considerations\n\nGoogle Flu Trends (GFT) Case Study\n\nBackground: CDC reports flu-related doctor visits with a 1-2 week lag. GFT aimed to predict these visits with a 1-day lag.\nIssue: GFT overestimated doctor visits by almost 2x.\n\n\n\nBig Data Hubris\n\nAssumes big data fixes all statistical issues, including sampling biases (i.e., sampling that isn’t random).\nMany big data sources are not from highly accurate scientific instruments.\n“Garbage in, garbage out” principle applies.\n\n\n\nUnderstanding Model Predictions\n\nFlu season coincides with winter.\nGFT detected both flu and winter, leading to misleading predictors.\n\nImportant predictors were basketball related (i.e., winter sport related).\n\n\n\n\nTemporal Dependencies in Prediction Models\n\nErrors in prediction models are often not independent over time.\n\nThe correlation within prediction errors can be used to improve model accuracy.\n\n\n\nData Snooping and Overfitting\n\nThe more predictors included, the higher the chance of falsely finding statistical significance (Type I error).\nWhen the number of predictors is much higher than the number of observations, overfitting is much more likely.\n\n\n\nAlgorithm Dynamics and Data Stability\n\nChanging the algorithm that produces your dataset can fundamentally alter its properties.\n\nIs the measurement of a variable stable and comparable across cases and over time?\n\n\n\nDatabase Logistics\n\nJust because data is available doesn’t mean all of it should be used.\nConsider:\n\nSampling appropriately to represent the target population.\nMeasurement error risks (i.e., consider the error risk of variables).\nThe necessity of specific variables - which ones are practically important?",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Communicating with Clients</span>"
    ]
  },
  {
    "objectID": "applied-chapter04.html#regression-models-in-practice",
    "href": "applied-chapter04.html#regression-models-in-practice",
    "title": "Communicating with Clients",
    "section": "Regression Models in Practice",
    "text": "Regression Models in Practice\n\nGeneral Workflow\nThe general workflow for regression is a highly iterative process.\n\nData Processing: Cleaning, curation, dropping variables\nExploratory Data Analysis (EDA):\n\nSummary statistics\nVisualization\nLight modeling for insight and assumption checking\n\nModel Building:\n\nFeature selection\nTuning (cross-validation)\nManual iteration\nAssumption checking and fixing\n\nCommunicating Results:\n\nHypothesis testing and interpretation\nReport prediction performance metrics (validation set results)\nModel comparison (provide a table, e.g., non-parametric vs. parametric)\nDeployment strategy\n\n\n\nAdvice: Avoid excessive iteration to prevent overfitting. Ensure models use the same finalized, processed dataset.\n\n\nBe mindful that the way missing data is handled can influence which population your model represents. For example, if missing values are not missing at random and are removed, the final dataset may not be representative of the full population.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Communicating with Clients</span>"
    ]
  },
  {
    "objectID": "applied-chapter04.html#communicating-results",
    "href": "applied-chapter04.html#communicating-results",
    "title": "Communicating with Clients",
    "section": "Communicating Results",
    "text": "Communicating Results\n\nChallenges\n\nIterative nature of analysis makes summarization difficult\nFinding the right level of technical detail for the audience\nTime and page constraints\n\n\n\nStructuring Reports and Presentations\n\nTry to summarize your approach and workflow by mimicking a theoretical linear workflow.\n\nAdditional details can be placed in an appendix at the back of a written report or at the end of a presentation.\n\nA well-structured report typically includes:\n\nProblem Statement and Presentation Overview\n\nClearly define the objective and goals.\n\nProvide a brief outline of the report structure, especially if there are:\n\nMultiple objectives\n\nMultiple approaches\n\nAppendices for more detailed information\n\n\n\nData Description and Processing Summary\n\nDefine key variables and their roles in the analysis.\n\nWhen using coded variables, provide a table mapping codes to actual names.\n\nConsider including data types (numeric, categorical, etc.), as different analysts may interpret variables differently.\n\nSummarize how data processing was conducted.\n\n\nExploratory Data Analysis (EDA)\n\nHighlight important relationships between variables.\n\nUse summary statistics and visualizations to articulate key insights.\n\n\nResults and Interpretation\n\nProvide a clear explanation of the final model’s findings.\n\nInterpret coefficients and/or evaluate predictive performance.\n\nExplain whether the error magnitude is meaningful in the real-world application.\n\n\nConclusions and Work-in-Progress (WIP)\n\nOffer brief global conclusions and next steps.\n\nIf there are multiple problem statements, repeat steps 3 & 4 as needed.\n\n\n\n\n\nData Processing Considerations\n\nEnsure that the final processed dataset aligns with EDA and model inputs.\nSummarize missing data handling without excessive technical detail.\n\n\n\nPresenting EDA Findings\n\nSummary statistics\n\nShould always be provided. Include mean, standard deviation, 5-number summary (median, min/max), and category counts or proportions.\nProvide reader/audience a way to sanity check basic things.\nCan provide intuition for what parts of the model is doing. For example, why are you running KNN on predictors that are z-scored (or otherwise scaled)?\n\n\n\nGraphics and Tables\n\nDon’t assume that figures speak for themselves—explicitly reference them. (Additional figures can be included in an appendix.)\nIf a graph is too cluttered, either simplify it or guide the audience’s focus.\n\n\n\nShowing Trends\n\nEDA visuals used for model-building may not be the best for presentation.\nFocus on how the response variable relates to predictors.\nHighlight trends that justify interaction terms or transformations.\nAvoid overemphasizing multicollinearity unless it directly affects interpretation.\nConsider parsing out numerical and categorical variables with either scatterplots or boxplots.\nBuild the audience’s intuition of the final model, highlight important relationships and unimportant ones when a variable was part of the question of interest.\n\n\n\n\nRegression Tables\n\nConsider whether the audience needs to see p-values and t-statistics.\n\nWould confidence intervals and significance markers (*, **, ***, etc.) be clearer?\nCan results be reformatted to show only essential information?\nAvoid overwhelming the audience with statistics and technical details that aren’t being used in interpretation.\n\n\n\n\nInterpreting Mean Squared Error (MSE)\n\nMSE measures prediction error, balancing bias and variance.\nA lower MSE does not always mean a better model:\n\nPractical significance matters:\n\nA model predicting hospital stay within ~1 day may be useful, even if another model has a slightly lower MSE but lacks interpretability.\nA model achieving a lower MSE but only predicting the mean hospital stay may not be useful.\n\n\nMSE should be considered alongside generalization ability, interpretability, and real-world usefulness.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Communicating with Clients</span>"
    ]
  },
  {
    "objectID": "applied-chapter04.html#handling-missing-data",
    "href": "applied-chapter04.html#handling-missing-data",
    "title": "Communicating with Clients",
    "section": "Handling Missing Data",
    "text": "Handling Missing Data\n\nTypes of Missing Data\n\nMissing Completely at Random (MCAR)\n\nThe missing observations form a random subset of all observations.\n\nThe data removed is consistent with the data kept, meaning:\n\nSimilar summary statistics, correlation behavior, and distributions.\n\nListwise deletion is acceptable, and imputation is also an option.\n\n\n\nMissing at Random (MAR)\n\nThe probability of missingness depends on observed covariates but not on the missing values themselves.\n\nIf you stratify the data by a known variable, the missing data within each subgroup is MCAR.\nExample: If income values are missing more often for older individuals, but within each age group the missingness is random, then the data is MAR.\n\nListwise deletion is generally not recommended, but may be acceptable if the covariate influencing missingness is not important in the model.\n\nImputation is preferred if the covariate affects the response variable or other predictors.\n\n\n\nMissing Not at Random (MNAR)\n\nA systematic reason exists for why certain values are missing.\n\nThe probability of missingness depends on the missing values themselves, meaning the reason for missingness is unknown or systematic.\n\nExample: If people with higher incomes are less likely to report their salary, then missingness depends on the unobserved income values themselves\n\nCatch-all category for cases that do not satisfy MCAR or MAR conditions.\n\nListwise deletion is not okay, and imputation may not be possible without strong assumptions.\n\n\n\n\nDeletion Considerations\n\nMost statistical software deletes rows with missing data by default, but this:\n\nReduces sample size.\n\nChanges population representation, potentially introducing bias.\n\n\nWhen is deletion acceptable?\n\nMCAR: Deletion is valid because missingness is random.\nMAR: Deletion may be justifiable if the missingness is due to a covariate that is not relevant to the analysis.\n\nHowever, if the covariate affects the response or other predictors, deletion is not recommended, and imputation should be considered.\n\n\nMNAR: Deletion should not be used, as missingness is related to the values themselves and may distort the results.\nWith MCAR or MAR, consider:\n\nSummary statistics and comparisons of deleted vs. retained data.\n\nWhether deletion skews the population of interest.\n\n\n\n\n\nImputation Methods\nThere are multiple ways to replace missing values with reasonable estimates.\n\nSimple Imputation\n\nReplace missing values with mean, median, or mode (for categorical values).\nLimitations:\n\nOnly reasonable when missing data is truly random (MCAR).\n\nCan distort distributions if a large proportion of data is missing.\n\n\n\n\nRegression Imputation\n\nFit a regression model on complete data.\nPredict missing values using the model.\nRepeat for each variable with missing values.\n\n\nThe variable with missing values becomes the response variable in this prediction problem.\nCan be extended to classification models for categorical variables.\nImputation should exclude the true response variable.\n\n\n\n\nPractical Imputation Strategies\n\nStratify data when imputing (e.g., by country or demographic groups).\nUse visualizations to assess missing data patterns.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Communicating with Clients</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html",
    "href": "applied-chapter05.html",
    "title": "Matrices",
    "section": "",
    "text": "Objectives\nThis chapter explores fundamental matrix concepts, including operations, applications in summarizing data, and their role in multiple linear regression.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#objectives",
    "href": "applied-chapter05.html#objectives",
    "title": "Matrices",
    "section": "",
    "text": "Review fundamental matrix operations and properties.\n\nUnderstand special cases of matrix multiplication.\n\nApply matrix concepts to summarize multivariate data (e.g., multivariate normal distribution).\n\nExplore how matrix algebra supports multiple linear regression (MLR).",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#review-of-matrix-operations",
    "href": "applied-chapter05.html#review-of-matrix-operations",
    "title": "Matrices",
    "section": "Review of Matrix Operations",
    "text": "Review of Matrix Operations\n\nSymmetric Matrices\n\nA symmetric matrix has the same number of rows and columns (i.e, a square matrix).\n\n\n\nVectors\n\nA vector is a matrix with a single column.\n\nVariables in vector format: \\(X = (X_1, X_2, X_3, X_4)\\)\n\n\n\nTransposing Matrices\n\nThe transpose of a matrix swaps its rows and columns.\n\nIf \\(A\\) is a matrix, then its transpose is denoted as \\(A'\\) or \\(A^T\\).\n\nThe first column becomes the first row in the transpose.\n\n\n\nMatrix Addition and Subtraction\n\nMatrices must have the same dimensions for addition or subtraction.\n\nOperations are performed elementwise.\n\n\n\nMatrix Multiplication\n\nNot all matrices can be multiplied—matrix multiplication is only defined if the number of columns in the first matrix matches the number of rows in the second matrix.\n\nIf \\(A\\) is an \\(m \\times n\\) matrix and \\(B\\) is an \\(n \\times p\\) matrix, then the product \\(AB\\) is an \\(m \\times p\\) matrix.\n\nEach element in \\(AB\\) is obtained by computing the dot product of a row from \\(A\\) and a column from \\(B\\).\n\n\nWhat is a Dot Product?\nThe dot product of two vectors is the sum of the element-wise multiplications of their corresponding entries.\nFor matrix multiplication, to compute the element at row \\(i\\), column \\(j\\) of \\(AB\\), we take:\n1. Row \\(i\\) from \\(A\\)\n2. Column \\(j\\) from \\(B\\)\n3. Multiply corresponding elements and sum them:\n\\[\n   AB_{i,j} = A_{i,1}B_{1,j} + A_{i,2}B_{2,j} + \\dots + A_{i,n}B_{n,j}\n   \\]\n\n\nStep-by-Step Example\nLet:\n\\[\nA =\n\\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{bmatrix}\n\\] (\\(2 \\times 3\\) matrix) and\n\\[\nB =\n\\begin{bmatrix}\n7 & 8 \\\\\n9 & 10 \\\\\n11 & 12\n\\end{bmatrix}\n\\] (\\(3 \\times 2\\) matrix)\nSince \\(A\\) has 3 columns and \\(B\\) has 3 rows, multiplication is valid, and the resulting matrix \\(AB\\) has dimension \\(2 \\times 2\\).\nTo compute the element in row 1, column 1 of \\(AB\\):\n\\[\nAB_{1,1} = (1 \\times 7) + (2 \\times 9) + (3 \\times 11) = 7 + 18 + 33 = 58\n\\]\nTo compute the element in row 1, column 2:\n\\[\nAB_{1,2} = (1 \\times 8) + (2 \\times 10) + (3 \\times 12) = 8 + 20 + 36 = 64\n\\]\nTo compute the element in row 2, column 1:\n\\[\nAB_{2,1} = (4 \\times 7) + (5 \\times 9) + (6 \\times 11) = 28 + 45 + 66 = 139\n\\]\nTo compute the element in row 2, column 2:\n\\[\nAB_{2,2} = (4 \\times 8) + (5 \\times 10) + (6 \\times 12) = 32 + 50 + 72 = 154\n\\]\nThus, the final matrix product is:\n\\[\nAB =\n\\begin{bmatrix}\n58 & 64 \\\\\n139 & 154\n\\end{bmatrix}\n\\]\n\n\n\nIdentity Matrices\n\nAn identity matrix is always symmetric, with:\n\nAll diagonal elements of 1\n\nAll off-diagonal elements of 0\n\nThe identity matrix behaves like 1 in scalar multiplication:\n\nIf \\(A\\) is an \\(r \\times c\\) matrix and \\(I\\) is a \\(c \\times c\\) identity matrix, then \\(AI = A\\).\nIf \\(I\\) is an \\(r \\times r\\) identity matrix, then \\(IA = A\\).\n\n\n\nMatrix Inverses\n\nIf a matrix is square and meets certain conditions, an inverse matrix exists.\n\nThe inverse of \\(A\\) is denoted as \\(A^{-1}\\).\n\nThe property: \\(AA^{-1} = A^{-1}A = I\\)\nInverse operations are the matrix equivalent of division.\n\n\n\nTips for Reading Matrix Formulas\n\nAlways check the dimension of the final result when interpreting matrix expressions.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#special-cases-of-matrix-multiplication",
    "href": "applied-chapter05.html#special-cases-of-matrix-multiplication",
    "title": "Matrices",
    "section": "Special Cases of Matrix Multiplication",
    "text": "Special Cases of Matrix Multiplication\nLet \\(C_{n \\times 1}\\) be a column vector of chosen numbers, and let \\(Y_{n \\times 1}\\) be a column vector representing a sample of data. The computation \\(C' Y\\) (the transpose of \\(C\\) multiplied by \\(Y\\)) allows us to compute:\n\nAverages\nIf all elements of \\(C\\) are equal to \\(\\frac{1}{n}\\), then the matrix multiplication: \\[\nC' Y =\n\\begin{bmatrix}\n\\frac{1}{n} & \\frac{1}{n} & \\dots & \\frac{1}{n}\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n\\end{bmatrix}\n= \\frac{1}{n} (y_1 + y_2 + \\dots + y_n) = \\frac{1}{n} \\sum_{i=1}^{n} y_i = \\bar{Y}\n\\] This shows that \\(C' Y\\) computes the sample mean \\(\\bar{Y}\\) using matrix multiplication.\n\n\nWeighted Averages\nIf \\(C\\) contains weights that sum to 1 and are all positive, then the matrix multiplication: \\[\nC' Y =\n\\begin{bmatrix}\nw_1 & w_2 & \\dots & w_n\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n\\end{bmatrix}\n= w_1 y_1 + w_2 y_2 + \\dots + w_n y_n = \\sum_{i=1}^{n} w_i Y_i = \\bar{Y}_w\n\\] This shows that \\(C' Y\\) computes the weighted mean \\(\\bar{Y}_w\\) using matrix multiplication.\n\n\nSummation\nIf all elements of \\(C\\) are set to 1, then the matrix multiplication: \\[\nC' Y =\n\\begin{bmatrix}\n1 & 1 & \\dots & 1\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n\\end{bmatrix}\n= y_1 + y_2 + \\dots + y_n = \\sum_{i=1}^{n} y_i\n\\] This shows that \\(C' Y\\) computes the sum of all values in \\(Y\\) using matrix multiplication.\n\n\nExtending to Matrices\nIf \\(C\\) is not a vector but a matrix, then multiple computations can be performed simultaneously using matrix multiplication: \\[\nC' Y =\n\\begin{bmatrix}\n\\frac{1}{n} & \\frac{1}{n} & \\dots & \\frac{1}{n} \\\\\n1 & 1 & \\dots & 1\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\bar{Y} \\\\\n\\sum Y\n\\end{bmatrix}\n\\] This shows that \\(C' Y\\) stores the mean in the first row and the sum in the second, efficiently computing both.\n\n\nSums of Squares\nIf \\(Y\\) is multiplied by its own transpose, then the matrix multiplication: \\[\nY' Y =\n\\begin{bmatrix}\ny_1 & y_2 & \\dots & y_n\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n\\end{bmatrix}\n= y_1^2 + y_2^2 + \\dots + y_n^2 = \\sum_{i=1}^{n} Y_i^2\n\\] This shows that \\(Y' Y\\) computes the sum of squares of \\(Y\\) using matrix multiplication, which is useful for variance and regression calculations.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#summarizing-multiple-variables",
    "href": "applied-chapter05.html#summarizing-multiple-variables",
    "title": "Matrices",
    "section": "Summarizing Multiple Variables",
    "text": "Summarizing Multiple Variables\nThis section describes how to summarize numerical data when working with multiple variables, leading up to the multivariate normal distribution (MVN) and how to estimate its parameters.\n\nOne-Variable Summaries\nBasic summaries for individual variables:\n\nMean and standard deviation (if normally distributed)\n\nFive-number summary: min, 1st quartile, median, 3rd quartile, max\n\n\n\nMultiple Variables\nWhen working with multiple variables:\n\nCompute the mean and standard deviation for each variable\n\nSome variables may be correlated\n\nMatrices provide a structured way to organize this information\n\n\n\nParameters for Two Variables\nFor two variables \\(X_1\\) and \\(X_2\\):\n\\(X_1\\)\n\nMean: \\(\\mu_1\\)\n\nStandard deviation: \\(\\sigma_1\\)\n\n\\(X_2\\)\n\nMean: \\(\\mu_2\\)\n\nStandard deviation: \\(\\sigma_2\\)\n\nIn addition to individual means and standard deviations, we also measure covariance (\\(\\sigma_{12}\\)), which describes how the two variables vary together. Covariance is directly related to correlation.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#matrix-representation",
    "href": "applied-chapter05.html#matrix-representation",
    "title": "Matrices",
    "section": "Matrix Representation",
    "text": "Matrix Representation\nMatrices provide a compact way to represent the relationships between multiple variables.\n\\(X_1\\) and \\(X_2\\) follow a multivariate normal distribution (MVN):\n\nMean vector: \\[\n\\mu =\n\\begin{bmatrix}\n\\mu_1 \\\\\n\\mu_2\n\\end{bmatrix}\n\\]\nCovariance matrix: \\[\n\\Sigma =\n\\begin{bmatrix}\n\\sigma_1^2 & \\sigma_{12} \\\\\n\\sigma_{12} & \\sigma_2^2\n\\end{bmatrix}\n\\]\nThe diagonal elements are variances; the off-diagonal elements are covariances.\nThe covariance matrix must be symmetric.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#covariance-and-correlation",
    "href": "applied-chapter05.html#covariance-and-correlation",
    "title": "Matrices",
    "section": "Covariance and Correlation",
    "text": "Covariance and Correlation\n\nCovariance (\\(\\sigma_{12}\\)) measures how two variables move together but depends on scale.\nCorrelation is the standardized version of covariance. \\[\n\\text{COR}(X_1,X_2) = \\frac{\\text{COV}(X_1, X_2)}{\\sigma_1 \\sigma_2}\n\\]\nProperties:.\n\nCovariance has units, correlation does not.\nA covariance of zero means the variables are not linearly related.\nCorrelation ranges from -1 to 1, making it easier to interpret.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#multivariate-normal-distribution-mvn",
    "href": "applied-chapter05.html#multivariate-normal-distribution-mvn",
    "title": "Matrices",
    "section": "Multivariate Normal Distribution (MVN)",
    "text": "Multivariate Normal Distribution (MVN)\nA multivariate normal distribution (MVN) extends the normal distribution to multiple variables, describing their relationships through both their individual distributions and their dependencies. It is defined by:\n\nA mean vector, which gives the expected values of the variables.\n\nA covariance matrix, which describes how the variables vary together.\n\nA joint probability distribution, which specifies the likelihood of different combinations of variable values.\n\n\nTheoretical Properties\n\nEach individual variable follows a normal distribution.\nThe relationships between variables are linear.\nData points are denser near the mean vector.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#estimating-parameters-from-data",
    "href": "applied-chapter05.html#estimating-parameters-from-data",
    "title": "Matrices",
    "section": "Estimating Parameters from Data",
    "text": "Estimating Parameters from Data\nIn practice, we estimate MVN parameters from a sample:\nSample Mean Vector: \\[\n\\bar{X} =\n\\begin{bmatrix}\n\\bar{X}_1 \\\\\n\\bar{X}_2\n\\end{bmatrix}\n\\] Sample Covariance Matrix: \\[\nS =\n\\begin{bmatrix}\ns_1^2 & s_{12} \\\\\ns_{12} & s_2^2\n\\end{bmatrix}\n\\]\nwhere:\n\n\\(s_1^2\\) and \\(s_2^2\\) are sample variances.\n\\(s_{12}\\) is the sample covariance.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#assessing-multivariate-normality",
    "href": "applied-chapter05.html#assessing-multivariate-normality",
    "title": "Matrices",
    "section": "Assessing Multivariate Normality",
    "text": "Assessing Multivariate Normality\nTo check if data follows an MVN distribution:\n\nEach variable should be normally distributed.\n\nDensity plots should be bell-shaped.\nQQ plots (e.g., mqqnorm(dataset)) should be linear with slight tail deviations.\nCheck scatterplot matrices for pairwise relationships.\n\nStart with these visualizations.\nPatterns should be elliptical or circular, and denser in the middle.\nLinear relationships suggest MVN, while unusual trends indicate deviations.\nPerform hypothesis tests where the null is MVN:\n\nRoyston’s test\nMardia’s test\nNo single test is definitive",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#applications-of-mvn",
    "href": "applied-chapter05.html#applications-of-mvn",
    "title": "Matrices",
    "section": "Applications of MVN",
    "text": "Applications of MVN\nThe multivariate normal distribution is widely used in statistics and machine learning:\n\nClassification:\n\nDiscriminant analysis\n\nRegression:\n\nMultiple linear regression (MLR) assumes MVN.\nHypothesis testing in regression uses MVN properties.\nRepeated measures and time series analysis rely on MVN structure.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#multiple-linear-regression-mlr-revisited",
    "href": "applied-chapter05.html#multiple-linear-regression-mlr-revisited",
    "title": "Matrices",
    "section": "Multiple Linear Regression (MLR) Revisited",
    "text": "Multiple Linear Regression (MLR) Revisited\nHow does linear regression use matrix operations and MVN assumptions?\n\nSimple Linear Regression\n\nModel: \\(y = \\beta_0 + \\beta_1x + \\epsilon\\)\nThis relationship is assumed to hold for each observation, meaning the model consists of \\(n\\) equations. For \\(n\\) observations: \\[\n\\begin{aligned}\ny_1 &= \\beta_0 + \\beta_1x_1 + \\epsilon_1 \\\\\n&\\vdots \\\\\ny_n &= \\beta_0 + \\beta_1x_n + \\epsilon_n\n\\end{aligned}\n\\]\nAssumptions:.\n\nErrors \\(\\epsilon_i\\) are independent, normally distributed, and have constant variance.\n\nThe error terms form a vector \\(\\epsilon\\) that follows a multivariate normal distribution.\n\n\nThese equations can be rewritten in matrix form.\n\n\n\nBig Picture: Computing Regression Coefficients\nTo estimate and test coefficients in MLR:\n\nEstimate coefficients using: \\(\\hat{\\beta} = (X^T X)^{-1} X^T Y\\)\n\nCompute the covariance matrix of estimates: \\(\\text{Var}(\\hat{\\beta}) = \\sigma^2 (X^T X)^{-1}\\)\n\nTake the square root of diagonal elements to get standard errors.\n\nUse \\(\\hat{\\beta}\\) and standard errors to compute t-statistics, p-values. and confidence intervals.\n\n\n\nThe Matrix Advantage\n\nThe matrix formula \\(\\hat{\\beta} = (X^T X)^{-1} X^T Y\\) works regardless of the number of predictors or sample size.\nMatrix form provides a general framework for linear regression.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter05.html#code-examples-in-r",
    "href": "applied-chapter05.html#code-examples-in-r",
    "title": "Matrices",
    "section": "Code Examples (in R)",
    "text": "Code Examples (in R)\n\nMatrix Operations\n\n\nCode\nM = matrix(c(0,1,2,3), 2, 2)  # 2x2 (r x c) matrix, filled by column\nN = matrix(c(4,3,2,1), 2, 2)\n\nt(M)        # Transpose\nM * N       # Elementwise multiplication\nM %*% N     # Matrix multiplication\nMinv = solve(M)     # Matrix inverse\nM %*% Minv          # Should return identity matrix c(1,0,0,1): confirms inverse\n\n\n\n\nMultiple Linear Regression\n\n\nCode\n# Predict y from x using matrix algebra\n\nx = c(1,2,3,4,5)\ny = c(6.5, 10.8, 14, 21.2, 26.8) # Response vector\n\n# Design matrix: column of 1s for intercept, then x\nbigX = cbind(rep(1, 5), x)\n\n# Estimate beta using matrix multiplication\nbeta_hat = solve(t(bigX) %*% bigX) %*% t(bigX) %*% y\nbeta_hat\n\n# Compare to lm()\nfit = lm(y ~ x)\ncoef(summary(fit))[,1]   # Estimated coefficients\nsummary(fit)\n\n\n# Estimate standard errors manually\nsigma2 = 1.261^2  # From residual standard error in model summary\ncov_beta = sigma2 * solve(t(bigX) %*% bigX)\nsqrt(diag(cov_beta))      # Standard errors\n\n# Compare to lm() standard errors\ncoef(summary(fit))[,2]",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html",
    "href": "applied-chapter06.html",
    "title": "Repeated Measures",
    "section": "",
    "text": "Objectives\nThis chapter explores repeated measures, which allow us to relax the independence assumption.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html#objectives",
    "href": "applied-chapter06.html#objectives",
    "title": "Repeated Measures",
    "section": "",
    "text": "Understand when repeated measures are appropriate.\n\nLearn about correlation structures, how to visualize them, and select the appropriate structure.\n\nExplore generalized least squares (GLS) and weighted least squares (WLS).\n\nFollow a repeated measures workflow to structure analysis.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html#what-is-repeated-measures",
    "href": "applied-chapter06.html#what-is-repeated-measures",
    "title": "Repeated Measures",
    "section": "What is Repeated Measures?",
    "text": "What is Repeated Measures?\n\nFamily Tree of Linear Models\n\n\n\n\n\n\nflowchart TD\n  A[\"Linear models&lt;br&gt;(constant variance,&lt;br&gt;normality assumptions)\"] --&gt; B[\"Errors are&lt;br&gt;independent\"]\n  B --&gt; D[\"*t*-tests\"]\n  B --&gt; E[\"ANOVA\"]\n  B --&gt; F[\"SLR\"]\n  A --&gt; C[\"Errors are&lt;br&gt;correlated\"]\n  C --&gt; G[\"Time series\"]\n  C --&gt; H[\"Repeated measures\"]\n\n  %% Arrow styling\n  linkStyle default stroke:#333,stroke-width:1.5px;\n\n  %% Node styling\n  style A fill:#d1c4e9,stroke:#512da8,stroke-width:1.25px,color:#000\n  style B fill:#bbdefb,stroke:#1976d2,stroke-width:1.25px,color:#000\n  style C fill:#ffcdd2,stroke:#c62828,stroke-width:1.25px,color:#000\n\n  style D fill:#e3f2fd,stroke:#64b5f6,stroke-width:1.25px,color:#000\n  style E fill:#e3f2fd,stroke:#64b5f6,stroke-width:1.25px,color:#000\n  style F fill:#e3f2fd,stroke:#64b5f6,stroke-width:1.25px,color:#000\n\n  style G fill:#ffebee,stroke:#ef5350,stroke-width:1.25px,color:#000\n  style H fill:#ffebee,stroke:#ef5350,stroke-width:1.25px,color:#000",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html#repeated-measures",
    "href": "applied-chapter06.html#repeated-measures",
    "title": "Repeated Measures",
    "section": "Repeated Measures",
    "text": "Repeated Measures\n\nLinear models assume constant variance and normality with independent errors.\n\nExamples: t-tests, ANOVA, simple linear regression (SLR)\n\nWhen errors are correlated:\n\nExamples: time series, repeated measures\n\nIgnoring correlation can produce misleading p-values and confidence intervals.\n\nWe need to model the correlation among errors (i.e., include additional parameters in the model) for valid inference and better predictions.\n\nRepeated measures refers to multiple measurements on the same subject (i.e., dependent observations).\n\nFor example, if a subject starts with high (or conversely low) values, their measurements tend to remain high (or low) over time.\n\n\n\nCommon Hypotheses in Repeated Measures:\n\nCompare every time point to a baseline (i.e., control), for each group (e.g., asymptomatic vs. symptomatic).\nCompare each time point between groups. (Baseline may not differ, but other time points might.)\n\n\n\nRegression Perspective\nTreat time as a categorical variable because measurements are made at discrete time points:\n\\[\nY = \\text{Time} + \\text{Status} + \\text{Time} \\times \\text{Status} + \\varepsilon\n\\]\n\nInclude an interaction since trends depend on status.\n\nRegression and contrasts help compare groups—we just need to model correlated errors.\n\n\n\nIdentifying Repeated Measures\n\nAsk how the data were collected.\n\nRepeated measures can apply to:\n\nRepeated measures one-way ANOVA\nRepeated measures MLR",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html#correlation-structures",
    "href": "applied-chapter06.html#correlation-structures",
    "title": "Repeated Measures",
    "section": "Correlation Structures",
    "text": "Correlation Structures\n\nAssessing Error Dependence\n\nSome methods include residual diagnostic tools to visualize correlated errors.\nSimilar tools exist for repeated measures, but they aren’t as commonly used.\nThe key idea is to explain how residuals are correlated using a correlation structure.\n\n\nCorrelogram (pseudo-code approach)\n\nObtain residuals from a regular MLR (some from the same subject).\nFor residuals that are one unit apart in time:\n\nCreate a scatterplot (earlier time point on the \\(x\\)-axis, later time point on the \\(y\\)-axis).\nCompute the correlation, and store the result.\n\nRepeat for residuals that are two, three, four, \\(\\dots, k\\) units apart.\nPlot the correlation values against the time lag.\n\n\n\nTakeaway\nCorrelation tends to decrease as the distance between residuals increases and eventually levels off. Large correlations at short time lags are a clear indication of correlated errors.\n\n\n\nCorrelogram Interpretation\n\nObservations closer in time are more similar (i.e., more correlated).\nObservations farther apart in time may still be mildly correlated.\n\n\n\nCommon Correlation Structures\nCorrelation structures are theoretical models that describe the expected trend in the correlogram.\n\nCompound symmetry (CS)\n\nCorrelation is constant (i.e., flat, horizontal line) regardless of time.\nOften used when time ordering is not meaningful (e.g., students within the same school).\n\n\n\nAutoregressive (AR(1))\n\nHigh correlation for nearby time points.\nCorrelation decreases as time lag increases.\nEventually approaches zero (like independent errors).\n\n\n\nGaussian\n\nSimilar to AR(1), but the drop-off in correlation is even faster.\nOften used when time is continuous.\n\n\n\n\nGeneralized Least Squares (GLS)\n\nGLS generalizes OLS technique for MLR to handle correlated errors.\nYou specify:\n\nA model with response and predictors\nA correlation structure (parameters estimated by software)\n\nGLS updates both:\n\nRegression coefficients\nStandard errors\n\nThese estimates are more reliable than standard MLR if the chosen correlation structure is approximately correct.\n\n\n\nEstimating Correlation in Practice\n\nVariograms and semivariograms (often used in spatial models) can be used as visual alternatives to correlograms.\nIn practice, repeated measures datasets may be too small to visualize correlation clearly through the high variability.\nAnalysts typically:\n\nUse theoretical justification for choosing a structure.\nFit multiple structures and compare using AIC (like feature selection).\nUse correlograms as a visual guide.\n\nInstructor note (Turner’s experience):\n\nCompound symmetry works well for biological or human-based data.\n\nUse structures with rapid decay (e.g., Gaussian) sparingly unless time points are equally spaced and numerous.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html#repeated-measures-workflow",
    "href": "applied-chapter06.html#repeated-measures-workflow",
    "title": "Repeated Measures",
    "section": "Repeated Measures Workflow",
    "text": "Repeated Measures Workflow\n\nIdentify that you are in a repeated measures setting.\nPerform EDA based on the equivalent MLR framework (determine the general theme: ANOVA, SLR, or MLR):\n\nUse boxplots or mean plots in ANOVA-style settings.\nUse scatterplots of predictor vs. response in SLR-style settings.\nCombine approaches for general MLR settings.\nApply feature selection tools from MLR to assess model complexity and the bias-variance trade-off.\n\nResidual diagnostics:\n\nCheck for normality and constant variance using residual plots.\n\nUpdate MLR to GLS:\n\nTry multiple correlation structures.\nUse AIC to select the best-fitting model.\nOptionally use a correlogram to guide your choice.\n\nConduct inference on regression coefficients:\n\nReport p-values and confidence intervals.\nResults will be more trustworthy when correlation is accounted for.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html#additional-notes-on-correlation-structures",
    "href": "applied-chapter06.html#additional-notes-on-correlation-structures",
    "title": "Repeated Measures",
    "section": "Additional Notes on Correlation Structures",
    "text": "Additional Notes on Correlation Structures\n\nSome correlation structures require a time component:\n\nAutoregressive (AR; exponential decay)\nGaussian\nLinear\nSpherical\nMatérn (A general class that includes AR and Gaussian as special cases; more flexible but may overfit.)\n\nSome correlation structures do not require a time component:\n\nCompound symmetry (CS)\nVariance components\n\nExamples that don’t involve time:\n\nTexas STAR exam: multiple test scores from the same schools/school districts\nHereditary studies: family studies where siblings or parents/offspring are clustered",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html#technical-details",
    "href": "applied-chapter06.html#technical-details",
    "title": "Repeated Measures",
    "section": "Technical Details",
    "text": "Technical Details\n\nMatrix Representation of MLR\n\\[\nY = X\\beta + \\varepsilon\n\\]\nwhere:\n\n\\(Y\\) is the response vector.\n\\(X\\) is the design matrix.\n\\(\\beta\\) is the regression coefficient vector.\n\\(\\varepsilon\\) is the error vector.\n\nThe model assumes properties of the errors:\n\\[\n\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I)\n\\]\nthat is:\n\n\\(\\varepsilon\\) is multivariate normal\nwhere \\(\\mathcal{N}\\) denotes the multivariate normal distribution (MVN)\nMean vector = \\(0\\), a \\(n x 1\\) matrix of \\(0\\)s\nCovariance matrix = \\(\\sigma^2 I\\)\n\nThe covariance matrix:\n\\[\n\\Sigma = \\begin{bmatrix}\n\\sigma^2 & 0 & 0 \\\\\n0 & \\sigma^2 & 0 \\\\\n0 & 0 & \\sigma^2 \\\\\n\\end{bmatrix} = \\sigma^2I\n\\]\nInterpretation:\n\nEach individual error has the same variance \\(\\sigma^2\\)\nTraditional multiple linear regression (MLR) assumptions:\n\nErrors are independent, which implies they are also uncorrelated, so all off-diagonal covariances are 0.\n\n\n\n\nGeneralized Least Squares (GLS) and Correlated Errors\nIn repeated measures models, we no longer assume that errors are uncorrelated.\nTo account for correlated errors, we extend the standard MLR assumptions using generalized least squares (GLS). This involves specifying a more flexible error structure.\nWe now assume:\n\\[\n\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 R)\n\\]\nwhere:\n\n\\(\\varepsilon\\) is multivariate normal with mean zero.\n\\(\\sigma^2 R\\) is the variance–covariance matrix of the errors.\n\\(R\\) is the correlation matrix, which specifies how errors are related (e.g., through time, subject grouping, etc.).\nWhen \\(R = I\\), we recover the standard MLR case with independent errors.\n\nThis updated formulation allows us to model within-subject correlation (e.g., repeated observations) by directly encoding the assumed pattern of correlation into \\(R\\).\n\n\nVisualizing the Correlation Structure in \\(\\sigma^2 R\\)\nWe can visualize the error term in repeated measures models as:\n\\[\nY = X\\beta + \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 R)\n\\]\nEach row in \\(\\varepsilon\\) corresponds to a specific subject and time point:\n\n\n\nSubject\nTime\nError Term\n\n\n\n\n1\nT1\n\\(\\varepsilon_1\\)\n\n\n1\nT2\n\\(\\varepsilon_2\\)\n\n\n1\nT3\n\\(\\varepsilon_3\\)\n\n\n2\nT1\n\\(\\varepsilon_4\\)\n\n\n2\nT2\n\\(\\varepsilon_5\\)\n\n\n2\nT3\n\\(\\varepsilon_6\\)\n\n\n\nThe corresponding variance–covariance matrix \\(\\sigma^2 R\\) has a block-diagonal structure and might look like this:\n\\[\n\\sigma^2 R = \\sigma^2 \\begin{bmatrix}\n1 & \\rho_{12} & \\rho_{13} & 0 & 0 & 0 \\\\\n\\rho_{12} & 1 & \\rho_{23} & 0 & 0 & 0 \\\\\n\\rho_{13} & \\rho_{23} & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & \\rho_{45} & \\rho_{46} \\\\\n0 & 0 & 0 & \\rho_{45} & 1 & \\rho_{56} \\\\\n0 & 0 & 0 & \\rho_{46} & \\rho_{56} & 1 \\\\\n\\end{bmatrix}\n\\]\nKey points:\n\nThe upper-left 3×3 block corresponds to Subject 1 and correlations among \\(\\varepsilon_1\\), \\(\\varepsilon_2\\), \\(\\varepsilon_3\\).\nThe lower-right 3×3 block corresponds to Subject 2 and correlations among \\(\\varepsilon_4\\), \\(\\varepsilon_5\\), \\(\\varepsilon_6\\)\nOff-diagonal correlations exist within subjects (e.g., \\(\\rho_{12}, \\rho_{13}, \\rho_{23}\\) for subject 1).\nBetween-subject correlations are zero, indicated by the block-diagonal structure.\nThe values of the \\(\\rho\\) terms are determined by the assumed correlation structure (e.g., compound symmetry, AR(1), etc.).\n\nThis block structure is how repeated measures models encode dependency within subjects but maintain independence between subjects.\n\n\nCorrelation Structure Matrices\nDifferent correlation structures determine the form of the matrix \\(R\\) in the repeated measures model.\n\nAutoregressive (AR(1))\nThis structure assumes correlation decreases with increasing time lag:\n\\[\n\\sigma^2 \\begin{bmatrix}\n1 & \\rho & \\rho^2 & \\rho^3 \\\\\n\\rho & 1 & \\rho & \\rho^2 \\\\\n\\rho^2 & \\rho & 1 & \\rho \\\\\n\\rho^3 & \\rho^2 & \\rho & 1 \\\\\n\\end{bmatrix}\n\\]\n\nHigh correlation for adjacent time points\nCorrelation decays exponentially with time separation\n\n\n\nCompound Symmetry (CS)\nThis structure assumes constant correlation across all time points:\n\\[\n\\sigma^2 \\begin{bmatrix}\n1 & \\rho & \\rho & \\rho \\\\\n\\rho & 1 & \\rho & \\rho \\\\\n\\rho & \\rho & 1 & \\rho \\\\\n\\rho & \\rho & \\rho & 1 \\\\\n\\end{bmatrix}\n\\]\n\nOften used when time ordering is less meaningful or measurements are equally spaced\nSimpler structure, fewer parameters\n\n\n\nGaussian\n\nSimilar to AR(1), but correlation drops off more quickly\nOften used when time is continuous or spacing between time points varies\n\n\n\nSpherical Power\n\nSame mathematical form as AR(1), just different context or terminology\nUseful when modeling spatial or continuous time-based correlation\n\n\n\n\nModel Fitting\nFitting repeated measures models typically uses restricted maximum likelihood (REML), a technique that improves estimation of variance components.\nDuring model fitting, the software estimates:\n\n\\(\\sigma^2 R\\): the variance–covariance matrix of the errors\n\\(\\beta\\): the regression coefficient vector\n\nThe estimate of \\(\\beta\\) under GLS is:\n\\[\n\\hat{\\beta} = \\left(X^T R^{-1} X\\right)^{-1} X^T R^{-1} Y\n\\]\n\nThis formula generalizes the OLS estimator\nWhen \\(R = I\\), it reduces to the standard OLS solution\n\n\n\nVariance of the GLS Estimator\nIn addition to estimating the coefficients \\(\\hat{\\beta}\\), we can also estimate their variances using the expression:\n\\[\n\\widehat{\\text{Var}}(\\hat{\\beta}) = \\hat{\\sigma}^2 \\left( X^T R^{-1} X \\right)^{-1}\n\\]\nThis is the generalized version of the variance formula used in OLS.\n\nWhen \\(R = I\\), this reduces to the traditional multiple linear regression (MLR) variance estimator:\n\n\\[\n\\widehat{\\text{Var}}(\\hat{\\beta}) = \\hat{\\sigma}^2 \\left( X^T X \\right)^{-1}\n\\]\nThus, the MLR estimator is a special case of GLS where the correlation structure is identity (i.e., no correlation among errors).\n\n\nSummary: MLR as a Special Case of GLS\nThe general linear model framework used in GLS relaxes the independence assumption of traditional MLR and allows for arbitrary correlation structures among errors (via the matrix \\(R\\)).\n\nMLR is a special case of GLS when the correlation structure is \\(R = I\\).\nThe structure of \\(R\\) determines how residuals are related (e.g., repeated measurements, clustered observations).\nUnder GLS, we estimate:\n\nRegression coefficients \\(\\hat{\\beta}\\)\nStandard errors of \\(\\hat{\\beta}\\)\nThe correlation structure (via estimated parameters in \\(R\\))\n\n\nKey idea: Accounting for correlation leads to valid statistical inference and improved prediction.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter06.html#weighted-least-squares-wls",
    "href": "applied-chapter06.html#weighted-least-squares-wls",
    "title": "Repeated Measures",
    "section": "Weighted Least Squares (WLS)",
    "text": "Weighted Least Squares (WLS)\nGLS can also be applied when independence holds, but the assumption of constant variance is violated (i.e., heteroscedasticity).\nIn this case, the error covariance matrix no longer looks like \\(\\sigma^2 I\\). Instead, each observation has its own variance:\n\\[\n\\Sigma = \\begin{bmatrix}\n\\sigma_1^2 & 0 & 0 \\\\\n0 & \\sigma_2^2 & 0 \\\\\n0 & 0 & \\sigma_3^2 \\\\\n\\end{bmatrix}\n\\]\n\nEach variance term \\(\\sigma_i^2\\) is unique.\nIndependence still holds (covariances are 0), but the variances are not constant across observations.\n\nWe can re-express each unique variance in terms of a common variance component and a weight:\n\\[\n\\sigma_1^2 = \\frac{1}{w_1} \\sigma^2,\\quad\n\\sigma_2^2 = \\frac{1}{w_2} \\sigma^2,\\quad\n\\sigma_3^2 = \\frac{1}{w_3} \\sigma^2\n\\]\nEach \\(w_i\\) is a weight term that serves as a multiplicative factor determining how different the variance of each observation is from the baseline \\(\\sigma^2\\).\n\nWeighted Error Structure in Matrix Form\nUsing the weights, the variance–covariance matrix of the errors can be written as:\n\\[\n\\Sigma =\n\\begin{bmatrix}\n\\sigma_1^2 & 0 & 0 \\\\\n0 & \\sigma_2^2 & 0 \\\\\n0 & 0 & \\sigma_3^2 \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\frac{\\sigma^2}{w_1} & 0 & 0 \\\\\n0 & \\frac{\\sigma^2}{w_2} & 0 \\\\\n0 & 0 & \\frac{\\sigma^2}{w_3} \\\\\n\\end{bmatrix}\n=\n\\sigma^2\n\\begin{bmatrix}\n\\frac{1}{w_1} & 0 & 0 \\\\\n0 & \\frac{1}{w_2} & 0 \\\\\n0 & 0 & \\frac{1}{w_3} \\\\\n\\end{bmatrix}\n= \\sigma^2 R\n\\]\n\nThis is a special case of GLS where the correlation matrix \\(R\\) is diagonal.\nWLS is GLS with unequal variances but uncorrelated errors.\n\nWe can use GLS techniques to obtain good estimates of the regression coefficients and their standard errors under this structure.\n\n\nEstimating Weights in Practice\nYou can only apply WLS if you know (or can estimate) the weights. There are numerous strategies for estimating the weights, but the basic approach follows a common pattern:\n\nFit a regular regression model.\nPlot the absolute values of your residuals against:\n\nOne of your predictors that you suspect may explain the changing variance, or\n\nThe predicted values from your model\nLook for a pattern or trend in the spread of the residuals.\n\nFit a regression model to the absolute value of the residuals to estimate the mean behavior (i.e., trend) of the variability.\nUse the predicted values from that model to compute weights:\n\\[\nw_i = \\frac{1}{(\\widehat{\\text{predicted}})^2}\n\\]\n\n\n\nCode\nweight.model = lm(abs(model1$residuals) ~ data1$x)\nwts = 1 / fitted(weight.model)^2\nwls.model = lm(y ~ x, data1, weights = wts)\n\n\n\n\nInterpretation\n\nObservations with higher variance are down-weighted.\nThe fitted line will more closely follow observations with lower variance.\nThe biggest difference is in the standard error estimates of the regression coefficients.\n\n\n\nWhen to Use WLS\n\nWhen transformations do not fix the constant variance problem.\nWhen an exotic transformation works but makes the model hard to interpret.\n\n\n\nAdditional Notes\n\nRaw residual vs. fitted plots may look the same for OLS and WLS.\nUse studentized residuals to check whether the variance has been stabilized.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Repeated Measures</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html",
    "href": "applied-chapter07.html",
    "title": "Classification",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#objectives",
    "href": "applied-chapter07.html#objectives",
    "title": "Classification",
    "section": "",
    "text": "Understand the distinction between regression and classification.\n\nLearn about classification boundaries.\n\nExplore classification methods:\n\nk-Nearest Neighbors (KNN)\n\nLinear and Quadratic Discriminant Analysis (LDA/QDA)\n\n\nEvaluate classification performance using error metrics.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#regression-vs.-classification",
    "href": "applied-chapter07.html#regression-vs.-classification",
    "title": "Classification",
    "section": "Regression vs. Classification",
    "text": "Regression vs. Classification\nMain distinction: The response variable in classification is categorical.\n\nBinary: Two outcomes (e.g., Yes/No)\n\nMulticlass: More than two categories\n\n\nWhy Not Use MLR?\n\nCan’t just convert categorical responses into numbers:\n\nIt doesn’t model trends well.\nIt violates assumptions due to the discreteness of the response.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#predictive-models-for-classification",
    "href": "applied-chapter07.html#predictive-models-for-classification",
    "title": "Classification",
    "section": "Predictive Models for Classification",
    "text": "Predictive Models for Classification\nClassification models work in two steps:\n\nPredict the probability that a categorical response will occur, given a set of explanatory variables: \\(P(Y = \\text{Default} \\mid X)\\)\nConvert that probability into a classification decision based on a threshold.\n\n\nComparison\n\nFor continuous responses: \\(Y = f(X)\\)\nFor categorical responses: \\(P(Y = \\text{Default} \\mid X) = f(X)\\)\n\nThe model predicts probabilities, not the class itself.\n\nPredictions stay between 0 and 1 (unlike MLR, which can go below 0 or above 1).\n\n\n\n\nWhy Predict Probabilities?\n\nPredictive models give us finer resolution than a simple yes/no.\n\nExample: A weather forecast predicting 60% chance of rain is more informative than just “yes” or “no”.\n\nSubtle relationships between predictors and the response lead to variability in predicted probabilities, creating a gray area.\n\nFor instance:\n\n\\(P(Y = \\text{Default} \\mid X = 100) = 0.82\\)\n\\(P(Y = \\text{Default} \\mid X = 100) = 0.52\\)\n\nThese two predictions might both get classified as “Default”, even though the model sees them very differently.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#classification-as-a-decision-rule",
    "href": "applied-chapter07.html#classification-as-a-decision-rule",
    "title": "Classification",
    "section": "Classification as a Decision Rule",
    "text": "Classification as a Decision Rule\n\nClassification forces a definitive decision based on the predicted probability: \\[\nY =\n\\begin{cases}\n\\text{Default}, & \\text{if } f(X) \\geq \\text{threshold} \\\\\n\\text{Not}, & \\text{otherwise}\n\\end{cases}\n\\]\nThis means classification doesn’t distinguish between a predicted probability of 0.52 and 0.82 if the threshold is 0.5.\n\n\nConsiderations When Classifying\n\nThe cost of getting the prediction wrong\n\nThe prevalence of the classes (how often each class occurs in the data)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#important-realizations",
    "href": "applied-chapter07.html#important-realizations",
    "title": "Classification",
    "section": "Important Realizations",
    "text": "Important Realizations\n\nAssessing how well a model performs is convoluted:\n\nHow well does the model predict the true probability of the response?\nHow well does your classification rule behave given the costs and context of your problem?\n\nMetrics commonly reported in software:\n\nOften assess classification decisions rather than predicted probabilities\n\nAre calculated without explicit consideration of the cost of mistakes\nAre often used to assess model fit, even though they may not reflect probability accuracy\n\nIt’s up to you to assess whether your decision rule fits your specific context, especially when the costs of different types of errors are not equal.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#terminology",
    "href": "applied-chapter07.html#terminology",
    "title": "Classification",
    "section": "Terminology",
    "text": "Terminology\n\nPositive class (+): The outcome for which you want to predict the probability\n\nNegative class (−): The other possible outcome (in a binary response)\n\nThese are mathematically arbitrary but can be practically important depending on the question you’re answering.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#classification-boundaries",
    "href": "applied-chapter07.html#classification-boundaries",
    "title": "Classification",
    "section": "Classification Boundaries",
    "text": "Classification Boundaries\n\nParametric Models\nThese models have always been of the predictive probability type:\n\nLogistic Regression\n\nLinear Discriminant Analysis (LDA)\n\nQuadratic Discriminant Analysis (QDA)\n\nNaive Bayes\n\n\nClassification Rule\nTo convert a predictive probability model into a classification rule, apply a threshold (commonly 0.5): \\[\n  \\hat{P}(Y = + \\mid X) \\geq 0.5 \\Rightarrow \\text{Classify as } +\n  \\]\n\nThe threshold can be adjusted to account for the cost of making a mistake.\n\n\n\n\nNonparametric Models\nThese models originally focused on making classification decisions (not probabilities):\n\nDecision Trees\n\nRandom Forests\n\nk-Nearest Neighbors (KNN)\n\nTo help standardize functions and workflows, software retroactively added predicted probabilities.\n\nKNN Classification Rule\n\nRecord the response values of the \\(k\\) nearest neighbors to \\(x_{\\text{new}}\\)\nEstimate: \\(\\hat{P}(Y = + \\mid x_{\\text{new}}) = \\frac{\\text{\\# of } + \\text{ neighbors}}{k}\\)\n\n\n\nClassification Boundary\n\nEvery model, once converted to a classification rule, defines a classification boundary.\nBoundaries help visualize:\n\nParametric vs. nonparametric behavior\n\nSimpler vs. more complex models\n\nSensitivity to changes in thresholds",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#discriminant-analysis-lda-qda",
    "href": "applied-chapter07.html#discriminant-analysis-lda-qda",
    "title": "Classification",
    "section": "Discriminant Analysis (LDA & QDA)",
    "text": "Discriminant Analysis (LDA & QDA)\n\nOverview\n\nDiscriminant analysis is a parametric approach for classification.\nApplies only to numeric predictors.\nAssumes predictors follow a multivariate normal (MVN) distribution within each class.\n\n\n\nCommon Types\n\nLinear Discriminant Analysis (LDA):\n\nDecision boundaries are linear (hyperplanes).\n\nQuadratic Discriminant Analysis (QDA):\n\nDecision boundaries are conic sections (typically quadratic).\n\n\n\n\nAssumptions\nIn discriminant analysis, the assumptions are on the predictors (not the error terms as in MLR).\n\n\\(X_+ = (X_1, X_2, \\dots, X_p)\\) is a set of \\(p\\) numeric predictors for the positive response class.\n\n\\(X_- = (X_1, X_2, \\dots, X_p)\\) is a set of the same \\(p\\) numeric predictors for the negative response class.\n\n\nLDA\n\n\\(X_+ \\sim MVN(\\mu_+, \\Sigma), \\quad X_- \\sim MVN(\\mu_-, \\Sigma)\\)\nEqual variance-covariance matrices (same \\(\\Sigma\\)), i.e., the predictors in each group should have the same variance and correlation.\nAllows different means, i.e., the predictor sets can have different mean vectors for each response. This is desirable for separation between the classes.\n\n\n\nQDA\n\n\\(X_+ \\sim MVN(\\mu_+, \\Sigma_+), \\quad X_- \\sim MVN(\\mu_-, \\Sigma_-)\\)\nCovariance matrices differ by class (relaxes assumptions, i.e., allows different \\(\\Sigma\\)s).\nMore flexibility, but more parameters to estimate.\nAlso allows different means.\n\n\n\nTechnical Insights\n\nLDA/QDA uses Bayes’ theorem to perform its predicted probabilities.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#bayes-theorem-ldaqda",
    "href": "applied-chapter07.html#bayes-theorem-ldaqda",
    "title": "Classification",
    "section": "Bayes’ Theorem & LDA/QDA",
    "text": "Bayes’ Theorem & LDA/QDA\nDiscriminant analysis (LDA/QDA) uses Bayes’ theorem to calculate predicted probabilities:\nBayes’ theorem for binary classification: \\[\nP(+ \\mid X) = \\frac{P(X \\mid +)P(+)}{P(X \\mid +)P(+) + P(X \\mid -)P(-)}\n\\]\nUpdated Bayes’ theorem using MVN assumptions: \\[\nP(+ \\mid X) = \\frac{MVN(\\mu_+, \\Sigma)P(+)}{MVN(\\mu_+, \\Sigma)P(+) + MVN(\\mu_-, \\Sigma)P(-)}\n\\]\n\n\\(P(+)\\) and \\(P(-)\\) are prior probabilities (i.e., class prevalence).\nClassification boundary with threshold = 0.5 results in linear (LDA) or quadratic (QDA) boundary.\nOutliers and class imbalance affect boundaries.\n\n\nKey Insights\nBayes’ formula is fully specified using:\n\nPrior probabilities\nPredictor value \\(X\\)\nClass-specific means and covariance matrices\n\nAll estimated from the training data\n\nWhen using a threshold (e.g., 0.5), LDA’s boundary mathematically reduces to a linear boundary.\n\n\nAdditional Notes on Classification Boundaries\n\nOutliers affect sample means and variances \\(\\rightarrow\\) can distort the boundary.\n\nPrior probabilities affect boundary placement, especially when priors are unequal.\nBayes’ theorem generalizes easily to more than two classes.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#complexity-of-qda",
    "href": "applied-chapter07.html#complexity-of-qda",
    "title": "Classification",
    "section": "Complexity of QDA",
    "text": "Complexity of QDA\n\nMore parameters: each class gets its own covariance matrix\nThe more predictors, the more parameters:\n\nIn binary classification with \\(p\\) predictors:\n\nLDA estimates \\(p + 1\\) parameters. Number of parameters increase at same rate as number of predictors.\nQDA estimates \\(\\frac{p(p + 3)}{2} + 1\\) parameters.\n\n\nNumber of parameters grows much faster than increase in number of predictors.\n\nGreater risk of overfitting, especially with small sample sizes.\n\nOverfitting is mitigated with larger datasets.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#pros-and-cons-of-ldaqda",
    "href": "applied-chapter07.html#pros-and-cons-of-ldaqda",
    "title": "Classification",
    "section": "Pros and Cons of LDA/QDA",
    "text": "Pros and Cons of LDA/QDA\n\nPros\n\nHandles correlated predictors (i.e., as long as the correlation isn’t perfect)\nParametric model that works when logistic regression fails due to complete separation of classes in training data\nOptimal when assumptions are met\n\n\n\nCons\n\nSensitive to outliers\nCannot handle categorical predictors due to the MVN assumption\nNo built-in feature selection\nSuffers from the curse of dimensionality\n\nPoor performance with many irrelevant predictors",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#error-metrics-for-classification",
    "href": "applied-chapter07.html#error-metrics-for-classification",
    "title": "Classification",
    "section": "Error Metrics for Classification",
    "text": "Error Metrics for Classification\n\nTwo Types of Metrics\n\nScoring Rules: Evaluate how close the predicted probabilities are to the true outcomes\n\nDecision Rule Metrics: Assess the accuracy of classification decisions made using a threshold",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#scoring-rules",
    "href": "applied-chapter07.html#scoring-rules",
    "title": "Classification",
    "section": "Scoring Rules",
    "text": "Scoring Rules\nThese assess the probability estimates of your model, not just the final classification.\n\nLog Loss (a.k.a. Entropy)\n\nPenalizes incorrect, confident predictions more heavily\n\nIncreases when predicted probabilities are uncertain (e.g., near 0.5), but the true class is strongly skewed\nSmaller when predicted probabilities are closer to the truth\n\ne.g., predicted probability = 0.9 when the true class is 1\n\nFormula: \\(\\text{Log Loss} = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(\\hat{p}_i) + (1 - y_i) \\log(1 - \\hat{p}_i) \\right]\\)\n\n\\(y_i = 1\\) if the true class is positive\n\n\\(y_i = 0\\) if the true class is negative\n\n\\(\\hat{p}_i\\) = predicted probability of the positive class\n\nHas nice mathematical properties that guarantee optimality in certain conditions\n\nUsed in logistic regression, classification trees, and many other algorithms\n\n\n\nBrier Score\n\nMeasures the mean squared difference between predicted probabilities and actual outcomes\n\nFormula: \\(\\text{Brier} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{p}_i - y_i)^2\\)\n\nLike an MSE for probabilities\nIntuitive and interpretable\nCan be decomposed into different sources of error (e.g., calibration and refinement)\n\n\n\n\nWhen to Use Scoring Rules\nScoring rules are ideal for:\n\nComparing models in feature selection\n\nTuning parameters (e.g., \\(k\\) in KNN, penalty terms in regularized models, or pruning in trees)\n\nEstimating regression coefficients in logistic regression\n\nThey help ensure that:\n\nPredicted probabilities are well-calibrated.\nYour model aligns well with the true underlying probabilities.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#decision-rule-metrics",
    "href": "applied-chapter07.html#decision-rule-metrics",
    "title": "Classification",
    "section": "Decision Rule Metrics",
    "text": "Decision Rule Metrics\nThese metrics assess how well a model performs after applying a classification threshold to the predicted probabilities.\nThey are derived from the confusion matrix, which compares predicted vs. actual classifications.\n\nConfusion Matrix\n\n\n\n\n\n\n\n\n\nActual Positive (+)\nActual Negative (–)\n\n\n\n\nPredicted Positive\ncorrectly predicted +\nincorrectly predicted +\n\n\nPredicted Negative\nincorrectly predicted –\ncorrectly predicted –\n\n\n\nThis matrix summarizes:\n\nHow often the model predicted correctly\nHow often the model made mistakes\nThe types of mistakes\n\n\nMost software may label these as:\n- True Positive (TP), False Positive (FP)\n- False Negative (FN), True Negative (TN)\nThese are helpful for shorthand but should be interpreted contextually.\n\nThe threshold (e.g., 0.5) determines how probabilities are turned into class predictions, which in turn affects all metrics derived from this table.\n\nAggregates and cross references how many times predictions were accurate and how many misclassifications were made using the thresholding strategy.\n\nIt will change when the threshold changes (depends on the threshold).\n\nUsed to compare models/optimize tuning parameters for techniques that do not produce a predicted probability.\n\n\n\nCommon Metrics\n\nMisclassification Rate (MCR)\nThe proportion of all observations where the model’s classification was wrong (i.e., the global error rate): \\[\n\\text{MCR} = \\frac{\\text{\\# incorrect predictions}}{n} = \\frac{\\text{FP} + \\text{FN}}{n}\n\\]\n\n\nAccuracy\nThe proportion of all observations where the model’s classification was correct: \\[\n\\text{Accuracy} = \\frac{\\text{\\# correct predictions}}{n} = \\frac{\\text{TP} + \\text{TN}}{n} = 1 - \\text{MCR}\n\\] &gt; Accuracy is an unconditional metric—it doesn’t distinguish between types of errors or account for class imbalance.\n\n\n\nConditional Metrics\nThese metrics are conditioned on a known true class or prediction. These metrics evaluate accuracy within a subset of observations. They help when accuracy alone is misleading.\n\nSensitivity (Recall / True Positive Rate)\n\n“Given that the true class is positive, how often did we predict positive?”\n\n\nFocuses on the true + group\n\nMeasures how well the model identifies actual positives\n\\[\n\\text{Sensitivity} = \\frac{\\text{correctly predicted +}}{\\text{total true +}} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n\\]\n\n\n\nSpecificity (True Negative Rate)\n\n“Given that the true class is negative, how often did we predict negative?”\n\n\nFocuses on the true – group\n\nMeasures how well the model avoids false positives\n\\[\n\\text{Specificity} = \\frac{\\text{correctly predicted –}}{\\text{total true –}} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}\n\\]\n\n\n\nPositive Predictive Value (PPV / Precision)\n\n“Given that we predicted positive, how often was that correct?”\n\n\nFocuses on the predicted + group\n\nMeasures trustworthiness of a positive prediction \\[\n\\text{PPV} = \\frac{\\text{correctly predicted +}}{\\text{total predicted +}} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n\\]\n\n\n\nNegative Predictive Value (NPV)\n\n“Given that we predicted negative, how often was that correct?”\n\n\nFocuses on the predicted – group\n\nMeasures trustworthiness of a negative prediction\n\\[\n\\text{NPV} = \\frac{\\text{correctly predicted –}}{\\text{total predicted –}} = \\frac{\\text{TN}}{\\text{TN} + \\text{FN}}\n\\]\n\n\n\n\nWhy So Many Metrics?\nDifferent metrics highlight different aspects of model performance and practical priorities, which can be especially helpful with imbalanced datasets.\nExample: Predicting whether a patient needs high-risk surgery\n\npositive class = needs surgery\n\nnegative class = does not need surgery\n\nSuppose:\n\nSensitivity = 90% → correctly detects 90% of patients who need surgery\n\nSpecificity = 90% → correctly identifies 90% of those who don’t need surgery\n\nPPV = 47% → only 47% of patients predicted to need surgery actually do\n\nNPV = 98.9% → almost all patients predicted not to need it truly don’t\n\n\nDoctors need PPV to decide: “How much trust should I put in a positive prediction?”\nEven with high sensitivity and specificity, prevalence affects PPV and NPV.\n\n\n\nPrevalence and Thresholding\n\nPrevalence: The base rate of the + class in the population\n\ne.g., 1 in 10 people need surgery → prevalence = 10%\n\nSensitivity and specificity do not depend on prevalence\n\nPPV and NPV do depend on prevalence",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#changing-the-threshold",
    "href": "applied-chapter07.html#changing-the-threshold",
    "title": "Classification",
    "section": "Changing the Threshold",
    "text": "Changing the Threshold\n\nThresholding affects the confusion matrix and all related metrics.\n\nA lower threshold → more positive predictions:\n\nIncreases sensitivity, reduces specificity\n\nA higher threshold → fewer positive predictions:\n\nIncreases specificity, reduces sensitivity\n\n\n\nChoose a threshold based on costs of different errors.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter07.html#summary-and-takeaways",
    "href": "applied-chapter07.html#summary-and-takeaways",
    "title": "Classification",
    "section": "Summary and Takeaways",
    "text": "Summary and Takeaways\n\nScoring rules assess probability estimates.\nDecision rule metrics evaluate classifications.\nConfusion matrices and derived metrics:\n\nDepend on threshold\nMust reflect real-world context and costs\n\n\n\nErrors are not always equal. In many applications, the cost of a false positive is different from a false negative.\n\n\nFocus first on thorough EDA and building a model with good predicted probability estimates.\n\nThen determine the threshold that best meets the needs of the problem.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html",
    "href": "applied-chapter08.html",
    "title": "2 x 2 Contingency Tables",
    "section": "",
    "text": "Objectives\nThis chapter introduces contingency tables as a bridge between group comparisons and logistic regression models.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#objectives",
    "href": "applied-chapter08.html#objectives",
    "title": "2 x 2 Contingency Tables",
    "section": "",
    "text": "Understand the role of 2×2 tables in modeling binary outcomes.\n\nCompare group proportions using appropriate statistical metrics.\n\nLearn when and how to apply Fisher’s exact test.\n\nUse chi-squared tests for large-sample inference.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#classification-tools",
    "href": "applied-chapter08.html#classification-tools",
    "title": "2 x 2 Contingency Tables",
    "section": "Classification Tools",
    "text": "Classification Tools\n\nLinear and Quadratic Discriminant Analysis (LDA/QDA)\n\nk-Nearest Neighbors (KNN)\n\nLogistic Regression\n\nA parametric method with strong interpretability\nAnalogous to multiple linear regression, but for binary categorical outcomes",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#building-up-to-multiple-linear-regression-mlr",
    "href": "applied-chapter08.html#building-up-to-multiple-linear-regression-mlr",
    "title": "2 x 2 Contingency Tables",
    "section": "Building Up to Multiple Linear Regression (MLR)",
    "text": "Building Up to Multiple Linear Regression (MLR)\n\n\n\nExplanatory Variable\nMethod\n\n\n\n\nOne categorical variable\nt-tests (2 groups)\n\n\n\nANOVA (3+ groups)\n\n\nOne numeric\nSimple linear regression\n\n\nMix of categorical and numeric\nMultiple linear regression",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#building-up-to-logistic-regression",
    "href": "applied-chapter08.html#building-up-to-logistic-regression",
    "title": "2 x 2 Contingency Tables",
    "section": "Building Up to Logistic Regression",
    "text": "Building Up to Logistic Regression\n\n\n\nExplanatory Variable\nMethod\n\n\n\n\nOne categorical variable\n2x2 contingency tables (2 groups)\n\n\n\nLogistic regression (3+ groups)\n\n\nOne numeric\nSimple logistic regression\n\n\nMix of categorical and numeric\nMultiple logistic regression",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#understanding-2x2-contingency-tables",
    "href": "applied-chapter08.html#understanding-2x2-contingency-tables",
    "title": "2 x 2 Contingency Tables",
    "section": "Understanding 2x2 Contingency Tables",
    "text": "Understanding 2x2 Contingency Tables\nThe main purpose is to compare the probability of a response outcome between two groups.\n\nAre smokers more likely to get cancer than non-smokers?\n\nExplanatory variable: smoker/non-smoker\n\nResponse variable: cancer/no cancer\n\n\nThere are three typical data collection designs:\n\nProspective\n\nRetrospective\n\nCompletely observational\n\n\nProspective Studies\n\nPopulations for each level of the explanatory variable are determined in advance.\n\nThis may happen naturally (e.g., obese vs. not obese) or by random assignment (e.g., placebo vs. treatment).\n\nSimple random samples are collected from each group.\nRow totals are fixed—the sample size for each group is determined before data collection.\nThe explanatory variable is fixed, and the response is observed after a follow-up period.\nExample: Vitamin C and Colds study\nRandomized experiments are a special type of prospective study:\n\nSubjects are randomly assigned to predictor groups.\nHelps mitigate confounding.\nAllows for causal conclusions.\nEqual row totals often suggest a prospective study and randomized design.\n\n\n\n\nRetrospective Studies\n\nReverse of prospective: the response variable is fixed in advance.\nSamples are selected based on response status; column totals are fixed.\nThe explanatory variable is determined after sample selection.\nExample: Cancer and smoking status study\n\nThis approach is often used when:\n\nEthical concerns prevent random assignment (e.g., assigning people to smoke).\nLong follow-up periods are impractical.\n\n\n\n\nObservational Studies\n\nOnly the grand total may be fixed—or no totals are fixed at all.\nThe researcher has little or no control over group membership.\nThere is greater potential for confounding.\nThere may be no clearly defined response or predictor, making the study more about association than group comparison.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#parameters-in-2x2-tables",
    "href": "applied-chapter08.html#parameters-in-2x2-tables",
    "title": "2 x 2 Contingency Tables",
    "section": "Parameters in 2x2 Tables",
    "text": "Parameters in 2x2 Tables\nThe goal is to compare two groups using either a difference in means or a difference in proportions.\n\nDifference in Means (t-tests)\n\nParameters:\n\n\\(\\mu_1\\): mean of the response for group 1\n\n\\(\\mu_2\\): mean of the response for group 2\n\n\nHypotheses:\n\n\\(H_0: \\mu_1 = \\mu_2\\)\n\\(H_a: \\mu_1 \\neq \\mu_2\\)\n\n95% Confidence Interval:\n\n\\(\\mu_1 - \\mu_2\\)\n\nIf 0 is not in the interval, the result supports \\(H_a\\).\n\n\n\n\nDifference in Proportions\n\nParameters:\n\n\\(\\pi_1\\): probability of event in group 1\n\n\\(\\pi_2\\): probability of event in group 2\n\n\nHypotheses:\n\n\\(H_0: \\pi_1 = \\pi_2\\)\n\n\\(H_a: \\pi_1 \\neq \\pi_2\\)\n\n95% Confidence Interval:\n\n\\(\\pi_1 - \\pi_2\\)\n\nIf 0 is not in the interval, the result supports \\(H_a\\).",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#problems-with-absolute-proportion-differences",
    "href": "applied-chapter08.html#problems-with-absolute-proportion-differences",
    "title": "2 x 2 Contingency Tables",
    "section": "Problems with Absolute Proportion Differences",
    "text": "Problems with Absolute Proportion Differences\nEven small absolute differences can be practically important:\n\\[\\pi_1 - \\pi_2 = 0.05 - 0.01 = 0.04\\] - The confidence interval may suggest a small estimated difference. - This is an absolute difference. - But it ignores relative scale: - A 5% event rate is 5 times higher than a 1% event rate!\nThis motivates the use of relative metrics like the odds ratio and relative risk, especially when working with rare events.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#two-additional-metrics-for-group-comparison",
    "href": "applied-chapter08.html#two-additional-metrics-for-group-comparison",
    "title": "2 x 2 Contingency Tables",
    "section": "Two Additional Metrics for Group Comparison",
    "text": "Two Additional Metrics for Group Comparison\n\nOdds Ratio\n\nGreat for retrospective studies\nCaptures relative difference\nCan be harder to understand intuitively and interpret\n\nRelative Risk\n\nAlso a relative difference metric\n\nMore intuitive to interpret\nOften confused with odds ratios\n\n\n\nOdds Example\n\nSuppose the odds of getting cancer are 1 to 2: \\(\\omega = \\frac{1}{2} = 0.5\\)\n\nOdds are not a probability because the denominator represents the number of non-events, not the total.\n\nThe corresponding probability of cancer is: \\(\\frac{1}{3} \\approx 0.33\\)\nAnother example using the complement rule:\n\nProbability of getting cancer: \\(3/8 = 0.375\\)\n\nProbability of not getting cancer: \\(5/8 = 1 - 3/8 = 0.625\\)\n\n\n\n\nOdds/Probability Relationship\nLet:\n\n\\(\\omega_c\\) = odds of cancer\n\\(\\pi_c\\) = probability of cancer\n\\(1 - \\pi_c\\): probability of not getting cancer\n\nThen:\n\\[\\omega_c = \\frac{\\pi_c}{1 - \\pi_c}\\] This formula shows how to convert between a probability and its corresponding odds.\n\nOdds Interpretation\n\n\\(0 &lt; \\omega &lt; 1\\): odds are against the event (i.e., not in the event’s favor)\n\\(\\omega = 1\\): 50/50 chance\n\\(\\omega &gt; 1\\): odds favor the event\nOdds are always positive (they cannot be negative)\n\n\n\n\nSummary Table: Parameters vs. Statistics\n\n\n\n\n\n\n\n\nMetric\nParameter (population)\nStatistic (sample)\n\n\n\n\nProportion / Probability\n\\(\\pi\\)\n\\(\\hat{\\pi}\\)\n\n\nOdds\n\\(\\omega\\)\n\\(\\hat{\\omega}\\)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#equivalent-hypotheses",
    "href": "applied-chapter08.html#equivalent-hypotheses",
    "title": "2 x 2 Contingency Tables",
    "section": "Equivalent Hypotheses",
    "text": "Equivalent Hypotheses\nIf two populations have the same probability of an event, they also have the same odds.\nThe following hypotheses are equivalent formulations of the null:\n\n\\(H_0\\): \\(\\pi_1 = \\pi_2\\)\n\n\\(H_0\\): \\(\\pi_1 - \\pi_2 = 0\\)\n\n\\(H_0\\): \\(\\omega_1 = \\omega_2\\)\n\n\\(H_0\\): \\(\\omega_1 - \\omega_2 = 0\\)\n\n\nRelative Hypotheses\nThe following are equivalent relative null hypotheses—these express the idea that the two groups have equal risk or odds:\n\n\\(H_0\\): \\(\\pi_1 = \\pi_2\\)\n\n\\(H_0\\): \\(\\frac{\\pi_1}{\\pi_2} = 1\\)\n\n\\(H_0\\): \\(\\omega_1 = \\omega_2\\)\n\n\\(H_0\\): \\(\\frac{\\omega_1}{\\omega_2} = 1\\)\n\nIn this context:\n\n\\(\\dfrac{\\omega_1}{\\omega_2}\\) is the odds ratio.\nThe odds ratio is always greater than 0.\n\nIf OR &gt; 1, the odds are higher in group 1.\n\nIf OR &lt; 1, the odds are lower in group 1.\n\n\n\nNote: Odds are not the same as probabilities!\nAvoid words like “chance” or phrases like “x times more likely” when interpreting an odds ratio.\nInstead, say: “The odds are x times higher.”",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#relative-risk",
    "href": "applied-chapter08.html#relative-risk",
    "title": "2 x 2 Contingency Tables",
    "section": "Relative Risk",
    "text": "Relative Risk\n\nNull hypothesis: \\(H_0: \\dfrac{\\pi_1}{\\pi_2} = 1\\)\nRelative risk is often easier to interpret than the odds ratio.\nSince it is a ratio of two probabilities (i.e., compares two probabilities directly), you can use words like “chance” or “more likely” in interpretation.\n\nTips for interpretation:\n\nPlace the larger proportion in the numerator.\n\nThis ensures the relative risk is greater than 1, making interpretation more intuitive.\n\n\nWhen using software:\n\nCheck how the “event” is defined — many functions choose this automatically.\nAlways verify the output with a quick mental or hand calculation.\nMost software allows you to change the reference group or event to match your intended interpretation.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#why-so-many-metrics",
    "href": "applied-chapter08.html#why-so-many-metrics",
    "title": "2 x 2 Contingency Tables",
    "section": "Why So Many Metrics?",
    "text": "Why So Many Metrics?\nAll three metrics aim to detect a difference in proportions between groups:\n\nDifference in proportions (absolute)\n\nOdds ratio (relative)\n\nRelative risk (relative)\n\n\nUse difference in proportions when events are common and you need a simple story.\nUse relative risk for rare events.\nUse odds ratio when working with retrospective studies.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#study-design-matters",
    "href": "applied-chapter08.html#study-design-matters",
    "title": "2 x 2 Contingency Tables",
    "section": "Study Design Matters",
    "text": "Study Design Matters\nRetrospective studies:\n\nOnly the odds ratio is valid.\nProportion and relative risk estimates are biased and are not valid metrics.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter08.html#statistical-inference-for-22-tables",
    "href": "applied-chapter08.html#statistical-inference-for-22-tables",
    "title": "2 x 2 Contingency Tables",
    "section": "Statistical Inference for 2×2 Tables",
    "text": "Statistical Inference for 2×2 Tables\nThere are several approaches to hypothesis testing and confidence interval construction, depending on:\n\nSample size\n\nStudy design\n\nHow well the test and interval method align\n\n\nAnalysis Workflow for Inference (Hypothesis Testing)\n\nIdentify the study design:\n\nProspective\n\nRetrospective*\n\nObservational\n\nChoose a metric:\n\nDifference in proportions → best when the event is not rare; easy to interpret\nRelative risk → best for rare events and clear interpretation\n\nOdds ratio → always valid; required for retrospective studies*\n\nState your hypotheses:\n\n\\(H_0\\): \\(\\pi_1 = \\pi_2\\) (difference in proportions)\n\n\\(H_0\\): \\(\\frac{\\pi_1}{\\pi_2} = 1\\) (relative risk)\n\n\\(H_0\\): \\(\\frac{\\omega_1}{\\omega_2} = 1\\) (odds ratio)\n\nFor purely observational studies, state without specifying parameters: \\(H_0\\): no association\n\nRun the test and construct a confidence interval:\n\nFor large sample sizes:\n\nUse a chi-squared test for the hypothesis test\nUse a Wald interval for the confidence interval\n\nConsider adding a continuity correction to improve the approximation\n\nFor small or moderate sample sizes:\n\nUse Fisher’s exact test for the hypothesis test\nUse a Fisher’s, bootstrap, or small-sample corrected Wald interval (e.g., Agresti–Coull) for the confidence interval\n\n\nInterpret the results:\n\nReport the test used and the associated p-value\n\nReport the confidence interval and explain what it means\n\nAlways state the method used for inference\n\n\n\n* The odds ratio is the only unbiased metric for retrospective studies.\n\n\n\nWorkflow Example\nPolio Vaccine Study (1954)\n\nRandomized: vaccine vs. placebo\n\n400,000 children\n\nPrimary concern: paralysis as a side effect\n\n\n\n\nGroup\nParalysis\nNo Paralysis\n\n\n\n\nPlacebo\n142\n199,858\n\n\nSalk Vaccine\n56\n199,944\n\n\n\n\nAnalysis Decisions\n\nDesign: Prospective (randomized)\n\nMetric: Difference in proportions for easy interpretation (all metrics are valid here)\n\nHypotheses: \\(H_0\\): \\(\\pi_{\\text{Placebo}} = \\pi_{\\text{Vaccine}}\\)\n\nSample size: Large \\(n\\) → use chi-squared test and Wald interval\n\nConclusion:\n&gt; Using a chi-squared test, there is significant evidence that the chances of a child suffering paralysis differ between placebo and vaccine groups (p-value = …).\n&gt; Using a Wald interval, we are 95% confident that the chance of paralysis is 0.029% to 0.0567% higher in the placebo group.\n\n\n\nCode\n# Wald test for difference in proportions (no continuity correction)\nprop.test(c(#eventsRow1,#eventsRow2),c(row1Total, row2Total), correct = FALSE) # events, total sample size, without continuity correction\nprop.test(c(142, 56), c(200000, 200000), correct = FALSE)\n\n# # Relative risk using epitab()\nepitab(polio, method = \"riskratio\", riskratio = \"wald\", rev = \"b\", pvalue = \"chi2\", verbose = TRUE)\n\n\n\n\nAlternative Framing (Relative Risk)\n\nBecause events are rare, relative risk may better communicate the result (very small changes in probability between the two groups)..\n\nThe p-value remains the same.\nThe interpretation of the confidence interval changes.\nThe testing conclusion is the same.\n\nWe are 95% confident that children in the placebo group are 1.86 to 3.45 times more likely to experience paralysis than children in the vaccine group.\n\n\nBe mindful that the choice of metric (difference in proportions vs. relative risk) can affect how results are interpreted in a practical context.\n\n\n\nAssumptions\n\nCounts in 2x2 tables should be independent.\n\nNo repeated measures or time-based observations",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>2 x 2 Contingency Tables</span>"
    ]
  },
  {
    "objectID": "applied-chapter09.html",
    "href": "applied-chapter09.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter09.html#objectives",
    "href": "applied-chapter09.html#objectives",
    "title": "Logistic Regression",
    "section": "",
    "text": "Understand how logistic regression models a binary response.\n\nUnderstand the structure and purpose of the simple logistic regression model.\nLearn how to interpret regression coefficients for both numeric and categorical predictors.\n\nRevisit the connection between logistic regression and 2×2 contingency tables.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter09.html#simple-logistic-regression-model",
    "href": "applied-chapter09.html#simple-logistic-regression-model",
    "title": "Logistic Regression",
    "section": "Simple Logistic Regression Model",
    "text": "Simple Logistic Regression Model\n\nClassification\n\nThe main distinction from linear regression: the response variable is categorical\n\nBinary classification examples:\n\nCancer or not\n\nClicked advertisement or not\n\nDefaulted on payment or not\n\n\n\n\n\nPredictive Models\n\nContinuous response: \\(Y = f(x)\\)\n\nCategorical response: \\(P(Y = \\text{Default} \\mid X) = f(X)\\)\n\nWith categorical responses, we predict the probability of the response, not the value itself.\n\nWe often write \\(f(X)\\) as \\(p(X)\\) to emphasize that it’s a probability given predictors \\(X\\).\nThis is still a function—it just describes how the probability changes with the predictors rather than the response directly.\n\n\n\nThe Linearity Problem\n\nA linear equation for \\(p(X)\\) doesn’t make sense:\n\nLinear functions range over \\((-\\infty, \\infty)\\).\nBut probabilities must stay between 0 and 1.\n\n\n\n\nVisualizing \\(p(X)\\)\n\nOne way to understand how \\(p(X)\\) behaves:\n\nBin a continuous predictor into categories.\n\nFor each bin, compute the proportion of the response.\n\n\n\n\nThe Path to Linearity\n\nScales and transformations—we apply transformations to make the model linear on a new scale.\n\n\\(p(X)\\): range \\((0,1)\\)\n\nOdds \\(= \\frac{p(X)}{1 - p(X)}\\): range \\((0, \\infty)\\)\n\nLog odds (logit) \\(= \\ln\\left(\\frac{p(X)}{1 - p(X)}\\right)\\): range \\((-\\infty, \\infty)\\)\n\n\nThe logit function maps probabilities to the full real number line.\n\nThis transformation enables linear modeling, because probabilities on the logit scale tend to be more linear with the predictor.\n\n\n\nModel Statement\n\nLogistic regression models the log odds as a linear function of \\(X\\):\n\\[\n\\ln\\left(\\frac{p(X)}{1 - p(X)}\\right) = \\beta_0 + \\beta_1 X\n\\]\n\n\n\nParameter Estimation\n\nMultiple Linear Regression (MLR)\n\nCoefficient estimates minimize the residual sum of squares.\n\nClosed-form solution exists via matrix algebra.\n\n\n\nLogistic Regression\n\nCoefficient estimates minimize the log loss (cross-entropy) error function.\nNo closed-form solution, i.e., cannot use matrix multiplication to find the answer.\nOptimization (minimizing the log loss) is done numerically.\n\n\n\n\nHypothesis Testing\n\nTo understand the relationship between a predictor and the response, test the slope coefficient:\n\n\\(H_0\\): \\(\\beta_1 = 0\\)\n\n\\(H_a\\): \\(\\beta_1 \\ne 0\\)\n\n\nTest statistic (z-statistic): \\(Z = \\frac{\\hat{\\beta}_1}{SE(\\hat{\\beta}_1)}\\)\n95% confidence interval: \\(\\hat{\\beta}_1 \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\beta}_1)\\)\nThe null distribution is standard normal: \\(Z \\sim N(0, 1)\\)\n\nSome software reports a chi-squared test instead of a z-test.\n\nIt squares the z-statistic: \\(Z^2\\)\nThen uses a \\(\\chi^2\\) distribution with 1 degree of freedom to compute the p-value.\n\nThis gives the same p-value as the two-sided z-test.\n\n\n\n\nPredicted Probabilities\n\nLogistic regression estimates the log odds, but we often want \\(p(X)\\): \\[\n\\ln\\left(\\frac{p(X)}{1 - p(X)}\\right) = \\beta_0 + \\beta_1 X\n\\] \\[\n\\frac{p(X)}{1 - p(X)} = e^{\\beta_0 + \\beta_1 X}\n\\] \\[\np(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\n\\]",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter09.html#interpreting-coefficients-continuous-predictors",
    "href": "applied-chapter09.html#interpreting-coefficients-continuous-predictors",
    "title": "Logistic Regression",
    "section": "Interpreting Coefficients: Continuous Predictors",
    "text": "Interpreting Coefficients: Continuous Predictors\n\nOdds and Odds Ratios\n\nLogistic regression coefficients have good interpretational value.\nLogistic regression coefficients are interpreted using odds ratios.\n\nWhether the predictor is numeric or categorical determines the interpretation.\n\nFor a continuous predictor \\(X\\), the odds of the event occurring are:\n\\[\n\\text{Odds}(X) = \\frac{p(X)}{1 - p(X)} = e^{\\beta_0 + \\beta_1X}\n\\]\n\nExample:\n\n\\(\\text{Odds}(X = 500) = e^{\\beta_0 + \\beta_1 \\cdot 500}\\)\n\n\\(\\text{Odds}(X = 501) = e^{\\beta_0 + \\beta_1 \\cdot 501}\\)\n\nThe odds ratio (OR) for a 1-unit increase in \\(X\\) is:\n\\[\n\\frac{e^{\\beta_0 + \\beta_1 \\cdot 501}}{e^{\\beta_0 + \\beta_1 \\cdot 500}} = e^{\\beta_1}\n\\]\nInterpretation: For every 1-unit increase in \\(X\\), the odds of the event occurring change by a factor of \\(e^{\\beta_1}\\).\n\n\n\nGeneralized Interpretation\n\nThis interpretation does not depend on the specific value of \\(X\\).\n\nFor a \\(\\Delta\\)-unit increase in \\(X\\), the odds change by a factor of \\(e^{\\Delta \\cdot \\beta_1}\\).\n\nExample:\n\nA $500 increase in balance increases the odds of default by a factor of 15.64.\n\nThat is, the odds of defaulting with a $1,000 balance are 15.64 times higher than with a $500 balance.\n\n\n\n\nTips\n\nOdds ratios describe relative, not absolute, changes in risk.\n\nUse predicted probabilities to assess absolute likelihood.\n\nFor clear communication, report odds ratios using meaningful values of \\(X\\) and real-world increments.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter09.html#interpreting-coefficients-categorical-predictors",
    "href": "applied-chapter09.html#interpreting-coefficients-categorical-predictors",
    "title": "Logistic Regression",
    "section": "Interpreting Coefficients: Categorical Predictors",
    "text": "Interpreting Coefficients: Categorical Predictors\n\nDummy Variables\n\nCategorical variables are dummytized (converted into binary indicators).\nOne coefficient is estimated for each level of the categorical variable, minus one.\nThe omitted level is the reference category, and its effect is absorbed into the intercept.\nCoefficients represent odds ratios relative to this reference group.\n\n\n\nExample: Student Status\n\nPredictor variable: student\n\nYes (1), No (0)\n\nOdds if student: \\(e^{\\beta_0 + \\beta_1 \\cdot 1}\\)\n\nOdds if not a student: \\(e^{\\beta_0 + \\beta_1 \\cdot 0} = e^{\\beta_0}\\)\nOdds ratio (OR):\n\\[\n\\text{OR} = \\frac{e^{\\beta_0 + \\beta_1}}{e^{\\beta_0}} = e^{\\beta_1}\n\\]\nInterpretation: The odds of defaulting for a student are \\(e^{\\beta_1}\\) times higher (or lower) than for a nonstudent.\n\n\n\nConfidence Intervals for Odds Ratios\n\n95% confidence interval for \\(\\beta_1\\):\n\\[\n\\hat{\\beta}_1 \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\beta}_1)\n\\]\nExponentiate the interval endpoints to get a 95% confidence interval for the odds ratio:\n\\[\n\\left( e^{\\hat{\\beta}_1 - z_{\\alpha/2} \\cdot SE(\\hat{\\beta}_1)},\\ e^{\\hat{\\beta}_1 + z_{\\alpha/2} \\cdot SE(\\hat{\\beta}_1)} \\right)\n\\]\nReport the odds ratio and its confidence interval; interpretation is typically given for the point estimate (coefficient). Use the interval to communicate sampling error, without a lengthy worded interpretation.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter09.html#general-workflow-and-considerations",
    "href": "applied-chapter09.html#general-workflow-and-considerations",
    "title": "Logistic Regression",
    "section": "General Workflow and Considerations",
    "text": "General Workflow and Considerations\n\nAssumptions\n\nObservations are independent.\nThe log odds of the outcome are linearly related to continuous predictors.\nNo important confounding variables have been omitted.\n\n\n\nAssessing Model Fit\n\nTraditional residual plots are less informative with binary outcomes (variance changes are expected).\nInstead:\n\nCompare predicted probabilities to observed proportions.\n\nDo the estimated effects align with what you saw during EDA?\n\nUse the Hosmer-Lemeshow test:\n\n\\(H_0\\): model fits well\n\n\\(H_a\\): model does not fit well\n\n\n\n\n\nIf the Fit Is Poor\n\nUnusual trends in EDA may signal that the linearity of log odds assumption is violated.\n\nTry adding polynomial terms or interaction effects.\n\n\nA rejected Hosmer-Lemeshow test does not always imply a problem with poor model fit, especially with large samples.\n\n\n\nRecommended Workflow\n\nEDA\n\nUse LOESS curves for continuous predictors.\n\nUse mosaic plots or proportion comparisons for categorical predictors.\n\n\nFit the model\n\nAssess model fit using diagnostic tests and visual checks.\n\n\nInference\n\nUse a z-test to assess whether coefficients are significantly different from zero.\n\nInterpret coefficients using odds ratios.\nReport confidence intervals for the odds ratios.\n\nChoose a sensible unit change based on the variable’s scale and context.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter09.html#looking-ahead-multiple-logistic-regression",
    "href": "applied-chapter09.html#looking-ahead-multiple-logistic-regression",
    "title": "Logistic Regression",
    "section": "Looking Ahead: Multiple Logistic Regression",
    "text": "Looking Ahead: Multiple Logistic Regression\n\nLike multiple linear regression, most applications of logistic regression involve multiple predictors.\nKey skills from this chapter:\n\nUnderstanding the logit function/transformation.\nInterpreting coefficients using odds ratios.\nUsing EDA to guide model building and interpretation.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter10.html",
    "href": "applied-chapter10.html",
    "title": "Multiple Logistic Regression",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Multiple Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter10.html#objectives",
    "href": "applied-chapter10.html#objectives",
    "title": "Multiple Logistic Regression",
    "section": "",
    "text": "Introduce multiple logistic regression as a tool for classification and statistical inference.\n\nExplore the benefits of using multiple predictors, including adjusting for confounders.\n\nUnderstand how to interpret coefficients and interactions.\n\nLearn how to assess model fit and compare alternative models.\n\nReview strategies for feature selection and model complexity.\n\nApply a general modeling workflow in practical settings.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Multiple Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter10.html#motivations-for-multiple-logistic-regression",
    "href": "applied-chapter10.html#motivations-for-multiple-logistic-regression",
    "title": "Multiple Logistic Regression",
    "section": "Motivations for Multiple Logistic Regression",
    "text": "Motivations for Multiple Logistic Regression\n\nSimple vs. Multiple Logistic Regression\n\nSimple Logistic Regression:\n\nAssumes there are no confounding variables.\n\nEstimates the effect of a single predictor without accounting for other factors.\n\n\nMultiple Logistic Regression:\n\nAdjusts for additional variables while estimating the effect of one predictor.\n\nAllows for both numerical and categorical predictors.\n\n\n\n\nSimpson’s Paradox\n\nAn example where a confounding variable distorts the observed relationship between predictors and the response.\n\nCrane/Eagle – Math/Physics Example:\n\nMath students are more likely to pass than physics students.\n\nMost Eagle students were in math, while Crane had an even mix.\n\nA single 2×2 table masks this confounding structure.\n\nLogistic regression enables comparisons between schools while holding department fixed.\n\nCan also test for interaction effects (e.g., school × department).\n\n\n\n\nPrediction vs. Explanation\n\nIdentifying important health risk factors is an explanatory modeling goal—a statistical inference problem.\n\nThe goal is not just to detect which variables matter, but to quantify their effects while accounting for other factors.\n\n\nIn contrast, clinicians may also be interested in predicting the probability of disease for individual patients.\n\nThe emphasis is on accurate predictions, not necessarily understanding the individual role of each variable.\n\n\n\nCase Study Examples\n\nCAD Study: Predicting coronary artery disease using sex, age, and ECG results.\n\nQuestions: Is sex still a risk factor after adjusting for age and ECG? Are there interaction effects?\n\n\nTitanic: Predicting survival based on ticket class, age, and sex.\n\nQuestions: Which factors had the largest impact on survival? Do the effects depend on each other?",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Multiple Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter10.html#the-multiple-logistic-regression-model",
    "href": "applied-chapter10.html#the-multiple-logistic-regression-model",
    "title": "Multiple Logistic Regression",
    "section": "The Multiple Logistic Regression Model",
    "text": "The Multiple Logistic Regression Model\nFor multiple predictors \\(X = (X_1, X_2, \\ldots, X_p)\\), the general logistic regression model is: \\[\n\\log\\left( \\frac{p(X)}{1 - p(X)} \\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p\n\\]\nThis model expresses the log odds of the outcome as a linear combination of predictors.\n\nInterpretation\n\nAdditive models:\n\nEach predictor appears once in the model.\n\\(e^{\\hat{\\beta}}\\) is interpreted as an odds ratio.\nInterpretation assumes we are “holding all other variables fixed.”\n\nComplex models:\n\nInclude interaction terms and/or polynomial terms.\nOdds ratios are still interpretable but require careful consideration of the regression formula.\nEffects plots are commonly used for visual interpretation in these cases.\n\n\n\nOdds Ratios in Complex Models\nWhen a model includes interaction terms, odds ratios must be interpreted in the context of the full model. Here is an example:\nModel:\n\\[\n\\log\\left( \\frac{p}{1 - p} \\right) = \\beta_0 + \\beta_1 \\cdot \\text{Age} + \\beta_2 \\cdot \\text{Smoking} + \\beta_3 \\cdot (\\text{Age} \\times \\text{Smoking})\n\\]\n\nAge: continuous\n\nSmoking: binary (1 = smoker, 0 = non-smoker)\n\nInterpretation:\n\nFor non-smokers (Smoking = 0):\nOdds ratio for a 1-year increase in age is \\(\\exp(\\beta_1)\\)\nFor smokers (Smoking = 1):\nOdds ratio for a 1-year increase in age is \\(\\exp(\\beta_1 + \\beta_3)\\)\n\n\nKey idea: Odds ratios remain interpretable but must account for interaction terms and the full model formula.\n\n\n\n\nClassification Boundaries\n\nAdditive models:\n\nProduce linear decision boundaries (when predictors are numeric)\nSimilar to LDA but without assuming normality of predictors\n\nComplex models:\n\nCan produce nonlinear boundaries, depending on the terms included:\n\nCategorical × continuous: separate linear boundary per category\nContinuous × continuous or polynomial: curved or non-parallel boundaries\nCategorical × categorical: nonlinear effects, but not meaningful to describe in terms of a boundary shape",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Multiple Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter10.html#feature-selection",
    "href": "applied-chapter10.html#feature-selection",
    "title": "Multiple Logistic Regression",
    "section": "Feature Selection",
    "text": "Feature Selection\n\nPenalized Logistic Regression\n\nUse glmnet with family = \"binomial\" to fit logistic regression models.\n\nUseful for both regularization and feature selection.\n\n\n\nStepwise Selection\n\nCommon approaches include forward, backward, and stepwise procedures.\nBest subset selection is also possible.\nModel comparison metrics:\n\nAIC (Akaike Information Criterion)\nLog loss or Brier Score, evaluated on a validation set or via K-fold cross-validation\n\n\n\n\nSeparability Problem\n\nWhen training data is perfectly separated:\n\nThis signals strong, influential predictors.\nHowever, the maximum likelihood estimate (MLE), i.e., the regression coefficient that minimizes the log loss, becomes \\(\\hat{\\beta} = \\infty\\).\n\nSoftware may issue warnings or fail to converge.\nPredicted probabilities become exactly 0 or 1.\n\nNo uncertainty estimate, confidence intervals, or inference is possible.\n\n\nSolutions:\n\nFor explanation: use penalization or Firth’s logistic regression\n\nFor prediction: consider Firth’s logistic, penalized logistic (e.g., glmnet), or alternative models (e.g., LDA)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Multiple Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter10.html#complex-logistic-models",
    "href": "applied-chapter10.html#complex-logistic-models",
    "title": "Multiple Logistic Regression",
    "section": "Complex Logistic Models",
    "text": "Complex Logistic Models\n\nModeling Strategy\n\nWhen including higher-order interaction terms:\n\nInclude the corresponding lower-order interactions\n\ne.g., if modeling a 3-way interaction, also include all 2-way interactions\n\nUse ANOVA-style tests to assess overall significance at each level of complexity\nRemove non-significant higher-order interactions and reassess model fit\nCompare models using:\n\nHosmer-Lemeshow test\nValidation or cross-validation metrics\n\n\n\n\n\nCoefficient Interpretation\n\nUse a similar strategy as in multiple linear regression:\n\nIdentify the appropriate contrast to combine regression coefficients\n\nAllows estimation of specific comparisons or trends from significant interactions\n\nExponentiate combined coefficients to obtain odds ratio interpretations\n\nIn more complex models:\n\nInterpretation becomes challenging\nUse effects plots to visualize and communicate model predictions\n\n\n\n\nEffects Plots\n\nDisplay predicted probabilities across 1–3 variables\nHold other variables fixed:\n\nCategorical: reference level (depends on software)\nContinuous: mean or median (depends on software)\n\n\n\nNote: Effects plots are not part of EDA. They visualize predictions from the fitted model, not the raw data. Their appearance reflects the model structure, not the underlying variable relationships.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Multiple Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter10.html#general-workflow",
    "href": "applied-chapter10.html#general-workflow",
    "title": "Multiple Logistic Regression",
    "section": "General Workflow",
    "text": "General Workflow\nThe overall workflow for multiple logistic regression closely parallels that of multiple linear regression.\n\nModeling Steps\n\nDefine primary question(s) and predictor(s)\nIdentify potential confounders and covariates\n\nThese are additional variables you want to account for\n\nPerform EDA and data cleaning\n\nUse summary statistics and plots\nExplore possible interactions\n\nFit candidate models\n\nGuided by findings from EDA\nUse ANOVA tests or feature selection to choose an appropriate model complexity\n\nAssess model fit\n\nUse the Hosmer-Lemeshow test\nEvaluate performance on a validation set or using K-fold cross-validation\n\nInterpret the final model\n\nFor additive models: interpret coefficients as odds ratios\nFor complex models with interactions:\n\nUse appropriate contrasts to combine coefficients\nUse effects plots for interpretation and communication\n\n\n\n\n\nClassification Considerations\n\nTry multiple classification methods (e.g., non-parametric approaches) and compare error metrics\nChoose a classification threshold based on context\n\nFor example, consider the cost of false positives vs. false negatives\n\nValidate both the model and the threshold using:\n\nAn independent test set\nAn entirely new dataset, if available\n\nSet up a monitoring strategy:\n\nRegularly check prediction accuracy\nAdjust the model if data collection methods or population characteristics change",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Multiple Logistic Regression</span>"
    ]
  },
  {
    "objectID": "applied-chapter11.html",
    "href": "applied-chapter11.html",
    "title": "Principal Component Analysis",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "applied-chapter11.html#objectives",
    "href": "applied-chapter11.html#objectives",
    "title": "Principal Component Analysis",
    "section": "",
    "text": "Introduce Principal Component Analysis (PCA) as a tool for unsupervised data analysis and dimensionality reduction.\n\nDescribe the difference between supervised and unsupervised analysis.\n\nExplain the motivation for reducing data dimensionality.\n\nExplore practical applications of PCA.\n\nReview the technical foundations of PCA.\n\nIntroduce nonlinear dimensionality reduction methods (t-SNE, MDS).",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "applied-chapter11.html#what-is-pca",
    "href": "applied-chapter11.html#what-is-pca",
    "title": "Principal Component Analysis",
    "section": "What Is PCA?",
    "text": "What Is PCA?\n\nSupervised vs. Unsupervised Learning\n\nSupervised learning: Both predictors and the response variable are provided. Models aim to:\n\nExplain relationships.\nPerform hypothesis testing and build confidence intervals.\nMake predictions.\n\nUnsupervised learning: Only predictors are provided.\n\nNo response variable is used.\nGoals vary; interpretation is often subjective.\nNot used for prediction or traditional explanation as with linear and logistic regression.\nTypically more challenging than supervised methods.\nNo standard or easy way to validate results on future data.\nCommon applications include:\n\nExploratory data analysis (EDA) to support supervised analysis.\nIdentifying subgroups or patterns.\nImproving computational efficiency.\nSimplifying downstream prediction tasks.\n\n\n\n\n\nUnsupervised Tools\nCommon techniques include:\n\nData reduction:\n\nPrincipal Component Analysis (PCA)\n\nt-SNE\n\nMultidimensional Scaling (MDS)\n\nClustering:\n\nHierarchical\n\nk-means clustering",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "applied-chapter11.html#pca-and-data-reduction",
    "href": "applied-chapter11.html#pca-and-data-reduction",
    "title": "Principal Component Analysis",
    "section": "PCA and Data Reduction",
    "text": "PCA and Data Reduction\n\nMotivation for Data Reduction\n\nWhen there are too many variables, it becomes difficult to analyze, visualize, or model the data.\nThe goal of PCA is to create a smaller set of variables that preserves as much information as possible.\nWhat counts as “information” depends on the algorithm.\n\nFor PCA, information is defined in terms of variability.\n\n\n\n\nPrincipal Components\n\nPCA creates new variables \\(Z_1, Z_2, \\dots, Z_p\\) called principal components.\nEach component \\(Z_j\\) is a linear combination of the original \\(X_i\\) variables.\n\nEach principal component uses different weights (coefficients): \\[\nZ_1 = \\phi_{11}X_1 + \\phi_{12}X_2 + \\dots + \\phi_{1p}X_p\n\\] \\[\nZ_2 = \\phi_{21}X_1 + \\phi_{22}X_2 + \\dots + \\phi_{2p}X_p\n\\] \\[\n\\vdots\n\\] \\[\nZ_p = \\phi_{p1}X_1 + \\phi_{p2}X_2 + \\dots + \\phi_{pp}X_p\n\\]\n\nPCA always produces the same number of principal components as the original number of variables.\n\nSo where is the “reduction”?\n\nDo we keep only a few?\n\nIf so, how many? Which ones? Based on what criterion?\n\n\n\n\n\nProperties of Principal Components\n\nUncorrelated with each other\nOrdered by variance: \\(\\text{Var}(Z_1) &gt; \\text{Var}(Z_2) &gt; \\dots &gt; \\text{Var}(Z_p)\\)\n\nTotal variance is preserved: \\[\n\\sum_{i=1}^p \\text{Var}(X_i) = \\sum_{i=1}^p \\text{Var}(Z_i)\n\\]\n\n\n\nReducing Dimensions\n\nBecause components are ordered by variance:\n\nLater components often have very low variance—some essentially zero.\n\nThese components carry little information and can be dropped.\nWe keep only the first \\(k\\) components where \\(k &lt; p\\), and \\(p\\) is the original number of variables.\n\nTotal variability is approximately preserved: \\[\n\\sum_{i=1}^p \\text{Var}(X_i) \\approx \\sum_{i=1}^k \\text{Var}(Z_i), \\quad \\text{where } k &lt; p\n\\]",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "applied-chapter11.html#performing-pca",
    "href": "applied-chapter11.html#performing-pca",
    "title": "Principal Component Analysis",
    "section": "Performing PCA",
    "text": "Performing PCA\n\nFrom Data to Components\n\nPCA requires:\n\nCentering (and possibly scaling) the data:\n\nCentering means subtracting the mean from each variable.\n\nComputing either:\n\nThe covariance matrix (if the data are unscaled)\nThe correlation matrix (if the data are standardized; this is the standard operating procedure)\n\nStandardizing (scaling) transforms the data to z-scores, allowing PCA to focus on relative variation rather than absolute scales.\n\n\n\nFrom the matrix, extract:\n\nEigenvectors: the weights (loadings) used to compute \\(Z_i\\)\nEigenvalues: the variance of each \\(Z_i\\)\nEach eigenvalue has an associated eigenvector. There are \\(p\\) of each.\n\n\n\n\nMatrix View\n\nThe eigenvector for \\(Z_1\\) is \\((\\phi_{11}, \\phi_{12}, \\dots, \\phi_{1p})\\).\nThe eigenvector matrix contains all loading coefficients. Eigenvectors are arranged columnwise.\n\nTranspose the loading matrix and multiply it by the original variable matrix to obtain \\(p\\) rows (one per principal component).\n\nEigenvalues quantify the variance of each principal component. These are sometimes expressed in matrix form.\n\n\n\nScree Plots and Component Selection\n\nScree plots:\n\nPlot eigenvalues in decreasing order.\nPlot variance proportions: \\(\\dfrac{\\lambda_i}{\\sum_{j=1}^p \\lambda_j}\\), where \\(\\lambda_i\\) is the \\(i\\)th eigenvalue.\nPlot the cumulative proportion of variance.\n\nStrategies for reduction:\n\nKeep enough principal components (PCs) to explain approximately 80–90% of the variance (cutoff may be arbitrary).\nKeep the first 3–4 PCs for visualization in EDA.\nLook for an “elbow” in the scree plot, where additional components contribute little to the explained variance.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "applied-chapter11.html#applications-of-pca",
    "href": "applied-chapter11.html#applications-of-pca",
    "title": "Principal Component Analysis",
    "section": "Applications of PCA",
    "text": "Applications of PCA\n\nSimplify Regression and Classification\n\nApply PCA to the predictors only.\nThe resulting predictors (PCs) are uncorrelated—no multicollinearity.\nReduces dimensionality (i.e., fewer predictors, more compact model).\nImportant notes:\n\nPCA is unsupervised!\nThe PCs may not align better with the response variable than the original predictors.\nPCA should be viewed as a preprocessing step, not a predictive tool.\n\n\n\n\nPCA for EDA in Classification\n\nPurpose\n\nGain insight into whether the predictors might work well—this is not for model fitting.\nConsider using feature selection instead:\n\nIf the project requires using original predictors (e.g., for interpretability)\nWhen the number of predictors is very large\n\n\n\n\nStrategy\n\nPlot PCs to visualize group separation.\nIf clear separation exists, the predictors may be promising.\nIf not:\n\nPredictors may lack signal or be irrelevant.\nAlternatively, nonlinear methods may be needed:\n\nTry nonlinear data reduction or increase model complexity.\n\n\nUse this as a sanity check: Is good prediction accuracy likely from these variables?\n\n\n\n\nImage Compression\n\nReduce the number of pixels (variables).\nPCA compresses the data by reducing dimensionality.\nReconstruct the image from a limited number of components.\n\n\n\nCommon Pitfalls\n\nNever include the response variable in PCA.\nInterpreting component coefficients can be challenging.\n\nStrategies exist, such as examining the eigenvectors to summarize key contributions.\n\nPCA is sensitive to outliers.\nCategorical variables can cause misleading results, especially with arbitrary numeric coding.\nPCA preserves only variance:\n\nAllows visualization of the “global” structure (e.g., linear separation)\nBut proximity in PC space does not guarantee proximity in the original space",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "applied-chapter11.html#nonlinear-data-reduction",
    "href": "applied-chapter11.html#nonlinear-data-reduction",
    "title": "Principal Component Analysis",
    "section": "Nonlinear Data Reduction",
    "text": "Nonlinear Data Reduction\n\nBeyond Linear PCA\n\nLinear PCA maps data to a linear plane:\n\nReduces the dimensionality of the data\nProjects observations onto the “closest” plane or hyperplane\n\nNonlinear methods allow curved manifolds:\n\nProject points onto lower-dimensional, nonlinear surfaces\nRequire careful selection of parameters and algorithms\nOften used strictly for EDA, not as inputs for predictive models\n\n\n\n\nCommon Nonlinear Reduction Techniques\n\nKernel PCA\n\nUses kernel functions (e.g., polynomial, radial basis function (RBF))\n\nPerforms PCA in a transformed feature space\n\nCan be used in predictive models\n\n\nMultidimensional Scaling (MDS)\n\nPreserves distances or similarities between points\n\nTypically used for 2D/3D visualizations\n\nNot directly used in predictive models\n\n\nt-SNE (t-Distributed Stochastic Neighbor Embedding)\n\nNonparametric\n\nCaptures local structure using probability models (i.e., models distances between points probabilistically)\n\nSeeks a lower-dimensional map that preserves the distribution of pairwise distances\n\n\nNot used in predictive models\n\nResults can vary based on hyperparameters like perplexity\n\nSometimes PCA is applied first to reduce computation time",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "applied-chapter11.html#pca-technical-details",
    "href": "applied-chapter11.html#pca-technical-details",
    "title": "Principal Component Analysis",
    "section": "PCA: Technical Details",
    "text": "PCA: Technical Details\n\nMatrix Decomposition\n\nAssume multiple variables follow a multivariate distribution.\nPrincipal components are:\n\nUncorrelated\nHave variances equal to their corresponding eigenvalues\nComputed using eigenvectors\n\nThese eigenvectors provide the coefficients for creating the principal components as linear combinations of the original variables.\n\n\nDecompose \\(\\Sigma\\) or \\(R\\): \\[\\Sigma = \\phi \\Lambda \\phi'\n\\] where:\n\n\\(\\phi\\) = matrix of eigenvectors\n\n\\(\\Lambda\\) = diagonal matrix of eigenvalues\n\nKey property: the eigenvector matrix is orthonormal, so its transpose is its inverse: \\[\n\\phi^\\top \\phi = \\phi \\phi^\\top = I\n\\]",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html",
    "href": "applied-chapter12.html",
    "title": "Clustering",
    "section": "",
    "text": "Objectives",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#objectives",
    "href": "applied-chapter12.html#objectives",
    "title": "Clustering",
    "section": "",
    "text": "Understand the goal of clustering as an unsupervised learning method.\n\nLearn how k-means and hierarchical clustering assign observations to groups.\n\nExplore linkage methods and distance metrics used in clustering.\n\nEvaluate clustering results using cluster validity metrics.\n\nVisualize clustering output using dendrograms and heatmaps.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#motivation-for-clustering",
    "href": "applied-chapter12.html#motivation-for-clustering",
    "title": "Clustering",
    "section": "Motivation for Clustering",
    "text": "Motivation for Clustering\nWhen plotting two numerical variables:\n\nAre all observations part of one homogeneous group?\n\nOr do some form distinct subgroups that behave more similarly to each other?\n\nKey points:\n\nClustering is an unsupervised learning method.\n\nEach data point is assigned to a group (cluster).\n\nPoints within a cluster are more similar.\n\nPoints in different clusters are more dissimilar.\n\n\nHeterogeneous Populations\n\nMost populations are heterogeneous.\nBenefits of identifying subpopulations:\n\nDeeper EDA and sanity checks (for classification problems)\n\nUnique trends may require unique models\n\nBetter decision-making in downstream tasks",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#k-means-clustering",
    "href": "applied-chapter12.html#k-means-clustering",
    "title": "Clustering",
    "section": "k-Means Clustering",
    "text": "k-Means Clustering\n\nMetric for Cluster Fit\nAssuming observations are already assigned to clusters, there is a trade-off between:\n\nWithin-cluster variability\n\nBetween-cluster variability\n\nWithin-cluster metric:\n\nLet \\(k\\) be the number of clusters.\n\nLet \\(C_k\\) be the set of observations assigned to cluster \\(k\\).\n\nDefine within-cluster variability \\(W(C_k)\\) as: \\[\nW(C_k) = \\frac{1}{|C_k|} \\sum_{i,j \\in C_k} d(x_i, x_j)^2\n\\] where, \\(|C_k|\\) is the number of observations in cluster \\(k\\), and \\(d(x_i, x_j)\\) is the Euclidean distance between two points in the same cluster.\nThe goal is to minimize overall within-cluster variability.\n\nHowever, within-cluster variability can always be minimized by increasing \\(k\\), so the key question is: how many clusters are actually present?\n\n\n\nChallenges in Minimizing \\(W(C_k)\\)\n\nThere are a large number of possible cluster assignments.\nThe number of possible assignments increases with \\(k\\) (number of clusters) and \\(n\\) (sample size).\nk-means clustering may converge to a local minimum rather than the global best solution.\nThe number of clusters \\(k\\) must be specified upfront to initialize the algorithm.\n\n\n\nk-Means Algorithm\n\nRandomly assign observations to cluster groups.\n\nReassignment:\n\nCompute the centroid of each group (i.e., the mean of the assigned observations).\n\nReassign observations to the nearest centroid.\n\n\nRepeat step 2 until within-cluster variability converges.\n\n\n\nDefining “Close”\nDistance metrics:\n\nEuclidean distance\nMahalanobis distance\nManhattan distance",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#hierarchical-clustering",
    "href": "applied-chapter12.html#hierarchical-clustering",
    "title": "Clustering",
    "section": "Hierarchical Clustering",
    "text": "Hierarchical Clustering\n\nDoes not require specifying \\(k\\) in advance.\n\nBegins with each observation as its own cluster.\n\nFuses observations to create progressively coarser clusters.\n\nProduces a dendrogram to visualize the clustering process.\n\n\nLinkage\n\nA distance (dissimilarity) metric is used between observations.\n\nClusters can fuse:\n\nTwo points\n\nOne cluster and one point\n\nTwo clusters\n\n\nThe dissimilarity metric between clusters is called linkage.\n\n\n\nCommon Linkage Types\n\nComplete linkage uses the maximum pairwise distance.\nSingle linkage uses the minimum pairwise distance.\nAverage linkage uses the mean of all pairwise distances.\nCentroid linkage uses distance between cluster centroids.\n\n\nComplete Linkage\n\nMaximal inter-cluster dissimilarity\n\nCompute all pairwise distances between cluster A and cluster B\n\nRecord the largest pairwise distance between the clusters\n\nMerge clusters with the smallest maximum distance (i.e., smallest dissimilarity)\n\n\n\nSingle Linkage\n\nMinimal inter-cluster dissimilarity\n\nCompute all pairwise distances between cluster A and cluster B\n\nRecord the smallest pairwise distance between the clusters\n\nMerge clusters with the smallest minimum distance (i.e., smallest dissimilarity)\n\nCan produce trailing dendrograms with single observations (i.e., many single observations fused with clusters)\n\n\n\nAverage Linkage\n\nMean inter-cluster dissimilarity\n\nCompute all pairwise distances between cluster A and cluster B\n\nRecord the mean distance between clusters\n\nRepeat for all pairwise clusters available\n\nMerge clusters with the smallest average\n\n\n\nCentroid Linkage\n\nMean inter-cluster dissimilarity\n\nDistance between cluster centroids\n\nCompute centroids of each cluster\n\nMerge clusters whose centroids are closest (i.e., have the smallest distance)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#considerations-for-either-tool",
    "href": "applied-chapter12.html#considerations-for-either-tool",
    "title": "Clustering",
    "section": "Considerations for Either Tool",
    "text": "Considerations for Either Tool\n\nKey Considerations\n\nWhich dissimilarity metric? (distance or correlation)\nShould variables be standardized?\nWhich linkage type? (for hierarchical)\nHow many clusters?\n\n\n\nCorrelation vs. Distance\n\nObservations may be far apart by distance but close in terms of correlation.\nExample:\n\nDistance metric: heavy vs. light shoppers\nCorrelation metric: shoppers buying similar items\n\n\n\n\nStandardization\n\nWithout standardization: variables with large scales dominate clustering.\nWith standardization: each variable contributes equally.\nRecommendation: Standardize unless there is a strong reason not to.\n\n\n\nChoice of Linkage\n\nResults vary depending on the linkage method.\n\nComplete and average linkage:\n\nCommonly used\n\nProduce easier-to-read dendrograms\n\n\nSingle linkage:\n\nUseful for identifying outliers\n\nMay form loosely connected clusters (i.e., observations within a cluster may be less similar than desired).\n\n\n\n\nChoosing the Number of Clusters\n\nApply clustering with different values of \\(k\\).\n\nCompute cluster validity metrics.\n\nPlot each metric against cluster size to guide the decision.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#cluster-validity-metrics",
    "href": "applied-chapter12.html#cluster-validity-metrics",
    "title": "Clustering",
    "section": "Cluster Validity Metrics",
    "text": "Cluster Validity Metrics\n\nInternal Cluster Validity\n\nNo ground truth available\n\nEstimate within-cluster vs. between-cluster variation\n\n\n\nCommon Metrics\n\nSilhouette statistic\nDunn index\nCubic clustering criterion (SAS)\n\n\nSilhouette Statistic\nFor each observation: - Calculate average dissimilarity within its cluster.\n- Calculate the minimum average dissimilarity to a different cluster.\n- Silhouette value for observation \\(i\\): \\[\n  \\text{Silhouette}_i = \\frac{\\text{between} - \\text{within}}{\\max(\\text{between}, \\text{within})}\n  \\] - Average silhouette values summarize overall clustering quality.\n\n\nDunn Index\n\nRatio: \\[\n\\frac{\\text{minimum distance between points in different clusters}}{\\text{maximum distance between points within the same cluster}}\n\\]\nHigher Dunn index indicates stronger cluster separation.\n\n\n\n\nAdditional Metrics\n\nDavies-Bouldin index (DB)\nMaulik-Bandyopadhyay index (MB)\nSaitta score function (SF)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#the-clustering-challenge",
    "href": "applied-chapter12.html#the-clustering-challenge",
    "title": "Clustering",
    "section": "The Clustering Challenge",
    "text": "The Clustering Challenge\n\nResults depend on choices made (distance metric, standardization, linkage type).\n\nNo single method is perfect for determining the number of clusters.\n\nAvoid relying on any single clustering result as absolute truth.\n\nExamine multiple clustering solutions to identify general patterns.\n\nSimulation studies show clustering performance depends on cluster separation, noise, and structure.\n\nIssues like sub-clusters or overlapping groups can lead to incorrect \\(k\\) estimates or misleading assignments.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#heatmaps",
    "href": "applied-chapter12.html#heatmaps",
    "title": "Clustering",
    "section": "Heatmaps",
    "text": "Heatmaps\n\nMotivation\n\nDendrograms and cluster assignments do not show the underlying data.\n\nHeatmaps provide a visual check and help interpret clusters.\n\n\n\nHeatmap Details\n\nPlot of raw or standardized numeric variables\n\nCan represent:\n\nData matrices of observations\n\nSummary matrices (e.g., means, correlations)\n\n\nGrid of rectangles colored by numeric values\n\n\n\nHeatmaps with Clustering\n\nHierarchical clustering can be applied to rows and/or columns.\nHelps investigate patterns among:\n\nObservations (rows)\nVariables (columns)",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "applied-chapter12.html#clustering-in-practice",
    "href": "applied-chapter12.html#clustering-in-practice",
    "title": "Clustering",
    "section": "Clustering in Practice",
    "text": "Clustering in Practice\n\nGoal: identify groups that are closer together (distance or correlation).\nDefinition of ‘observation’ varies depending on context.\n\nPossible uses:\n\nClustering correlation statistics\n\nClustering variables (i.e., treating variables as the observations by transposing the data matrix).\n\nVariables often cluster based on strong positive correlations.",
    "crumbs": [
      "Applied Statistics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html",
    "href": "appendix-r-code.html",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "",
    "text": "Quick Navigation:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#data-import-summary",
    "href": "appendix-r-code.html#data-import-summary",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "1. Data Import & Summary Statistics",
    "text": "1. Data Import & Summary Statistics\n\n1A. Import and Explore the Dataset\n\n\nCode\n# Load the tidyverse (for read, dplyr, ggplot2, etc.)\nlibrary(tidyverse)\n\n# Import the dataset using a file dialog\ndataset = read.csv(file.choose(), header = TRUE, stringsAsFactors = TRUE)\n\n# Explore the structure and contents\nstr(dataset)\nhead(dataset)\n\n\n\n\n1B. Summary Statistics by Group\n\n\nCode\n# Summarize response by levels of the explanatory variable\ndataset %&gt;% group_by(explanatory) %&gt;% \n  summarize(n = n(), mean = mean(response), sd = sd(response))",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#viz-assumption-checks",
    "href": "appendix-r-code.html#viz-assumption-checks",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "2. Visualization & Assumption Checks",
    "text": "2. Visualization & Assumption Checks\n\n2A. Base R Plots (One Variable or Group Subsets)\n\n\nCode\n# Visual checks for distributional assumptions (normality and spread)\n\n# Histogram, QQ plot, and Boxplot of a numerical variable\nhist(dataset$numericalColumn, main = \"Histogram\", xlab = \"Numerical Variable\")\nqqnorm(dataset$numericalColumn, main = \"QQ Plot\")\nqqline(dataset$numericalColumn)\nboxplot(dataset$numericalColumn, horizontal = TRUE, main = \"Boxplot\")\n\n\n\n\n2B. Base R: Comparison Between Groups\n\n\nCode\n# Compare two levels of a grouping variable using base R\n\n# Replace level1 and level2 with actual factor levels\nlevel1 = \"A\"\nlevel2 = \"B\"\n\n# Layout: 2 rows, 3 columns\npar(mfrow = c(2, 3))\n\n# Level 1 plots\nhist(subset(dataset, explanatory == level1)$response, main = paste(\"Histogram -\", level1), xlab = \"Response\")\nboxplot(subset(dataset, explanatory == level1)$response, main = paste(\"Boxplot -\", level1), horizontal = TRUE)\nqqnorm(subset(dataset, explanatory == level1)$response, main = paste(\"QQ Plot -\", level1))\nqqline(subset(dataset, explanatory == level1)$response)\n\n# Level 2 plots\nhist(subset(dataset, explanatory == level2)$response, main = paste(\"Histogram -\", level2), xlab = \"Response\")\nboxplot(subset(dataset, explanatory == level2)$response, main = paste(\"Boxplot -\", level2), horizontal = TRUE)\nqqnorm(subset(dataset, explanatory == level2)$response, main = paste(\"QQ Plot -\", level2))\nqqline(subset(dataset, explanatory == level2)$response)\n\n\n\n\n2C. ggplot2 + patchwork for Grouped Assumption Plots\n\n\nCode\n# Import ggplot if tidyverse not already imported\n# library(ggplot2) # in tidyverse package\n\n# Create histograms, QQ plots, and boxplots by group\n# Use facet_wrap() to show each level of explanatory separately\n\n# Patchwork allows multi-plot arrangement\nlibrary(patchwork)\n\n# Histogram faceted by group\nhist = dataset %&gt;% \n  ggplot(aes(x = response)) +\n  geom_histogram(bins = 15) + \n  # facet_wrap(~explanatory, scales = \"free_y\") +\n  facet_wrap(~explanatory) +\n  ggtitle(\"Histogram of Response by Group\") +\n  theme_bw()\n\n# QQ plot per group\nqq = dataset %&gt;%\n  ggplot(aes(sample = response)) +\n  geom_qq() +\n  facet_wrap(~explanatory) +\n  ggtitle(\"QQ Plots of Response by Group\") +\n  theme_bw()\n\n# Boxplot per group\nbox = dataset %&gt;% \n  ggplot(aes(y = response, x = explanatory)) +\n  geom_boxplot() +\n  ggtitle(\"Boxplot of Response by Group\") +\n  theme_bw()\n\n# Combine plots using patchwork (arrange histogram above qqplot, next to boxplot)\n(hist / qq) | box",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#permutation-test",
    "href": "appendix-r-code.html#permutation-test",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "3. Permutation Test: Generate Permutation Distribution for Group Mean Difference",
    "text": "3. Permutation Test: Generate Permutation Distribution for Group Mean Difference\n\n\nCode\n# Step 1: Calculate the observed difference in sample means\nxbars = dataset %&gt;% group_by(explanatory) %&gt;% summarize(mean = mean(response))\nxbarGrp1minusGrp2 = xbars[2,2] - xbars[1,2] # observed difference\nxbarGrp1minusGrp2\n\n# Step 2: Build the permutation distribution under the null with this loop\n# Make sure nGrp1 and nGrp2 are defined as sample sizes of the groups\nxbarDiffHolder = numeric(10000)\n\nfor (i in 1:10000){\n  scrambledLabels = sample(dataset$explanatory, nGrp1+nGrp2); # shuffle labels\n  \n  datasetTemp = dataset\n  datasetTemp$explanatory = scrambledLabels\n  \n  xbars = datasetTemp %&gt;% group_by(explanatory) %&gt;% summarize(mean = mean(response))\n  xbarGrp1minusGrp2 = xbars[2,2] - xbars[1,2] # observed difference\n  xbarGrp1minusGrp2\n  xbarDiffHolder[i] = xbarGrp1minusGrp2$mean\n}\n\n# Step 3: Plot the permutation distribution\ndf = data.frame(xbarDiffs = xbarDiffHolder)\n\ndf %&gt;% ggplot(mapping = aes(x = xbarDiffs)) + \n  geom_histogram(bins = 25, fill = \"cornflowerblue\", linewidth = 0.1) +\n  ggtitle(\"Permutation Distribution of the Difference of Sample Means\") +\n  xlab(\"xbarGrp1 - xbarGrp2\")\n\n# Step 4: Calculate the p-value (two-tailed)\nnum_more_extreme = sum((abs(xbarDiffHolder)) &gt;= abs(xbarGrp1minusGrp2))\n\npvalue = num_more_extreme / 10000\npvalue",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#t-tests-power",
    "href": "appendix-r-code.html#t-tests-power",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "4. t-Tests and Power Analysis",
    "text": "4. t-Tests and Power Analysis\n\n4A. Basic \\(t\\)-Tests\n\n\nCode\n# Critical value for a two-sided t-test (95% CI)\n# Use df = n - 1 (one-sample) or df = n1 + n2 - 2 (two-sample)\nqt(0.975, df - 2)\n\n# One-sample t-test\nt.test(x=dataset, mu = underTheNull, conf.int = \"TRUE\", alternative = \"two.sided\")\n\n# Paired t-test (one-sample, df-1, within-subject comparison)\nt.test(x = dataset$explantoryGrp2, y = dataset$explantoryGrp1, paired = TRUE) # this is probably easiest\n# Or alternative formula syntax\nt.test(response ~ explanatory, data = dataset, paired = TRUE) # alternative = \"two-sided\", mu = 0, conf.level = 0.95, var.equal(doesn't apply, one-sample)\n# Check the order of the treatment groups\nlevels(dataset$explanatory)\n\n# Two-sample t-test with equal variance\nresults = t.test(response ~ explanatory, data = dataset, var.equal = TRUE, alternative = \"two.sided\")\nresults\n\n# Two-sample t-test with unequal variance (Welch's)\nresults = t.test(response ~ explanatory, data = dataset, var.equal = FALSE, alternative = \"two.sided\")\nresults\n\n# Extract test statistic and degrees of freedom\nresults = t.test(response ~ explanatory, data = dataset)\ntstat = results$statistic\ndf = results$parameter\n\n# Manual two-sided p-value\npt(abs(tstat), df,lower.tail = FALSE) * 2\n\n\n\n\n4B. Power Analysis\n\n\nCode\n# Compute the power of a t-test (one-sample or two-sample)\npower.t.test(n = nPerGrp, delta = effectSize, sd = sd, sig.level = alpha, power = NULL, type = \"one.sample\", alternative = \"one.sided\")\n# or \"two.sample\", can also just leave power (or unknown variable off)\n\n# Find sample size to get 80% power (leave n blank)\npower.t.test(n = , delta = effectSize, power = .8, sd = s, sig.level = .05, type = \"one.sample\", alternative = \"one.sided\")\n\n# Unequal sample sizes using Cohen’s d (if you have different sample sizes in each of two samples)\nlibrary(pwr)\npwr.t2n.test(n1 = n1, n2 = n2, d = effectSize/stdev, sig.level = 0.05, alternative = \"two.sided\") # alternative = \"greater\"\n\n# Power calculation with unequal standard deviations (Welch’s)\npower.welch.t.test(n = n, delta = effectSize, power = , sd1 = s1, sd2 = s2, alternative = \"two-sided\")\n\n\n\n\n4C. Power Curve\n\n\nCode\n# Create power curve across a range of sample sizes\nsamplesizes = seq(nlower, nhigher, by = 1)\npowerholder = numeric(length(samplesizes))\n\nfor(i in 1:length(samplesizes))\n{\n  powerholder[i] = power.t.test(n = samplesizes[i], delta = effectSize, sd = s, sig.level = .05, type = \"one.sample\", alternative = \"one.sided\")$power\n}\n\n# Combine into a data frame\npowerdf = data.frame(samplesizes, powerholder)\n\n# Plot power vs sample size to create the power curve\npowerdf %&gt;% ggplot(aes(x = samplesizes, y = powerholder)) +\n  geom_line(color = \"blue3\", linewidth = 1.5) +\n  ggtitle(\"Power Curve\") +\n  ylab(\"Power\") +\n  xlab(\"Sample Sizes\") +\n  ylim(0.75, 1.0) +\n  theme_bw()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#anova-extra-ss",
    "href": "appendix-r-code.html#anova-extra-ss",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "5. One-Way ANOVA and Extra Sum of Squares",
    "text": "5. One-Way ANOVA and Extra Sum of Squares\n\n5A. One-Way ANOVA\n\n\nCode\n# Fit a one-way ANOVA model (make sure groups is a factor variable)\nfit = aov(response ~ groups, data = dataset)\nsummary(fit)\n\n# Find the critical value for the F-distribution (one-sided test)\n# critical_value = qf(alpha, dfn, dfd, lower.tail = FALSE)\nqf(0.05, dfn, dfd, lower.tail = FALSE)\n\n\n\n\n5B. Extra Sum of Squares Test\n\n\nCode\n# Compare a full model to a reduced model using extra sum of squares\n# Example: comparing CTRL and D and testing whether they can be combined\n\n# To confirm at lease two groups are different: one-way ANOVA first (make sure groups is a factor variable)\nfit = aov(response ~ groups, data = dataset)\nsummary(fit)\n\n# Full model: all group levels (e.g., CTRL, A, B, C, D, E)\nfit_full = aov(response ~ explanatory, data = dataset)\nsum_fit_full = summary(fit_full)\nsum_fit_full\n# Extract the degrees of freedom for the error\ndfd = sum_fit_full[[1]][\"Residuals\", \"Df\"]\n# Extract the sum of squares for the error\nssFull = sum_fit_full[[1]][\"Residuals\", \"Sum Sq\"]\n\n# Reduced model: O, O, A, B, C, E (combine CTRL & D)\nfit_reduce = aov(response ~ explanatoryReduced, data = dataset)\nsum_fit_reduce = summary(fit_reduce)\nsum_fit_reduce\n# Extract the degrees of freedom for the error\ndfTotal = sum_fit_reduce[[1]][\"Residuals\", \"Df\"]\n# Extract the sum of squares for the error\nssRed = sum_fit_reduce[[1]][\"Residuals\", \"Sum Sq\"]\n\n#F-Statistic and P-Value for Model Comparison\n# BYOA table calculations (F-test to compare reduced vs full model)\nalpha = 0.05\ndfn = dfTotal - dfd                     # numerator df\nssModel = ssRed - ssFull                # difference in SS\nmse = ssFull / dfd                      # mean square error\nmsModel = ssModel / dfn                 # mean square model\nfstat = msModel / mse                   # F-statistic\nfstat\n\n# P-value (one-tailed test)\np_value = pf(fstat, dfn, dfd, lower.tail = FALSE)\np_value\n\n# Critical F value\ncritical_value = qf(alpha, dfn, dfd, lower.tail = FALSE)\ncritical_value\n\n# Print results\ncat(\"alpha:\", alpha, \"\\n\")\ncat(\"dfTotal (reduced):\", dfTotal, \"\\n\")\ncat(\"dfd (full):\", dfd, \"\\n\")\ncat(\"dfn:\", dfn, \"\\n\")\ncat(\"Sum of Squares for Reduced Model:\", ssRed, \"\\n\")\ncat(\"Sum of Squares for Error (Full):\", ssFull, \"\\n\")\ncat(\"Sum of Squares for Model (SS explained):\", ssModel, \"\\n\")\ncat(\"Mean Square Error:\", mse, \"\\n\")\ncat(\"Mean Square Model (MS explained):\", msModel, \"\\n\")\ncat(\"Critical Value:\", critical_value, \"\\n\")\ncat(\"F-Statistic:\", fstat, \"\\n\")\ncat(\"p-Value F-test:\", p_value, \"\\n\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#multiple-comparisons",
    "href": "appendix-r-code.html#multiple-comparisons",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "6. Multiple Comparisons",
    "text": "6. Multiple Comparisons\n\n6A. Tukey HSD using multcomp (Tukey-Kramer Adjustment)\n\n\nCode\n# Use the multcomp package to conduct pairwise comparisons with the Tukey-Kramer multiple comparison correction\nlibrary(multcomp)\n\n# Fit must come from an ANOVA or linear model with a factor variable\ngfit = glht(fit, linfct = mcp(groups = \"Tukey\")) # 'groups' is your factor variable\n\n# See pairwise comparisons and adjusted p-values\nsummary(gfit)\n\n# Extract confidence intervals for all pairwise comparisons\nconfint_gfit = confint(gfit)\nconfint_gfit\n\n\n\n\n6B. Tukey HSD using agricolae\n\n\nCode\n# Tukey HSD using the agricolae package\n# Different way to extract half_width\nlibrary(agricolae)\n\n# Run Tukey HSD test (grouping variable must be specified)\ntukey_half = HSD.test(fit, 'groups') # put groups variable in\n\n# Extract minimum significant difference (half-width of CI)\ntukey_half$statistics$MSD\n\n\n\n\n6C. Tukey HSD using Base R\n\n\nCode\n# Alternative method using base R function TukeyHSD()\n# Note: This function works correctly on models fit with aov()\n# (I haven't used this before, so confirm it is the correct function.)\n\n# Provides adjusted CIs and p-values\ntukey_result = TukeyHSD(fit)\ntukey_result",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#contrasts",
    "href": "appendix-r-code.html#contrasts",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "7. Contrasts",
    "text": "7. Contrasts\n\nPerform planned contrasts only after a significant ANOVA result. Use adjusted p-values when doing multiple, unplanned comparisons.\n\n\n7A. Setup and Specifying Contrasts\n\n\nCode\n# Contrast of the average of the mean of 2 groups of 2\n\n# Load emmeans for estimated marginal means (least squares means) and contrasts\nlibrary(emmeans)\n\n# Check the order of factor levels - for assigning contrast coefficients\nunique(dataset$groups)\n\n# Fit linear model with categorical explanatory variable\nfit = lm(response ~ groups, data = dataset)\n\n# Get least-squares means for each group\nleastsquare = emmeans(fit, \"groups\") # put groups variable in\n\n# Define contrast weights: compare (A+B) vs (C+D)\ncontrasts = list(Grp1and2vsGrp3and4 = c(.5, .5, -.5, -.5))\n\n\n\n\n7B. Run Contrast Tests\n\n\nCode\n# With adjustment\ncontrastResultsCorr = contrast(leastsquare, contrasts, adjust = \"sidak\") # slightly less conservative than bonferroni\nsum_contrastResultsCorr = summary(contrastResultsCorr)\nsum_contrastResultsCorr\n# Confidence interval\nconfint(contrastResultsCorr, level = 0.95) \n\n# Without adjustment\ncontrastResults = contrast(leastsquare, contrasts) # no adjustment\nsum_contrastResults = summary(contrastResults)\nsum_contrastResults\n# Confidence interval\nconfint(contrastResults, level = 0.95) \n\n\n\n\n7C. Manual Confidence Interval from Estimate\n\n\nCode\n# Find critical value for 95% CI (df from ANOVA)\ncriticalVal = qt(0.975, df)\ncriticalVal\n\n# CI = estimate ± criticalValue*SE (estimate is the difference of means from the original t-test)\n# Estimate ± margin of error\nestimate = sum_contrastResultsCorr$estimate\nSE = sum_contrastResultsCorr$SE\n\nCI_lower = estimate - criticalVal * SE\nCI_upper = estimate + criticalVal * SE\n\nCI_lower\nCI_upper",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#nonparam-tests",
    "href": "appendix-r-code.html#nonparam-tests",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "8. Non-Parametric Tests",
    "text": "8. Non-Parametric Tests\n\n8A. Wilcoxon Rank-Sum Test (Mann-Whitney)\n\n\nCode\n# Compare two independent samples\n\n# Get the EXACT p-value (one-sided test)\nwilcox.test(response ~ explanatory, data = dataset, alternative = \"less\", exact = TRUE)\n# Get the exact matching CI (note it is not alpha, it is conf.level)\n# ‘conf.int’ option provides the HL confidence limits (like SAS)\nwilcox.test(response ~ explanatory, data = dataset, alternative = \"two.sided\", exact = TRUE, conf.level = 0.90, conf.int = TRUE)\n\n# Get the NORMAL APPROXIMATION p-value (with continuity correction)\nwilcox.test(response ~ explanatory, data = dataset, alternative = \"less\", exact = FALSE, correct = TRUE)\n# Get the normal approximation matching CI\nwilcox.test(response ~ explanatory, data = dataset, alternative = \"two.sided\", exact = FALSE, correct = TRUE, conf.level = 0.90, conf.int = TRUE)\n\n\n\n\n8B. Signed-Rank Test (Paired Samples)\n\n\nCode\n# Get critical Z value for one-sided test\ncritVal = qnorm(0.95)\ncritVal\n\n# Run the paired test\nsignedRank = wilcox.test(dataset$before, dataset$after, paired = TRUE, alternative = \"greater\", exact = FALSE, correct = TRUE)\nsignedRank\n\n# Get the 90% matching CI\nsignedRankCI = wilcox.test(dataset$before, dataset$after, paired = TRUE,alternative = \"two.sided\", exact = FALSE, correct = TRUE, conf.level = 0.90, conf.int = TRUE)\nsignedRankCI\n\n\n\n\n8C. Manual Z-Approximation for Signed-Rank\n\n\nCode\n# This is extra code for the by-hand calculations.\n# Extract the test statistic (S)\nS = signedRank$statistic\nS\n\n# Calculate sample size (n)\nn = length(dataset$before)\nn\n\n# Calculate the expected value (mean) of S under the null hypothesis\nmean_S = n * (n + 1) / 4\nmean_S\n\n# Calculate the standard deviation of S under the null hypothesis\nsd_S = sqrt(n * (n + 1) * (2 * n + 1) / 24)\nsd_S\n\n# Calculate the Z-statistic with continuity correction\nCC = ifelse(S &gt; meanS, -0.5, 0.5)\nCC\nZ = (S + CC - mean_S) / sd_S\nZ\n\n# Get the p-value for a one-tailed test (upper tail)\np_value_one_tailed = 1 - pnorm(Z)\np_value_one_tailed",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#correlation-simple-regression",
    "href": "appendix-r-code.html#correlation-simple-regression",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "9. Correlation and Simple Linear Regression",
    "text": "9. Correlation and Simple Linear Regression\n\n9A. Pearson Correlation\n\n\nCode\n# Create a sample dataset\ndataset = data.frame(response = c(1, 2, 3, 4, 5), \n                     explanatory = c(1, 2, 3, 4, 5))\n\n# Make a scatter plot to visualize the relationship\nplot(dataset$explanatory, dataset$response, \n     xlab = \"Explanatory\", ylab = \"Response\", \n     main = \"Scatterplot of Response vs. Explanatory\", pch = 15)\n\n# Alternatively, without making a dataframe\nplot(response, explanatory)\n\n# Get Pearson correlation coefficient (three ways)\ncor(dataset) # returns correlation matrix\ncor(dataset$response, dataset$explanatory)\ncor(x = explanatory, y = response)\n\n# Hypothesis test for correlation (t-test)\n# Get r, the test statistic, p-value, and confidence interval\ncor.test(dataset$response, dataset$explanatory)\n\n# Get the critical value\nqt(0.975,n-2) # df = n-2, for 95% two-sided test\n\n\n\n\n9B. Simple Linear Regression: Fitting and Diagnostics\n\n\nCode\n# Fit the linear model\nfit = lm(response ~ explanatory, data = dataset)\nsummary(fit)  # Shows coefficients, t-tests, R-squared\n\n# Plot data and fitted line (base R)\nplot(dataset$explanatory, dataset$response, \n     xlab = \"Explanatory\", ylab = \"Response\", \n     main = \"Linear Regression\", pch = 15)\nlines(dataset$explanatory, fit$fitted.values, col = \"blue\")\n\n# ANOVA for regression model\nanova(fit)\n\n\n# --- Residual Diagnostics ---\n\n# Default residual plots (base R)\nplot(fit)  # Residuals vs Fitted, QQ Plot, etc.\n\n# Save residuals and fitted values for custom plots\ndataset$residuals = residuals(fit)\ndataset$fittedVals = fitted(fit)\n\n# ggplot2 residuals vs fitted plot\ndataset %&gt;% \n  ggplot(aes(x = fittedVals, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ggtitle(\"Residuals vs Fitted Values\") +\n  theme_bw()\n\n# QQ plot of residuals (base R)\nresiduals = residuals(fit)\nqqnorm(residuals)\nqqline(residuals, col = \"black\")\n\n\n\n\n9C. Confidence & Prediction Intervals\n\n\nCode\n# --- Confidence Intervals for Coefficients ---\n\nfit = lm(response ~ explanatory, data = dataset)\n\n# Show summary\nsummary(fit)\n\n# Confidence interval for the parameter estimates (intercept and slope)\nconfint(fit)\n\n# CI for just the slope\nconfint(fit, \"explanatory\")\n\n# CI at different confidence level\nconfint(fit, level = 0.99) # to change alpha\n\n\n# --- Confidence & Prediction for New Observations ---\n\n# Add a new data point\nnew_data = data.frame(response = NA, explanatory = 2.5)\n# or\nnew_data = data.frame(explanatory = 2.5)\n\n# Confidence interval (mean response at x)\n# 95% CI estimating the mean value of y expected at value of x\npredictionCI = predict(fit, newdata = new_data, interval = \"confidence\")\npredictionCI\n\n# Prediction interval (individual response at x)\n# 95% CI estimating the individual value of y expected at value of x, more error\npredictionPI = predict(fit, newdata = new_data, interval = \"prediction\")\npredictionPI\n\n\n# --- Plot CI and PI Around Fitted Line ---\n\n# Predicted values + intervals (for the full dataset)\npredictions = predict(fit, interval = \"confidence\", level = 0.95, se.fit = TRUE)\nprediction_intervals = predict(fit, interval = \"prediction\", level = 0.95)\n\n# Add intervals to original data for plotting\nmovies = movies %&gt;%\n  mutate(fit = predictions$fit,\n         lwr_conf = predictions$fit[, \"lwr\"],\n         upr_conf = predictions$fit[, \"upr\"],\n         lwr_pred = prediction_intervals[, \"lwr\"],\n         upr_pred = prediction_intervals[, \"upr\"])\n\n# Plot fitted line with CI and PI ribbons\nggplot(data, aes(x = explanatory, y = response)) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  geom_ribbon(aes(ymin = lwr_conf, ymax = upr_conf), alpha = 0.5, fill = \"lightblue\") +\n  geom_line(aes(y = lwr_pred), linetype = \"dashed\", color = \"black\") +\n  geom_line(aes(y = upr_pred), linetype = \"dashed\", color = \"black\") +\n  geom_hline(yintercept = 210, color = \"darkred\") +\n  geom_point() +\n  labs(title = \"Regression Line with 95% Confidence and Prediction Intervals\",\n       x = \"Explanatory\", y = \"Response\") +\n  theme_bw()\n\n\n# --- Calibration Intervals (Reverse Prediction) ---\n\n# For estimating values of x from given y\nlibrary(investr)\n\n# Calibration interval for the mean budget (Estimate x for a given y0, mean response)\ncalibrate(fit,y0 = 210, interval = \"Wald\", mean.response = TRUE, limit = FALSE)\n\n# Calibration interval for a single movie budget (estimate x for an individual response)\ncalibrate(fit,y0 = 210, interval = \"Wald\", mean.response = FALSE, limit = FALSE)\n\n\n# --- R-squared Interpretation ---\n# R-squared = measure of the proportion of variation in the response that is accounted for by the explanatory variable\n\n# Get the summary of the model\nsummary_fit = summary(fit)\n\n# Extract R-squared\nR_squared = summary_fit$r.squared\n\n# Interpretation\ncat(\"The R-squared value is\", R_squared, \"\\n\")\ncat(\"This means that\", round(R_squared * 100, 2), \"% of the variability in Response is explained by Explanatory.\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#residual-analysis",
    "href": "appendix-r-code.html#residual-analysis",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "10. Residual Analysis",
    "text": "10. Residual Analysis\n\n10A. Fit Model and Add Residuals\n\n\nCode\n# Fit a linear model\nfit = lm(response ~ explanatory, data = dataset)\n\n# Log transform the data if needed\ndataset = dataset %&gt;% mutate(\n  log_explanatory = log(explanatory),\n  log_response = log(response)\n)\n\n# Add residuals and fitted values to the dataframe\ndataset$residuals = residuals(fit)\ndataset$fittedVals = fitted(fit)\n\n# Studentized residuals (internal)\nlibrary(car)  # for rstudent(), studentized residuals\ndataset$studentized_residuals = rstudent(fit) \n\n# Another way to get studentized residuals (studentized deleted residuals)\n# External: excluding the data point being tested. More accurate for identifying outliers or influential points, because the data point doesn't bias its own standard error.\nlibrary(MASS)\n# Calculate studentized residuals (external studentized: ti=ei/σhati*sqrt(1−hii))\ndataset$StudentizedResiduals = rstudent(fit)\n\n\n\n\n10B. Residual Plots\n\n\nCode\n# Base R: full residual diagnostics (residuals vs fitted, QQ, sqrt(std residuals), Cook’s)\nplot(fit)\n\n# ggplot: residuals vs fitted scatterplot\nggplot(data = dataset, aes(x = fittedVals, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"blue\") +\n  labs(x = \"Fitted Values\", y = \"Residuals\", title = \"Scatterplot of Residuals\") + \n  theme_bw()\n\n\n\n\n10C. Normality Checks for Residuals\n\n\nCode\n# Base R: QQ plot of residuals\nqqnorm(residuals(fit), main = \"QQ Plot of Residuals\")\nqqline(residuals(fit), col = \"blue\")\n\n# or using residuals saved to dataset\nqqnorm(dataset$residuals, main = \"QQ Plot of Residuals\")\nqqline(dataset$residuals, col = \"blue\")\n\n# car package: enhanced QQ plot\nlibrary(car)\nqqPlot(dataset$residuals, main = \"QQ Plot (car::qqPlot)\")\n\n# ggplot2 QQ plot\nggplot(dataset, aes(sample = residuals)) +\n  stat_qq() +\n  stat_qq_line(col = \"blue\") +\n  labs(title = \"QQ Plot of Residuals\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme_bw()\n\n\n\n\n10D. Histogram of Residuals\n\n\nCode\n# ggplot2 histogram with normal curve\nggplot(data = dataset, aes(x = residuals)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 15, fill = \"lightblue\", color = \"gray30\") +\n  stat_function(fun = dnorm, args = list(mean = mean(dataset$residuals), sd = sd(dataset$residuals)), color = \"blue\") +\n  labs(x = \"Residuals\", y = \"Density\", title = \"Histogram of Residuals with Normal Curve\") + \n  theme_bw()\n\n# Base R version with overlaid normal curve\nhist(residuals(fit), breaks = 15, probability = TRUE, col = \"lightblue\", border = \"gray30\", main = \"Histogram of Residuals with Normal Curve\", xlab = \"Residuals\")\ncurve(dnorm(x, mean = mean(residuals(fit)), sd = sd(residuals(fit))), col = \"blue\", lwd = 2, add = TRUE)\n\n\n\n\n10E. Regression Line with Confidence & Prediction Intervals\n\n\nCode\n# Base R scatterplot and regression line\nplot(dataset$explanatory, dataset$response, \n     xlab = \"Explanatory\", ylab = \"Response\", \n     main = \"Linear Regression of Response & Explanatory\", pch = 16)\n# Add the regression line\nabline(fit, col = \"blue\", lwd = 2)\n\n# ggplot2 scatterplot + regression line\nggplot(dataset, aes(x = explanatory, y = response)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(x = \"Explanatory\", y = \"Response\", \n       title = \"Linear Regression of Response & Explanatory\") +\n  theme_bw()\n\n\n# --- Optional: Add Intervals and Highlighted Points ---\n\n# Identify specific data points to highlight\ndataToHighlight = dataset %&gt;%\n  filter(columnName == \"Value\") %&gt;% \n  select(\"col1\", \"col2\", \"col3\")\ndataToHighlight\n\n# Build prediction data frame (example using log-log model structure)\nnew_data = data.frame(logGDP = InfantVGDP_clean$logGDP, logInfantMort = InfantVGDP_clean$logInfantMort)\n\n# Generate confidence and prediction intervals using log-log model fit\nconfInt = predict(fitLogLog, newdata = new_data, interval = \"confidence\")\npredInt = predict(fitLogLog, newdata = new_data, interval = \"predict\")\n\n# Add intervals to new_data\nnew_data$fit = confInt[, \"fit\"]\nnew_data$lwr_conf = confInt[, \"lwr\"]\nnew_data$upr_conf = confInt[, \"upr\"]\nnew_data$lwr_pred = predInt[, \"lwr\"]\nnew_data$upr_pred = predInt[, \"upr\"]\n\n# Plot CI and PI with highlighted point(s)\nggplot(dataset, aes(x = explanatory, y = response)) +\n  # Prediction interval ribbon (widest)\n  geom_ribbon(data = new_data, aes(ymin = lwr_pred, ymax = upr_pred), alpha = 0.3, fill = \"gray70\") +\n  # Confidence interval ribbon (narrower)\n  geom_ribbon(data = new_data, aes(ymin = lwr_conf, ymax = upr_conf), alpha = 0.6, fill = \"lightblue\") +\n  # Raw data points\n  geom_point() +\n  # Highlighted point(s)\n  geom_point(data = dataToHighlight, aes(x = explanatory, y = response), color = \"red3\", size = 4, stroke = 1.25, shape = 21) +\n  # Regression line\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(x = \"Explanatory\", y = \"Response\", \n       title = \"Linear Regression with 95% CI, PI, and Highlighted Points\") +\n  theme_bw()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#log-log-models",
    "href": "appendix-r-code.html#log-log-models",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "11. Log-Log Models & Back-Transformation",
    "text": "11. Log-Log Models & Back-Transformation\n\n11A. Back-Transform the Slope and Interpret\n\n\nCode\n# Extract slope from log-log model\nintercept = coef(fitLogLog)[1]\nslope = coef(fitLogLog)[2]\n\n# Get confidence interval for slope\nconf_intervals = confint(fit)\nslope_conf_lower = conf_intervals[\"log_explanatory\", 1]\nslope_conf_upper = conf_intervals[\"log_explanatory\", 2]\n\n# Back-transform the slope and its CI\nback_transformed_slope = 2^slope\nback_transformed_conf_lower = 2^slope_conf_lower\nback_transformed_conf_upper = 2^slope_conf_upper\n\n# Percentage change interpretation\npercentage_change = (1 - back_transformed_slope) * 100\npercentage_change_conf_lower = (1 - back_transformed_conf_lower) * 100\npercentage_change_conf_upper = (1 - back_transformed_conf_upper) * 100\n\n# Display results\ncat(\"Slope:\", slope, \"\\n\")\ncat(\"Back-transformed Slope (2^b1):\", back_transformed_slope, \"\\n\")\ncat(\"Percentage Change:\", percentage_change, \"%\\n\")\ncat(\"CI for Slope: (\", slope_conf_lower, \", \", slope_conf_upper, \")\\n\")\ncat(\"Back-transformed CI for Slope: (\", back_transformed_conf_lower, \", \", back_transformed_conf_upper, \")\\n\")\ncat(\"Percentage Change CI: (\", percentage_change_conf_lower, \"%, \", percentage_change_conf_upper, \"%)\\n\")\n\n\n\n\n11B. Back-Transform the Intercept\n\n\nCode\n# Get CI for intercept\nintercept_conf_lower = conf_intervals[\"(Intercept)\", 1]\nintercept_conf_upper = conf_intervals[\"(Intercept)\", 2]\n\n# Back-transform using exponential\nback_transformed_intercept = exp(intercept)\nback_transformed_intercept_conf_lower = exp(intercept_conf_lower)\nback_transformed_intercept_conf_upper = exp(intercept_conf_upper)\n\n# Display results\ncat(\"Intercept:\", intercept, \"\\n\")\ncat(\"Back-transformed Intercept (exp(b0)):\", back_transformed_intercept, \"\\n\")\ncat(\"CI for Intercept: (\", intercept_conf_lower, \", \", intercept_conf_upper, \")\\n\")\ncat(\"Back-transformed CI: (\", back_transformed_intercept_conf_lower, \", \", back_transformed_intercept_conf_upper, \")\\n\\n\")\n\n\n\n\n11C. Compare Predicted vs Observed Values\n\n\nCode\n# Estimate log(Y) and then back-transform to original scale\nest_log_response = intercept + slope * dataset$explanatory\nest_response = exp(est_log_response)\n\n# Display for comparison\ncat(\"Estimated log(response):\", est_log_response, \"\\n\")\ncat(\"Estimated response:\", est_response, \"\\n\")\ncat(\"Actual log(response):\", dataset$obs_log_response, \"\\n\")\ncat(\"Actual response:\", dataset$obs_response, \"\\n\")\n\n\n\n\n11D. Lack of Fit Test\n\n\nCode\n# Extra sum of squares F-test (lack of fit)\n# H0: Linear regression fits well (no lack of fit)\n# HA: Separate means model fits better (LRM is lacking fit)\n\n# Critical value\nqf(1-alpha, dfn, dfd)\n\n# Find p-value for f-distribution\npf(fstat, dfn, dfd, lower.tail = FALSE)\n\n# Template interpretation:\n# \"There is [overwhelming/sufficient/insufficient] evidence at the alpha = 0.05 level of significance to suggest the linear regression model has a lack of fit compared to the separate-means model (p- value = XYZ from an extra-sum-of-squares F-test).\"",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#multiple-regression",
    "href": "appendix-r-code.html#multiple-regression",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "12. Multiple Linear Regression (MLR)",
    "text": "12. Multiple Linear Regression (MLR)\n\n12A. MLR with Only Numeric Predictors (Same Slopes)\n\n\nCode\n# Subset to just the numerical columns of interest\nsubset_scores = scores[ , c(\"science\", \"math\", \"read\")]\n\n# Visualize relationships: matrix scatterplot\nplot(subset_scores,\n     main = \"Matrix Scatterplot\", \n     pch = 19, # point character\n     col = \"darkblue\")\n\n# Use GGally:GGpairs to make a matrix scatterplot\nlibrary(GGally)\nggpairs(subset_scores,\n        title = \"Matrix Scatterplot\")\n\n# Fit the multiple linear regression model\nfit = lm(science ~ math + read, data = scores)\nsummary(fit)      # Includes t-tests, R², etc.\nconfint(fit)      # Confidence intervals for coefficients\n\n# Plot residuals to check assumptions (normality, linearity, equal variance)\nplot(fit)\n\n\n\n\n12B. MLR with Categorical Predictors (Indicator Variables, Same Slopes)\n\n\nCode\n# Visualize response by numeric and categorical explanatory variables\ndataset %&gt;% \n  ggplot(aes(x = explanatoryNum, y = response, color = explanatoryCat)) +\n  geom_point() +\n  labs(title = \"Response vs Numeric and Categorical Predictors\",\n       x = \"Explanatory (Numeric)\",\n       y = \"Response\",\n       color = \"Explanatory (Category)\") +\n  theme_bw()\n\n# Convert category variable to a factor if needed\nscores$ses = as.factor(scores$ses)\n\n# Fit the model, set reference level if necessary\nfit = lm(response ~ explanatoryNum + relevel(explanatoryCat, ref = \"3\"), data = dataset)\nsummary(fit)\nconfint(fit)\n\n# View the covariance matrix (advanced)\nvcov(fit)\n\n# Check assumptions with residual plots\nplot(fit)\n\n\n\n\n12C. MLR with Interaction (Different Slopes per Group)\n\n\nCode\n# Include interaction term between numeric and categorical variables\nfit = lm(response ~ explanatoryNum * relevel(factor(explanatoryCat), ref = \"3\"), data = dataset) # can convert to factor here instead\nsummary(fit)\nconfint(fit)\n\n# Equivalent fully expanded form\nfit2 = lm(response ~ \n            explanatoryNum + \n            relevel(factor(explanatoryCat), ref = \"3\") + \n            explanatoryNum*relevel(factor(explanatoryCat), ref = \"3\"), \n          data = dataset)\nsummary(fit2)\nconfint(fit2)\n\n# Plot residuals to check model fit\nplot(fit)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-r-code.html#variable-selection",
    "href": "appendix-r-code.html#variable-selection",
    "title": "Appendix A: R Code Examples for Statistical Foundations",
    "section": "13. Variable Selection",
    "text": "13. Variable Selection\n\n13A. Stepwise Selection by \\(p\\)-Value\n\n\nCode\n# Use olsrr for stepwise selection based on p-values (significance level)\n# install.packages(\"olsrr\")\nlibrary(olsrr)\n\n# Full model with all predictors\nfit = lm(response ~ ., data = dataset)\n\n# Forward selection (add variables one at a time)\na = ols_step_forward_p(fit, p_val = 0.15, details = TRUE)\n\n# Backward elimination (start with full model, remove variables)\nb = ols_step_backward_p(fit, p_val = 0.15, details = TRUE) # bigger p-remove, more variables in the model; smaller p-remove, fewer\n\n# Stepwise (both directions)\nc = ols_step_both_p(fit, p_enter = 0.15, p_remove = 0.15, details = TRUE)\n\n\n\n\n13B. Forward Selection by AIC\n\n\nCode\n# Refit full model\nfit = lm(response ~ ., data = dataset)\n\n# Forward selection using AIC as criterion\nd = ols_step_forward_aic(fit, details = TRUE)\n\n\n\n\n13C. Cross-Validation and Interaction Terms\n\n\nCode\n# Fit model with all two-way interactions\nfit = lm(response ~ .^2, data = dataset)\n\n# Use caret for model tuning with LOOCV\nlibrary(caret)\n\n# Define training control method\ntrain_control = trainControl(method=\"LOOCV\")\n\n# Train linear model with specified predictors\nmodel = train(response ~ explanatory1 + explanatory2 + explanatory3 + explanatory4 + explanatory5, data = dataset, trControl = train_control, method = \"lm\")\n\n# Output cross-validated model results\nmodel",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Appendix A: R Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html",
    "href": "appendix-sas-code.html",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "",
    "text": "Quick Navigation:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html#data-import-summary",
    "href": "appendix-sas-code.html#data-import-summary",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "1. Data Import and Summary Statistics",
    "text": "1. Data Import and Summary Statistics\n\nMost SAS procedures require your dataset to be sorted by group for grouped analysis or plotting. You can either import data from a file or create a dataset manually for small examples.\n\n\n1A. Import or Create a Dataset\n\n\nCode\n\n/* OPTION 1: Import a CSV from your SAS Studio home directory */\n\n%web_drop_table(WORK.mydata);\n\nfilename reffile '/home/your-username/path-to-your-data.csv';\n\nproc import datafile=reffile\n    dbms=csv\n    out=WORK.mydata\n    replace;\n    getnames=yes;\nrun;\n\n/* View structure and preview the dataset */\nproc contents data=WORK.mydata;\nrun;\n\n%web_open_table(WORK.mydata);\n    \n    \n/* OPTION 2: Manually create a small dataset column-wise (each row = one observation) */\n\ndata mydata;\n    input variable1 variable2;\n    datalines;\n    1 A\n    2 B\n    3 C\n    4 D\n    5 E\n    ;\nrun;\n\nproc print data = mydata;\nrun;\n\n\n/* OPTION 3: Create a row-wise dataset (data entered horizontally using @@) */\ndata mydata;\n    input variable @@;\n    datalines;\n    1 2 3 4 5 6\n    ;\nrun;\n    \nproc print data = mydata;\nrun;\n    \n\n\n\n\n1B. Summary View and Sorting\n\n\nCode\n\n/* Preview the data */\nproc print data = dataset;\nrun;\n\n/* Sort data by explanatory variable (required for some procedures) */\nproc sort data = dataset;\n    by explanatory;\nrun;\n\n\n\n\n\n1C. Summary Statistics\n\n\nCode\n\n/* Summary stats: n, mean, sd, min, max */\nproc means data = dataset;\n    var response;\nrun;\n\n/* Medians by group */\nproc means data = dataset median;\n    class explanatory;\n    var response;\nrun;\n\n/* Manual p-value from t-statistic (two-sided) */\ndata mypval;\n    pv = 2 * (1 - cdf(\"t\", tstat, df));\nrun;\nproc print data = mypval;\nrun;\n\n\n\n\n\n1D. Log Transformation and Filtering\n\n\nCode\n\n/* Create a log-transformed version of response */\ndata ldataset;\n    set dataset;\n    logResponse = log(response);\nrun;\n\n/* Remove outlier (e.g., filter response &lt; 1200) */\ndata datasetNoOutlier;\n    set dataset;\n    where response &lt; 1200;\nrun;\n\n/* Scatter plot without outlier */\nproc sgplot data = datasetNoOutlier;\n    scatter x = explanatory y = response;\nrun;\n\n\n\n\n\n1E. Categorical Recoding and Viewing Subsets\n\n\nCode\n\n/* Create ordinal version of categorical variable */\n\ndata educMultiGrp;\n    set educMultiGrp;\n    if Educ = '&lt;12' then EO = 1;\n    else if Educ = '12' then EO = 2;\n    else if Educ = '13-15' then EO = 3;\n    else if Educ = '16' then EO = 4;\n    else if Educ = '&gt;16' then EO = 5;\nrun;\n\n/* Create a column to collapse levels */\ndata educMultiGrp;\n    set educMultiGrp;\n    if Educ = \"&lt;12\" then Combine = \"&lt;12\";\n    else if Educ = \"12\" then Combine = \"12\";\n    else if Educ = \"13-15\" then Combine = \"13-15\";\n    else if Educ in (\"16\", \"&gt;16\") then Combine = \"16+\";\nrun;\n\n/* View first 50 rows of a dataset */\nproc print data = lIncome5Grps(obs=50);\nrun;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html#viz-assumption-checks",
    "href": "appendix-sas-code.html#viz-assumption-checks",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "2. Visualization and Assumption Checks",
    "text": "2. Visualization and Assumption Checks\n\nUse proc univariate, proc sgplot, and proc ttest to visualize distributions and assess assumptions of normality and variance.\nMany visualizations require sorting your dataset by the grouping variable.\n\n\n2A. Univariate Plots (No Grouping)\n\n\nCode\n\n/* Histogram and QQ plot (ungrouped) */\nproc univariate data = dataset;\n    var response;\n    histogram response;\n    qqplot response;\nrun;\n\n/* Boxplot (ungrouped) */\nproc sgplot data = dataset;\n    vbox response;\nrun;\n\n/* Scatterplot of response vs explanatory */\nproc sgplot data = dataset;\n    scatter x = explanatory y = response;\n    * title \"Scatterplot of \";\nrun;\n\n/* Turn off the title */\ntitle;\nrun;\n\n\n\n\n\n2B. Histograms and QQ Plots by Group\n\n\nCode\n\n/* Sort by grouping variable (required for BY statement) */\nproc sort data = dataset;\n    by explanatory;\nrun;\nproc print data = dataset;\nrun;\n\n/* Histograms grouped by explanatory */\nproc univariate data = dataset;\n    by explanatory;\n    histogram response;\nrun;\n\n/* QQ plots grouped by explanatory */\nproc univariate data = dataset;\n    * title \"QQ Plot by \";\n    by explanatory;\n    qqplot response / normal(mu=est sigma=est);\nrun;\n\n\nproc sgplot data = dataset;\n    * title \"Histogram by \";\n    by explanatory;\n    histogram response / transparency=0.5;\n    density response; * with a normal distribution curve;\nrun;\n\n\n\n\n\n2C. Boxplots and Density Plots by Group\n\n\nCode\n\n/* Boxplot by group */\nproc sgplot data=dataset;\n    * title \"Boxplot of\";\n    vbox response / category=explanatory;\nrun;\n\n/* Histogram with overlaid normal curve by group */\nproc sgplot data = dataset;\n    by explanatory;\n    histogram response / transparency = 0.5;\n    density response;  /* Normal curve */\nrun;\n\n\n\n\n\n2D. Visualizations from proc ttest\n\n\nCode\n\n/* `proc ttest` also generates histogram, QQ plot, and boxplot (grouped) */\nproc ttest data = dataset;\n    class explanatory;\n    var response;\nrun;\n\n\n\n\n\n2E. Custom Histogram with Set Bin Width\n\n\nCode\n\n/* Adjust histogram range and bin width */\nproc univariate data = dataset noprint;\n    by explanatory;\n    histogram response / endpoints = 0 to 1000 by 50 normal; /* Adjust as needed */\n    inset n mean std / pos = ne;\nrun;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html#permutation-test",
    "href": "appendix-sas-code.html#permutation-test",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "3. Permutation Test",
    "text": "3. Permutation Test\n\n3A. Observed Difference in Means\n\n\nCode\n\n/* Use proc ttest to compute observed difference between groups */\nproc ttest data = dataset;\n    class group;\n    var response;\nrun;\n\n\n\n\n\n3B. Generate Permutations with proc iml\n\n\nCode\n\n/* Shuffle response values across group labels using IML */\n\n/* Borrowed code from internet: randomizes observations and creates a matrix with one row per permutation */\n\n/* NOTE: Replace `dataset`, `group` and `response` with your actual variable names */\n\nproc iml;\n    use dataset;\n    read all var {group response} into x;  /* Make sure to specify class variable first */\n    \n      nPerms = 10000;                 /* Number of permutations */\n    permuted = t(ranperm(x[,2], nPerms));  /* Create permuted response matrix */\n    combined = x[,1] || permuted;   /* Combine original group column with each permuted column */\n\n    create newds from combined;\n    append from combined;\nquit;\n\n\n\n\n\n3C. Build Permutation Distribution\n\n\nCode\n\n/* Use proc ttest to calculate mean differences for each permutation */\n\nods output off;\nods exclude all;   /* Suppress output */\n  \n/* The ods output line below is optional if you want to capture confidence intervals */\n/* ods output conflimits=diff; */\n\nproc ttest data = newds plots = none;\n    class col1;\n    var col2 - col10001;\nrun;\n\nods output on;\nods exclude none;\n\n\n\n\n\n3D. Plot Permutation Histogram and Calculate p-value\n\n\nCode\n                                                                    \n/* Plot the distribution of permuted mean differences (Pooled method only) */\nproc univariate data = diff;\n    where method = \"Pooled\";\n    var mean;\n    histogram mean;\nrun;\n\n/* Count number of permuted differences as or more extreme than observed */\n/* Replace `obsDiff` with your observed test statistic from 3A */\n/* Adjust for one-tailed or two-tailed test accordingly */\ndata numdiffs;\n    set diff;\n    where method = \"Pooled\";\n    if abs(mean) &gt;= abs(obsDiff);\nrun;\n\n/* Print matching rows (just for visual check) */\nproc print data = numdiffs;\n    where method = \"Pooled\";\nrun;    \n\n/* Manual Step:\n   - Check the number of rows in `numdiffs` (from the log or output)\n   - Divide that by the total number of permutations (e.g., 10000)\n   - This gives your p-value */",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html#t-tests-power",
    "href": "appendix-sas-code.html#t-tests-power",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "4. t-Tests and Power Analysis",
    "text": "4. t-Tests and Power Analysis\n\nThis section includes basic t-test syntax, F-tests for equal variances, and power analysis using proc power.\n\n\n4A. Basic t-Tests and Critical Values\n\n\nCode\n\n/* Compute critical t-value for two-sided test at α = 0.05 */\ndata criticalvalue;\n    critval = quantile(\"T\", 0.975, df);\nrun;\nproc print data = criticalvalue;\nrun;\n\n/* One-sample t-test (H0: mean = muUnderNull) */\n/* * proc ttest outputs histogram, boxplot and qqplot */\nproc ttest data = dataset h0 = muUnderNull sides = 2 alpha = 0.05;\n    var response;\nrun;\n\n/* Paired t-test (H0: mean difference = 0, computed as Group2 - Group1) */\nproc ttest data = dataset;\n    paired explanatory2*explanatory1;\nrun;\n\n/* Two-sample t-test (equal variance and Welch's handled together) */\n/* Pooled uses pooled st.dev. and Satterthwaite uses Welch's */\nproc ttest data = dataset h0 = 0 sides = 2 alpha = 0.05;\n    class explanatory;\n    var response;\nrun;\n\n\n\n\n\n4B. Equality of Variances Tests\n\n\nCode\n\n/* F-test for equality of variances is run automatically as part of proc ttest */\n/* The F-test (default in proc ttest) assumes normal distributions. It's useful as secondary evidence for variance equality if visuals are inconclusive. Null: population variances are equal. */\n\n/* Brown-Forsythe test does not require normality assumptions */\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / hovtest = bf;  /* Brown-Forsythe test */\nrun;  \n\n\n\n\n\n4C. Power Analysis (One- and Two-Sample)\n\n\nCode\n\n/* Power for one-sample t-test */\nproc power;\n    onesamplemeans\n        sides = 1\n        alpha = 0.05\n        nullmean = 0\n        mean = xbar\n        stddev = s\n        ntotal = n\n        power = .;\nrun;\n\n/* Power for two-sample t-test */\nproc power;\n    twosamplemeans\n        sides = 1\n        alpha = 0.05\n        meandiff = effectSize\n        stddev = s\n        npergroup = n1\n        power = .; /* specify a dot or omit this line to solve for the unknown parameter */\n\nrun;\n\n/* Example: specify total sample size and mean for each using `nullmean and meandiff` */\nproc power;\n    twosamplemeans\n        sides = 1\n        alpha = 0.05\n        nulldiff = 0\n        meandiff = 3\n        stddev = 4.5\n        ntotal = 47;  /* e.g. 24 in group 1, 23 in group 2 */\nrun;\n\n\n\n\n\n4D. Power Curve Plots\n\n\nCode\n\n/* Power vs. sample size (one-sample) */\nods graphics on;\n\nproc power;\n    onesamplemeans\n        sides = 1\n        alpha = 0.05\n        nullmean = 0\n        ntotal = 60 80\n        mean = 0.07\n        stddev = 0.2\n        power = .;\n    plot x = n min = 60 max = 80;\nrun;\n\nods graphics off;\n\n/* Power vs. effect size (two-sample) */\nods graphics on;\n\nproc power;\n    twosamplemeans\n        sides = 1\n        alpha = 0.05\n        nulldiff = 0\n        meandiff = 3 to 5 by 0.1\n        ntotal = 47\n        stddev = 4.5\n        power = .;\n    plot x = effect min = 3 max = 5;\nrun;\n\nods graphics off;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html#anova-extra-ss",
    "href": "appendix-sas-code.html#anova-extra-ss",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "5. ANOVA and Extra Sum of Squares",
    "text": "5. ANOVA and Extra Sum of Squares\n\nThis section includes one-way ANOVA, multiple comparisons, linear contrasts, and extra sum of squares tests for nested or grouped comparisons.\n\n\n5A. One-Way ANOVA with Variance Checks\n\n\nCode\n\n/* One-way ANOVA: for EMM and SMM (full), tests if any group means differ (i.e. any pair has difference of means) */\n/* Brown-Forsythe test is included to check equal variance assumption (does not require normality) */\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / hovtest = bf;  /* Brown-Forsythe test (homogeneity of variance) */\nrun;\n\n/* Manually compute F critical value */\ndata critical_value;\n    set calculations;\n    critical_value = finv(1 - alpha, dfn, dfd);  /* right-tailed (1-alpha) */\nrun;\n\n\n\n\n\n5B. Multiple Comparisons (Tukey + Pairwise Tests)\n\n\nCode\n\n/* Example: pairwise t-tests with Tukey adjustment and confidence intervals */\nproc glm data = playersHeight;\n    class Sport;\n    model Height = Sport;\n    means Sport / hovtest = bf;\n    lsmeans Sport / pdiff adjust = tukey cl;\nrun;\n\n/* Optionally show differences both directions (A–B and B–A) */\nproc glm data = playersHeight;\n    class Sport;\n    model Height = Sport;\n    means Sport / hovtest = bf tukey cldiff;\nrun;\n\n/* The cl option provides CIs for the means, \n while cldiff provides CIs for the differences between means. */\n\n\n\n\n\n5C. Linear Contrasts\n\n\nCode\n\n/* Test linear contrasts using CONTRAST and ESTIMATE statements.\n   CONTRAST is used to test hypotheses (produces sum of squares and F-statistic).\n   ESTIMATE provides a point estimate and standard error (used for CIs).\n   These allow comparisons of one group mean to a linear combination of others. */\n\n/* Note: SAS orders categorical levels alphabetically by default.\n   To retain original data order (e.g., to match planned contrast coefficients),\n   use 'order = data' in PROC GLM:\n   proc glm data = Handicap order = data; */  \n  \nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory;\n   \n    /* Grp1 vs sum or average of others (assuming 5 groups) */\n    contrast 'Grp1 vs Sum of Other 4 Groups' explanatory 4 -1 -1 -1 -1;\n    estimate 'Grp1 vs Sum of Other 4 Groups' explanatory 4 -1 -1 -1 -1;\n    estimate 'Grp1 vs Avg of Other 4 Groups' explanatory 4 -1 -1 -1 -1 / divisor = 4;\n\n    /* Grp1 vs Grp2 */\n    contrast 'Grp1 vs Grp2' explanatory 1 -1 0 0 0;\n    estimate 'Estimate Grp1 vs Grp2' explanatory 1 -1 0 0 0;\nrun;  \n   \n\n/* Manually compute the critical t-value for a 95% confidence interval.\n   This is used in: point estimate ± (multiplier × standard error)\n*/\ndata quantile;\n    quant = quantile(\"t\", 0.975, df);  * where df = n − number of groups;\nrun;\nproc print data = quantile;\nrun;   \n\n\n\n\n\n5D. Bonferroni Adjustment for Selected Comparisons\n\n\nCode\n\n/* Simultaneous CIs for selected differences (e.g. μ2–μ3, μ2–μ5, μ3–μ5) */\n/* k=3 (comparing 3 pairs) */\n\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory;\n    lsmeans explanatory / pdiff cl;\n\n    /* ESTIMATE used to extract estimate and SEs for CI construction */\n    estimate 'mu2 - mu3' explanatory 0 1 -1 0 0;\n    estimate 'mu2 - mu5' explanatory 0 1 0 0 -1;\n    estimate 'mu3 - mu5' explanatory 0 0 1 0 -1;\nrun;\n\n\n/* to get 95% CI for the difference in averages of above\npoint estimate +- multiplier * standard error */\n/* Bonferroni multiplier: 1 - α/(2k) for two-tailed test with k comparisons; df=n-totalgrps */\ndata quantile;\n    quant = quantile(\"t\", 1 - 0.05/6, df);  /* adjust denominator for # comparisons and tails */\nrun;\nproc print data = quantile;\nrun;\n\n\n\n\n\n5E. Summary: Choosing a Multiple Comparison Adjustment\n\nWhen choosing a multiple comparison correction:\n\nWere the comparisons planned before looking at the data or unplanned? If planned, no need to make multiple comparison correction. Can use LSD.\nAre the groups being compared to a single control or reference group? If so, use Dunnett’s.\nAre the groups normally distributed with equal standard deviation? If so, use Tukey-Kramer.\nIf we are doing some or all unplanned pairwise comparisons, without a reference/control group and without the assumption of normality or equal variance, use Bonferroni.\n\n\n\n\nCode\n\n/* Commands for various multiple comparison methods */\n\n* LSD (Least Significant Difference, use when comparisons are planned) with CI half-width;\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / lsd;  * means returns the half-width;\n    lsmeans explanatory / pdiff cl;\nrun;\n\n* Dunnett (compare each group to a control/reference group);\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / dunnett('Control');\n    lsmeans explanatory / pdiff = control('Control') adjust = dunnett cl;\nrun;  \n/* Calculate the half-widths: HalfWidth = (UpperCL - LowerCL) / 2 */\n\n* Tukey-Kramer (assumes normality + equal variance; unplanned all-pairwise) with CI half-width;\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / tukey;\n    lsmeans explanatory / pdiff adjust = tukey cl;\nrun;\n\n* Bonferroni (safest if assumptions are not met or comparisons are partially unplanned) with CI half-width;\nproc glm data = dataset order = data;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / bon;\n    lsmeans explanatory / pdiff adjust = bon cl;\nrun;\n\n* View all options together (Jaren’s code);\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / lsd tukey dunnett bon scheffe;\nrun;\n\n\n\n\n\n5F. Extra Sum of Squares F-Test\n\n\nCode\n\n/* Conduct an anova (explanatory=group) */\nproc glm data = data;\nclass explanatory;\nmodel response = explanatory;\nrun;\n\n/* Extra-sum-of-squares */\n/* Compare full and reduced models using BYOA-style calculations */\ndata calculations;\n    alpha = 0.05;  \n    dftotal = 2580;\n    dfd = 2579;\n    dfn = dftotal - dfd;\n    ssred = 2234.10;\n    ssfull = 2232.12;\n    ssmodel = ssred - ssfull;\n    mse = ssfull / dfd;\n    msmodel = ssmodel / dfn;\n    fstat = msmodel / mse;\nrun;\n\n/* Compute critical F and p-value for the above hypothesis test. */\ndata critical_value;\n    set calculations;\n    critical_value = finv(1 - alpha, dfn, dfd); *1-alpha for right-tail;\nrun;\n\ndata f_test;\n    set critical_value;\n    p_value = 1 - probf(fstat, dfn, dfd); *1-probf for right-tail;\nrun;\nproc print data = f_test;\nrun;\n\n/* another way to get p-value */\ndata quantile;\n    myquant = 1-CDF('F', fstat, dfn, dfd)\nrun;\nproc print data = quantile;\nrun;\n\n/* You can check against a contrast if relevant */\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory;\n    contrast 'Contrast Grp1 vs. Grp2' explanatory 0 0 0 1 -1 0;\n    estimate 'Estimate Grp1 vs. Grp2' explanatory 0 0 0 1 -1 0;\nrun;\n\n\n\n\n\n5G. Welch’s ANOVA (Unequal Variances)\n\n\nCode\n\n/* Appropriate for normal distributions with unequal variance */\nproc glm data = dataset;\n    class explanatory;\n    model response = explanatory;\n    means explanatory / welch;\nrun;\n\n/* Critical F-value calculation */\ndata critical_value;\n    critical_value = finv(1-0.05, 4, 706.2); /* 1-alpha for right-tail */\nrun;\nproc print data = critical_value;\nrun;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html#nonparam-tests",
    "href": "appendix-sas-code.html#nonparam-tests",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "6. Non-Parametric Tests",
    "text": "6. Non-Parametric Tests\n\nNote: The permutation test (Section 3) is also a non-parametric method.\n\n\n6A. Wilcoxon Rank-Sum Test (Mann–Whitney U Test)\n\nUsed for inference on the median of two independent samples.\n\n\n\nCode\n\n/* Exact Wilcoxon Rank-Sum Test (with Hodges-Lehmann CI) */\n/* Best for small samples. Computationally intensive for large samples. */\nproc npar1way data = dataset wilcoxon;\n    class explanatory;\n    var response;\n    exact HL wilcoxon;\nrun;\n\n/* For one-sided alpha = 0.05, specify alpha = 0.10 to match CI to one-sided test */\n/* HL = Hodges-Lehmann estimator of the median difference for confidence intervals. */\nproc npar1way data = dataset wilcoxon alpha = 0.10;\n    class explanatory;\n    var response;\n    exact HL wilcoxon;\nrun;\n\n\n/* Rank-Sum Test: NORMAL Approximation\nthe larger the sample size, you can use the z approximation\nthe smaller, the more conservative, choose the t approximation */\n/* Normal approximation for large samples */\n/* z-approximation used when sample size is large. Choose t-approximation for smaller samples or to be more conservative. */\nproc npar1way data = dataset wilcoxon;\n    class explanatory;\n    var response;\nrun;\n\n/* CI using normal approximation with HL estimator (asymptotic CI version) */\n/* To get the CI to match a one-sided alpha = 0.5, set alpha = 0.1 */\nproc npar1way data = dataset wilcoxon HL alpha = 0.10;\n    class explanatory;\n    var response;\nrun;\n\n/* One-sided critical value from normal (Z) distribution */\ndata critval;\n    cv = quantile(\"normal\", 0.95); alpha for left, 1-alpha for right;\nrun;\nproc print data = critval;\nrun;\n\n\n\n\n\n6B. Wilcoxon Signed-Rank Test (Paired Samples)\n\n\nCode\n\n/* Create difference column for paired data */\ndata dataset;\n    set dataset;\n    diff = before - after;\nrun;\n\nproc print data = dataset;\nrun;\n\n/* Run Wilcoxon Signed-Rank test using diff */\n/* This seems to give an incorrect output for S, but close for 2-sided p-value */\nproc univariate data = dataset;\n    var diff;\nrun;\n\n/* Critical value for normal approximation (one-sided z-distribution) */\ndata critval;\n    cv = quantile(\"normal\", 0.95);  /* alpha for left, 1-alpha for right */\nrun;\nproc print data = critval;\nrun;\n\n* This is extra code for the by hand calculations;\n* Calculate the absolute differences and rank them;\ndata ranked;\n    set dataset;\n    abs_diff = abs(diff);\nrun;\n\n\n\n\n\n6C. Manual Z-Approximation for Signed-Rank\n\n\nCode\n\n/* Step 1: Calculate absolute differences */\ndata ranked;\n    set dataset;\n    abs_diff = abs(diff);\nrun;\n\n/* Step 2: Rank the absolute differences */\nproc rank data=ranked out=ranked ties=mean;\n    var abs_diff;\n    ranks rank_abs_diff;\nrun;\n\n/* Step 3: Identify and sum ranks for positive differences */\ndata stats;\n    set ranked;\n    if diff &gt; 0 then S = rank_abs_diff;\n    else S = 0;\nrun;\n\nproc means data = stats sum noprint;\n    var S;\n    output out=sums sum(S)=sum_S n=n_obs;\nrun;\n\n/* Step 4: Calculate expected mean, standard deviation, and Z-statistic */\ndata final;\n    set sums;\n    mean_S = n_obs * (n_obs + 1) / 4;\n    sd_S = sqrt(n_obs * (n_obs + 1) * (2 * n_obs + 1) / 24);\n    Z_statistic = (sum_S - 0.5 - mean_S) / sd_S;\nrun;\n\nproc print data = final;\n    var sum_S mean_S sd_S Z_statistic;\nrun;\n\n/* Step 5: Compute p-value for one-sided test */\ndata pvalue;\n    set final; /* not sure if this line is needed */\n    pv = 1 - probnorm(Z_statistic);\nrun;\n\nproc print data = pvalue;\nrun;\n\n\n\n\n\n6D. Kruskal–Wallis Test (For Inference on the Median of 3+ Groups)\n\n\nCode\n\n/* Appropriate when normality or equal variance assumptions are violated,\n   or when sample sizes are small (CLT not reliable). \n   Works by ranking all data and running ANOVA on the ranks.\n   If following up with group comparisons, use rank-sum tests. */\n/* Test statistic: χ² (chi-square). For very small n, request exact p-values with the EXACT option \n   (avoids large-sample χ² approximation).*/\nproc npar1way data = dataset wilcoxon;\n    class explanatory;\n    var response;\nrun;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html#correlation-simple-regression",
    "href": "appendix-sas-code.html#correlation-simple-regression",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "7. Correlation and Simple Regression",
    "text": "7. Correlation and Simple Regression\n\nThis section includes Pearson correlation, simple linear regression, and options for confidence and prediction intervals.\n\n\n7A. Pearson Correlation\n\n\nCode\n\n/* Pearson's R Correlation Coefficient */\n\n/* Scatterplot of response vs. explanatory */\nproc sgscatter data = dataset;\n    plot response * explanatory / markerattrs = (symbol = circlefilled);\n    title \"Scatterplot: Response vs. Explanatory\";\nrun;\n\n/* T-Critical value (two-sided t-test) */\ndata criticalvalue;\n    critval = quantile(\"T\", 0.975, df = n - 2);\nrun;\nproc print data = criticalvalue;\nrun;\n\n/* Correlation coefficient and p-value */\nproc corr data = dataset;\n    var response explanatory; /* not sure if this line is needed */\nrun;\n\n\n\n\n\n7B. Simple Linear Regression: Coefficients and Fit\n\n\nCode\n\n/* Linear regression: parameter estimates and summary stats */\nproc reg data = dataset;\n    model response = explanatory;\nrun;\n\n/* Optional: set alpha to change significance level and CI width (e.g., 99%) */\nproc reg data = dataset alpha = 0.01;\n    model response = explanatory / clb;  /* clb = confidence limits for betas */\nrun;\n\n/* Alternate method to get the parameter estimate table using proc glm */\nproc glm data = dataset;\n    model response = explanatory / solution;  /* shows estimate table */\nrun;\n\n/* Add confidence intervals for coefficients (alternative way) */\nproc glm data = dataset alpha = 0.01;\n    model response = explanatory / solution clparm;\nrun;\n\n\n\n\n\n7C. Confidence and Prediction Intervals for New Observations\n\n\nCode\n\n/* Example dataset with missing response values for prediction */\n/* Add new data */\ndata dataset;\n    input explanatory response;\n    datalines;\n    62 65\n    90 64\n    50 48\n    35 57\n    200 601\n    100 146\n    90 47\n    95 .\n    200 .\n    ;\nrun;\n\n/* CI for mean response (CLM = confidence limits for mean) */\nproc reg data = dataset;\n    model response = explanatory / clm;\nrun;\n\n/* PI for individual response (CLI = confidence limits for individual) */\nproc reg data = dataset;\n    model response = explanatory / cli;\nrun;    \n\n/* Optionally using proc glm */\nproc glm data = dataset;\n    model response = explanatory / solution clm;  /* confidence interval for mean */\nrun;\n\nproc glm data = dataset;\n    model response = explanatory / solution cli;  /* prediction interval for individual */\nrun;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix-sas-code.html#residual-analysis",
    "href": "appendix-sas-code.html#residual-analysis",
    "title": "Appendix B: SAS Code Examples for Statistical Foundations",
    "section": "8. Residual Analysis",
    "text": "8. Residual Analysis\n\nThis section focuses on residual diagnostics to evaluate model assumptions such as linearity, homoscedasticity, and outliers.\n\n\n8A. Residual Plots and Diagnostics\n\nSAS automatically produces residual plots (and other diagnostics) with proc reg if ODS graphics are enabled.\n\n\n\nCode\n\nods graphics on;\n\nproc reg data = dataset;\n    model response = explanatory;\nrun;\n\nods graphics off;\n\n/* If you need customized residual plots (e.g. residuals vs. predicted), use proc sgplot after outputting residuals: */\n\n/* Save residuals and predicted values */\nproc reg data = dataset;\n    model response = explanatory;\n    output out = diagnostics r = residual p = predicted;\nrun;\n\n/* Residuals vs. Fitted Values */\nproc sgplot data = diagnostics;\n    scatter x = predicted y = residual;\n    refline 0 / axis = y;\nrun;\n\n/* Residuals vs. Explanatory Variable */\nproc sgplot data = diagnostics;\n    scatter x = explanatory y = residual;\n    refline 0 / axis = y;\nrun;\n\n\n\n\n\n8B. Studentized Residuals\n\nStudentized residuals help detect outliers by standardizing residuals using their estimated standard errors.\n\n\n\nCode\n\n/* Use PROC REG to compute studentized residuals */\nproc reg data = dataset;\n    model response = explanatory;\n    output out = diagnostics\n        rstudent = studentized_resid  /* Studentized residuals */\n        h = leverage;                 /* Leverage values (optional) */\nrun;\n\nproc print data = diagnostics;\n    var response explanatory studentized_resid leverage;\nrun;\n\n/* Optional: plot studentized residuals */\nproc sgplot data = diagnostics;\n    scatter x = explanatory y = studentized_resid;\n    refline 0 / axis = y;\nrun;\n\n\n\n\n\n8C. Influence Diagnostics\n\nInfluence diagnostics help identify observations that have an unusually large effect on the model. These include leverage, Cook’s distance, and DFFITS.\n\n\n\nCode\n\n/* Influence statistics from PROC REG */\nods graphics on;\n\nproc reg data = dataset;\n    model response = explanatory;\n    output out = influence_out\n        rstudent = studentized_resid\n        cookd = cooks_d\n        dffits = dffits_val\n        h = leverage;\nrun;\n\nods graphics off;\n\nproc print data = influence_out;\n    var response explanatory studentized_resid cooks_d dffits_val leverage;\nrun;\n\n/* Visualize Cook’s Distance for all observations */\nproc sgplot data = influence_out;\n    scatter x = _N_ y = cooks_d;\n    refline 4 / axis = y;  /* Optional threshold line (e.g. rule of thumb for large values) */\nrun;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Appendix B: SAS Code Examples for Statistical Foundations</span>"
    ]
  },
  {
    "objectID": "appendix_hypothesis_test_flowchart.html",
    "href": "appendix_hypothesis_test_flowchart.html",
    "title": "Appendix C: Hypothesis Test Flowchart",
    "section": "",
    "text": "Hypothesis Test Selection\nUse the following flowcharts to help guide your choice of hypothesis test based on study design, sample size, and assumptions. These decision tools support the logic discussed across several chapters in this book.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Appendix C: Hypothesis Test Flowchart</span>"
    ]
  },
  {
    "objectID": "appendix_hypothesis_test_flowchart.html#hypothesis-test-selection",
    "href": "appendix_hypothesis_test_flowchart.html#hypothesis-test-selection",
    "title": "Appendix C: Hypothesis Test Flowchart",
    "section": "",
    "text": "Which flowchart should you use?\nClick the option that matches your study design.\n\n\n\n\n\nflowchart TD\n    A[\"&lt;b&gt;What kind of data&lt;br/&gt; do you have?&lt;/b&gt;\"]\n\n    B[\"&lt;u&gt;One sample&lt;/u&gt;\"]\n    C[\"&lt;u&gt;Paired samples&lt;/u&gt;\"]\n    D[\"&lt;u&gt;Two independent groups&lt;/u&gt;\"]\n    E[\"&lt;u&gt;Three or more groups&lt;/u&gt;\"]\n\n    A --&gt; B\n    A --&gt; C\n    A --&gt; D\n    A --&gt; E\n\n    %% Click targets\n    click B href \"#one-sample-test-selection\" \"Jump to One-Sample flowchart\"\n    click C href \"#paired-sample-test-selection\" \"Jump to Paired-Sample flowchart\"\n    click D href \"#two-independent-samples-test-selection\" \"Jump to Two-Sample flowchart\"\n    click E href \"#more-than-two-groups\" \"Jump to ANOVA flowchart\"\n\n    %% Styling for all clickable nodes\n    classDef decision fill:#f0f0f0,stroke:#666,color:#000;\n    classDef link fill:#e6f0fa,stroke:#336699,color:#003366,font-weight:bold;\n\n    class A decision;\n    class B,C,D,E link;\n\n    %% Increase font size for central question\n    style A font-size:18px,font-weight:bold;\n\n\n\n\n\n\n\n\n\nOne-Sample Test Selection\n\n\n\n\n\n\nNote\n\n\n\nAre you comparing a single sample to a fixed or known value?\n\nIf the sample is approximately normal → use a one-sample t-test\nIf not normal but large sample size → use a one-sample t-test (CLT)\nIf not normal and small sample size:\n\nTry a transformation\n\nIf still non-normal → use Wilcoxon or Sign Test\n\n\n\n\n\n\n\n\n\nflowchart TD\n    A[\"One sample&lt;br/&gt;(single group)\"] --&gt; B[\"Compare to&lt;br/&gt;fixed value\"]\n    B --&gt; C[\"Check distribution\"]\n    C --&gt; D[\"Normal&lt;br/&gt;→ one-sample t-test\"]\n    C --&gt; E[\"Not normal, large n&lt;br/&gt;→ t-test (CLT)\"]\n    C --&gt; F[\"Not normal,&lt;br/&gt;small n\"]\n    F --&gt; G[\"Try transformation\"]\n    G --&gt; H[\"Still non-normal&lt;br/&gt;→ Wilcoxon / Sign Test\"]\n\n    class C,F,G decision;\n    class D,E param;\n    class H nonparam;\n\n    classDef param fill:#e6f0fa,stroke:#336699,color:#000;\n    classDef nonparam fill:#fff3e0,stroke:#cc6600,color:#000;\n    classDef decision fill:#f0f0f0,stroke:#666,color:#000;\n\n\n\n\n\n\n\n\n\nPaired-Sample Test Selection\n\n\n\n\n\n\nNote\n\n\n\nAre you comparing before-and-after measurements on the same units?\n\nIf differences are approximately normal → use a paired t-test\nIf not normal but sample size is large → use a paired t-test (CLT)\nIf not normal and small sample size → use a Wilcoxon Signed Rank Test\n\n\n\n\n\n\n\n\nflowchart TD\n    A[\"Paired samples&lt;br/&gt;(same units)\"] --&gt; B[\"Check distribution&lt;br/&gt;of differences\"]\n    B --&gt; C[\"Normal&lt;br/&gt;→ paired t-test\"]\n    B --&gt; D[\"Not normal, large n&lt;br/&gt;→ paired t-test (CLT)\"]\n    B --&gt; E[\"Not normal, small n&lt;br/&gt;→ Wilcoxon Signed Rank\"]\n\n    class B decision;\n    class C,D param;\n    class E nonparam;\n\n    classDef param fill:#e6f0fa,stroke:#336699,color:#000;\n    classDef nonparam fill:#fff3e0,stroke:#cc6600,color:#000;\n    classDef decision fill:#f0f0f0,stroke:#666,color:#000;\n\n\n\n\n\n\n\n\n\nTwo Independent Samples Test Selection\n\n\n\n\n\n\nNote\n\n\n\nAre you comparing two independent groups?\n\nIf both groups are normal:\n\nEqual variances → use a pooled t-test\nUnequal variances → use Welch’s t-test\n\nIf not normal but sample sizes are large → Welch’s t-test (CLT)\nIf not normal and small sample size:\n\nTry a transformation\n\nIf still non-normal → use Mann-Whitney U Test\n\n\n\n\n\n\n\n\n\nflowchart TD\n    A[\"Two independent&lt;br/&gt;groups\"] --&gt; B[\"Check group&lt;br/&gt;distributions\"]\n    B --&gt; C[\"Normal, equal variances&lt;br/&gt;→ pooled t-test\"]\n    B --&gt; D[\"Normal, unequal variances&lt;br/&gt;→ Welch's t-test\"]\n    B --&gt; E[\"Not normal, large n&lt;br/&gt;→ Welch's t-test (CLT)\"]\n    B --&gt; F[\"Not normal,&lt;br/&gt;small n\"]\n    F --&gt; G[\"Try transformation\"]\n    G --&gt; H[\"Still non-normal&lt;br/&gt;→ Mann-Whitney U\"]\n\n    class B,F,G decision;\n    class C,D,E param;\n    class H nonparam;\n\n    classDef param fill:#e6f0fa,stroke:#336699,color:#000;\n    classDef nonparam fill:#fff3e0,stroke:#cc6600,color:#000;\n    classDef decision fill:#f0f0f0,stroke:#666,color:#000;\n\n\n\n\n\n\n\n\n\nMore Than Two Groups\n\n\n\n\n\n\nNote\n\n\n\nAre you comparing means across three or more independent groups?\n\nIf all groups are normal:\n\nEqual variances → use One-Way ANOVA\nUnequal variances → use Welch’s ANOVA\n\nIf not normal but large samples → Welch’s ANOVA (CLT)\nIf not normal and small samples:\n\nTry a transformation\n\nIf still non-normal → use Kruskal-Wallis Test\n\n\nIf the omnibus ANOVA is significant, use post hoc comparisons (e.g., Tukey HSD, Bonferroni, Dunnett).\n\n\n\n\n\n\n\nflowchart TD\n    A[\"Three or more&lt;br/&gt;groups\"] --&gt; B[\"Check group&lt;br/&gt;distributions\"]\n    B --&gt; C[\"Normal, equal variances&lt;br/&gt;→ One-Way ANOVA\"]\n    B --&gt; D[\"Normal, unequal variances&lt;br/&gt;→ Welch's ANOVA\"]\n    B --&gt; E[\"Not normal, large n&lt;br/&gt;→ Welch's ANOVA (CLT)\"]\n    B --&gt; F[\"Not normal,&lt;br/&gt;small n\"]\n    F --&gt; G[\"Try transformation\"]\n    G --&gt; H[\"Still non-normal&lt;br/&gt;→ Kruskal-Wallis\"]\n    C --&gt; I[\"Post hoc tests\"]\n    D --&gt; I\n    E --&gt; I\n\n    class B,F,G decision;\n    class C,D,E param;\n    class H nonparam;\n    class I posthoc;\n\n    classDef param fill:#e6f0fa,stroke:#336699,color:#000;\n    classDef nonparam fill:#fff3e0,stroke:#cc6600,color:#000;\n    classDef decision fill:#f0f0f0,stroke:#666,color:#000;\n    classDef posthoc fill:#e0f8e0,stroke:#339933,color:#000;\n\n\n\n\n\n\n\n\n\nHypothesis Testing: Step-by-Step\n\n\n\n\n\n\nHypothesis Testing: Step-by-Step\n\n\n\n\nUnderstand the study design. Is it a randomized experiment or observational?\n\nVisualize the data. Use histograms, boxplots, and Q-Q plots.\n\nSelect an appropriate test. Based on design, assumptions, and sample size.\n\nState the hypotheses. Null (\\(H_0\\)) and alternative (\\(H_a\\)), one- or two-sided.\n\nChoose a significance level. Typically \\(\\alpha = 0.05\\).\n\nSketch the reference distribution. Show critical regions.\n\nCalculate the test statistic and p-value.\n\nMake a decision. Reject or fail to reject \\(H_0\\) (never accept it).\n\nIf needed, perform post hoc testing.\n\nInterpret the result in context. Communicate clearly in applied terms.\n\n\n\n\nThe Appendix C flowcharts were adapted from a diagram by Michael Burkhardt (2015), Choosing a Hypothesis Test.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Appendix C: Hypothesis Test Flowchart</span>"
    ]
  }
]