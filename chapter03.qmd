---
title: "Chapter 3: Data Screening, Assumptions, and Transformations"
---

# Data Screening, Assumptions, and Transformations


## Experimental Design
- **Randomization**: Reduces potential bias.
- **Placebo**: Controls for confounding variables; ensures only the variable being tested differs.
- **Blinding**: Minimizes bias in experimental outcomes.


## Conditions for Null Hypothesis Significance Testing (NHST)
1. Random sampling
2. Independent observations
3. Representative of the population
4. Quantitative observations
5. Nearly normal distribution
6. Equal standard deviations for two-sample tests (homoscedasticity, meaning the distributions have the same shape).


## Paired t-Test
- Used when the assumption of independence is violated.
- Compares the difference between paired samples using a one-sample t-test.


## Tools for Checking Normality
1. **Boxplot**
   - Visualizes the five-number summary.
   - Highlights symmetry, skewness, and tail behavior.
   - Useful for side-by-side comparisons.
2. **Dotplot**
   - Displays individual data points.
   - Simple to construct and interpret.
3. **Histogram**
   - Shows data symmetry and shape.
4. **Normal Quantile (QQ) Plot**
   - Plots theoretical normal values (X-axis) against observed data (Y-axis).
   - Normal distribution aligns points along a straight line.
   - Sensitive to deviations from normality.


## Robustness
- A procedure is **robust** if its results remain valid despite minor assumption violations.
- Example: 95% confidence intervals (CIs) should capture the true parameter value 95% of the time.

### Moderate Robustness in t-Tools
- **Sample size effects**:
  - Larger samples tolerate greater deviations from normality (unless tails are excessively heavy, meaning there are many large outliers).
- **Two-sample t-tests**:
  - Problems arise with differing shapes/skewness or unequal standard deviations.
  - Worst-case scenario: Smaller sample size paired with a population of larger standard deviation. In this case, the sample may fail to accurately represent the population's variability.

## Independence
- **Definition**: Observations are independent if knowing one value provides no information about another. Independent observations must be built into the experimental design.
- **Cluster effects**: Occur in subgroup data (e.g. littermates) and require analysis with different tools or by treating each cluster as a single observation.
- **Serial effects**: Occur when measurements are taken over time.


## Outliers
- **Definition**: Observations far from the group average.
- **Effects**:
  - Long-tailed distributions often result from outliers.
  - t-statistics are sensitive to outliers.

### Dealing with Outliers
- Do not delete unless they are clear data entry or measurement errors.
- Run analyses with and without outliers and report both results.


## Resistance:
- A statistical procedure is resistant if it doesn’t change much when a small part of the data changes (e.g. the median is resistant, the mean isn’t).
- t-tools are based on means and aren’t resistant to long tails


## Log Transformation (natural log usually):
- Use if ratio of largest to smallest is greater than 10
- Consider if data is skewed (in QQ plot or other graph)
- Consider if group with larger mean has larger spread
- Will correct nonconstant variance and non-normality
- Need to back transform median and CI to the original scale.

## Other transformations are harder to back transform.
- Square root
- Inverse
- Reciprocal

## Log Transformation, in statistics implied base e:
- Proposition 1:
  - Normal distribution (mean = median)
- Proposition 2: 
  - Log is a monotonically increasing function.
  - log(median x) = median(log(x))
- Proposition 3:
  - log(a) – log(b) = log(a/b)
- Propostion 4: 
  - e^log(x) = x

## Interpretation for t-test:
- mean(log x) – mean(log y) = g
- Because normal distributed:
  - median(log x) – median(log y) = g
- log(median x) – log(median y) = g
- e^log(median x / median y) = e^g
- median x / median y = e^g
- It is estimated that the median of x is e^g times the median of y
- Software will also give you a confidence interval for g.

## Inequality of Variance
- Guidance: always use the visual evidence as primary evidence.
- F-test – null hypothesis: population variances are equal, alternative: population variance are not equal
  - Not robust to assumption of normality
- Use hypothesis tests for equality of variance cautiously.

## General Rules of Thumb
- If sample sizes are the same and sufficiently large, the t-tools are robust to violations of normality and the equality of standard deviation
- If two populations have the same standard deviations, t-test is valid with sufficient sample size.
- If two populations have the different standard deviations, but sample sizes are sufficiently large and the same, t-tools are valid.
- If standard deviations are different and sample sizes are different, the t-tools aren’t valid.

## Welch’s t-test:
- A variation of the t-test for when standard deviations are different. (Still assumes normality.)
- Standard error equals the square root of the sum of each sample’s variance divided by its corresponding sample size.
- It also adjusts the degrees of freedom to account for this uncertainty by the Satterthwaite approximation.

## Going back to non-normal distributions:
- Long-tailed distributions – CIs are wider than (1- α)%. The t-test is failing to reject too often. It is grabbing the true µ more than (1- α)% of the time, and not rejecting enough (not α% of the time).
![](images/display_3_4.png){width=4in}^[Source: Ramsey and Schafer (2012).]
- When sample sizes and standard deviations both differ, CIs are either too narrow or too wide.
![](images/display_3_5.png){width=4in}^[Source: Ramsey and Schafer (2012).]






