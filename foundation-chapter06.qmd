---
title: "Comparisons Among Several Samples"
---

## Objectives

- Explain the purpose of analysis of variance (ANOVA) for comparing means across multiple groups.
- Formulate and interpret hypotheses for ANOVA tests.
- Check model assumptions to ensure the validity of ANOVA results.
- Construct and interpret ANOVA tables using the extra sum of squares principle.
- Compare full and reduced models using $F$-tests.
- Understand and apply the Kruskal-Wallis test as a non-parametric alternative.
- Distinguish between fixed and random effects in the context of ANOVA.
- Calculate sample sizes needed to detect a specified effect size using power analysis.


## ANOVA: Analysis of Variance

- **Purpose**: Test equality of means from more than two populations by comparing variability within groups to variability between groups.
- **Assumptions**:
  - All populations have normal distributions (reasonable symmetry in samples).
  - Population standard deviations are equal (to ensure differences in means aren't confounded by differences in variability).
  - Independence within (achieved automatically with random samples) and between samples.
- **Hypotheses**:
  - $H_0$: All population means are equal.
  - $H_A$: At least one population mean differs from another.
- ANOVA is a preliminary test; if significant, it indicates that at least one mean differs. Specific pairwise differences can be explored using post-hoc tests (not covered in detail here).

### Comparing Models in ANOVA
- **Two competing models**:
  - **Equal means model (EMM)**: Assumes all groups share the same population mean (null hypothesis).
  - **Separate means model (SMM)**: Assumes each group has its own mean (alternative hypothesis).
- **Hypotheses**:
  - $H_0$: $\mu_1 = \mu_2 = \mu_3$ 
  - $H_A$: At least one pair of means differs
- A **residual** is defined as: $\text{  Residual} = \text{Observed} - \text{Predicted}$

![**Equal Means vs. Separate Means Models.** 
Comparison of two models: one assumes all groups share a single population mean (equal means model), and the other estimates a separate mean for each group (separate means model). Brackets illustrate residuals from observed values to the grand mean.](images/fch06_equal_and_separate_means_models.png){fig-title=""}

#### Equal Means Model (EMM)
- All observations are predicted using the grand mean: $\bar{X} = 13$
- Sum of squared residuals (SSR): $\text{SSR}_{\text{EMM}} = 462$

| Level | Observation 1    | Observation 2    | Observation 3    |
|-------|------------------|------------------|------------------|
| 1     | $(3 - 13)^2 = 100$ | $(5 - 13)^2 = 64$  | $(7 - 13)^2 = 36$  |
| 2     | $(10 - 13)^2 = 9$  | $(12 - 13)^2 = 1$  | $(14 - 13)^2 = 1$  |
| 3     | $(20 - 13)^2 = 49$ | $(22 - 13)^2 = 81$ | $(24 - 13)^2 = 121$ |

#### Separate Means Model (SMM)
- Each group has its own sample mean (perfect fit).
- Sum of squared residuals: $\text{SSR}_{\text{SMM}} = 24$

| Level | Observation 1    | Observation 2    | Observation 3    |
|-------|------------------|------------------|------------------|
| 1     | $(3 - 5)^2 = 4$   | $(5 - 5)^2 = 0$   | $(7 - 5)^2 = 4$   |
| 2     | $(10 - 12)^2 = 4$ | $(12 - 12)^2 = 0$ | $(14 - 12)^2 = 4$ |
| 3     | $(20 - 22)^2 = 4$ | $(22 - 22)^2 = 0$ | $(24 - 22)^2 = 4$ |

#### Notes
- A perfect fit means predicted values match the observations exactly, so residuals are zero.
- The **sum of squared residuals (SSR)** quantifies total error:
$$
\text{SSR} = \sum (\text{Observed} - \text{Predicted})^2 = \sum (\text{Residual})^2
$$

### Comparing EMM and SMM Using an $F$-Test

To formally compare the equal means model (EMM) and separate means model (SMM), we use an **$F$-test**. This test evaluates whether the extra parameters in the more complex model (SMM) explain a significantly greater portion of the total variability.

See the ANOVA table below for how these calculations break down.

#### ANOVA Table

| Source | df | SS  | MS  | F     | P       |
|--------|----|-----|-----|-------|---------|
| Model (Between / Extra) | 2  | 438 | 219 | 54.75 | 0.0001 |
| Error (Within / Full / SMM)    | 6  | 24  | 4   |       |         |
| Total (Reduced / EMM)             | 8  | 462 |     |       |         |

- **df**: Degrees of freedom
- **SS**: Sum of squares
- **MS**: Mean square = SS / df
- **F**: Ratio of explained to unexplained variability: $F$-statistic = $\frac{\text{MS}_{\text{model}}}{\text{MS}_{\text{error}}}$
- **P**: $p$-value from the $F$-distribution

#### Notes
- Degrees of freedom reflect how many means are being estimated.
- Mean square values (MS) are variances: $\text{MS} = \frac{\text{SS}}{\text{df}}$, which follows the general variance formula: $\text{var}(x) = \frac{\sum (X_i - \bar{X})^2}{n - 1}$
- The top row of the table (Between / Extra) is how much variance is explained by using separate means.
- The **mean square error (MSE)** estimates within-group variance: $\text{MSE} = 4$
- The **root mean square error (RMSE)** is:$\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{4} = 2$
- This is also our estimate of the shared population standard deviation: $\hat{\sigma} = \text{RMSE} = 2$

#### Understanding Degrees of Freedom in ANOVA
- Degrees of freedom reflect how many parameters (means) are estimated and how much data is available to estimate variability.
- In ANOVA, the total degrees of freedom are split into two parts:

| **Source**              | **Formula** | **Interpretation**                                      |
|-------------------------|-------------|----------------------------------------------------------|
| Model (Between Groups)  | $k - 1$     | Number of group means (parameters) being estimated minus 1 |
| Error (Within Groups)   | $n - k$     | Leftover variation after estimating $k$ group means      |
| Total                   | $n - 1$     | Total variation in the dataset                           |

For example, with 3 groups and 9 total observations:

- Model df = $3 - 1 = 2$
- Error df = $9 - 3 = 6$
- Total df = $9 - 1 = 8$

#### Visualizing the $F$-Test

The $F$-statistic is compared to an $F$-distribution with 2 and 6 degrees of freedom. (Every $F$-distribution has 2 degrees of freedom.)

- $F_{2,6} = 54.75$
- Critical value at $\alpha = 0.05$: $F_{2,6}^{*} \approx 5.14$
- The region to the right of 54.75 under the curve gives the $p$-value, which is very small ($p = 0.0001$), indicating strong evidence against the null model (EMM).

![**$F$-distribution.** Right-skewed $F_{2,6}$ distribution showing critical value (5.14), observed test statistic (54.75), and rejection region representing $p$-value (0.0001).](images/fch06_fdistribution.png){fig-title=""}

#### Interpretation
- The top row of the ANOVA table shows how much variability is explained by the model.
- The second row shows how much variability is left over (residual error).
- A high $F$-value means the SMM explains significantly more variability than the EMM.
- We conclude that at least one group mean differs significantly from the others.

---

![Detailed ANOVA Table Overview](images/notes_6_3.png){width=6in fig-align="left"}   
*Figure 3: Detailed breakdown of ANOVA table components.*  


## ANOVA: Six-Step Hypothesis Test

1. **Define Hypotheses**:
   - $H_0: \mu_1 = \mu_2 = \mu_3 = \dots$ (Equal means model).
   - $H_A$: At least one pair of means is different.
   - The null model assumes all observations are drawn from a single population distribution with the same mean (grand mean).
   - The alternative allows group-specific distributions with different means (separate means model).
   - Models are compared by finding the sum of squared residuals. A good fitting model will have smaller residuals (observed - predicted).
2. **Get Critical Value**:
   - From an $F$-distribution.
   - Degrees of freedom: $df_1$ (model) and $df_2$ (error).
   - Calculate quantiles in R using `qf(alpha, df1, df2)`. Use $1-\alpha$ for a R-tailed test.  
3. **Calculate $F$-Statistic** (F in SAS ANOVA table):
   - Formula:  
   $$
   F = \frac{\text{MS}_{\text{between}}}{\text{MS}_{\text{within}}} 
     = \frac{\text{Extra SS} / \text{Extra df}}{\text{MSE}} 
     = \frac{\text{Variation Explained}}{\text{Variation Left to Explain}}
  $$
   - Where:
     - $\text{MS between} = \frac{\text{extra SS}}{\text{extra df}}$
     - $\text{MS within} = \text{MSE} = \frac{\text{Error SS}}{\text{Error df}}$
4. **Determine p-value**:
   - Compare $F$-statistic to the critical value.
5. **Decision**:
   - Reject $H_0$ if $p$-value < $\alpha$; otherwise, fail to reject.
6. **Interpretation**:
   - Rejecting $H_0$ indicates evidence that at least one pair of group means is different.

::: {layout-ncol=2}
![SAS Output Table](images/notes_6_4.jpg)  
*Figure 4: SAS output showing $F$-statistic, $p$-value, and $R^2$ metrics.*  

![R-Squared and Variance Explained](images/notes_6_5.jpg)  
*Figure 5: Illustration of $R^2$, showing the proportion of total variance explained by the model.*  
:::

## SAS code for ANOVA

```{sas eval=FALSE}
* Generalized Linear Model: Extends analysis to multiple groups (e.g. ANOVA for 3+ groups);
proc glm data = dataSet;
class group;
model responseVar = groupingVar; * Fits an ANOVA;
run;
```


## R code for ANOVA

```{r eval=FALSE}
# aov = analysis of variance
# numerical response ~ factor groupings
fit = aov(responseVar ~ groupingVar, data = dataSet)
summary(fit)
```


## Key Metrics in ANOVA

### $R^2$: Coefficient of Determination
- $R^2 = \frac{\text{Variation Explained by Full Model}}{\text{Total Variation}} = \frac{\text{Extra Sum of Squares}}{\text{Total Sum of Squares}}$. 
- Represents the percentage of total variance explained by group membership.
- Example: $R^2$ of 0.75 indicates 75% of the response variation is explained by group differences.
- $R$: Pearson correlation coefficient between observed and predicted values

### RMSE: Root Mean Square Error
- $\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\text{Unexplained Variation}}$
- Quantifies the amount of unexplained variation in the model, i.e., the standard deviation of the model's residuals.

### Coefficient of Variation (CV)
$\text{CV} = \frac{\text{RMSE}}{\text{Grand Mean}} \times 100$
- Measures relative standard deviation as a percentage of the mean.


## ANOVA Assumptions and Robustness

- **Normality**:
  - Check with histograms, boxplots, and Q-Q plots.
  - ANOVA is robust to slight violations of normality, especially with large sample sizes.
- **Equal Standard Deviations**:
  - This assumption is crucial for the validity of ANOVA results.
  - ANOVA is less robust to violations of this assumption compared to $t$-tests.
  - Confidence intervals depend on this assumption being met.
  - Confidence intervals are widest when the group with the largest standard deviation also has the largest sample size.
- **Independence**:
  - Ensure independence of observations both within and between groups.  


## Welch’s ANOVA

- Still assumes normality.
- Adjusts for unequal standard deviations.
- Degrees of freedom are lowered.


## Kruskal-Wallis Test

- Non-parametric alternative for ANOVA.
- Tests medians instead of means.
- **Assumptions**:
  - Does not require normality, making it useful for non-symmetric distributions or small sample sizes.  
  - Robust to unequal variances.
- $p$-values follow a chi-square distribution.


## Power Analysis for ANOVA – SAS code

```{sas eval=FALSE}
proc power;
  onewayanova test=overall;
  groupmeans ... ;
run;
```


## Random vs. Fixed Effects

- **Random Effects**:
  - Observations are a random sample from a larger population of possible levels.
  - Levels of observations are meant to be representative of the population of things you could sample, even if you cannot sample every possible level.
  - Desired inferences are on the entire population of levels, not just the levels included in the study.
  - Variance includes:
    - Residual variance (variance of each observation from the overall mean).
    - Variance associated with random effects.
  - There is typically more error associated with random effects models.
- **Fixed Effects**:
  - Inferences are specific to the levels included in the study.
  - Levels are not intended to represent a larger population.
- **Statistical Considerations**:
  - Random effects models account for extra variability by including variance from random effects, reducing the probabilities of Type I and Type II errors.
  - Fixed effects models do not include this extra variability, which may lead to increased risk of Type I or II errors if used improperly.


## Writing Up Results

- ANOVA tests whether the between-group variability is significantly larger than the within-group variability, providing evidence that group means are different.
- The $F$-test does not identify which specific means are different or how they differ. Additional tests (e.g. post-hoc tests) are required to answer these questions of interest (QOI).

### Steps for Writing Results:
1. State the research question, treatments, and context.
2. Describe data collection methods, sample sizes, and treatments.
3. Summarize assumption checks (relying on visual evidence).
4. Provide descriptive statistics for groups.
5. Report effect size, $F$-statistic, degrees of freedom, and $p$-value.
6. Include residual diagnostics, mention transformations and information about other tests if used.  
7. Conclude with decisions and contextual interpretations.
