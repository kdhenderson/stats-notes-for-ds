---
title: "Linear Combinations and the Multiple Comparison Problem"
---

## Objectives
- Understand weaknesses of the alternative hypothesis for an ANOVA F-test.
- Formulate appropriate linear combinations of means.
- Understand the multiple comparison problem and how to correct for it.
- Use the formulation to make appropriate inferences.


## Fallacies in Hypothesis Testing
1. **False Causality**: A small p-value does not indicate causation. Causality can only be inferred from randomized experiments, not observational studies.
2. **Accepting the Null**: Should state, “no evidence of a difference,” not that the null hypothesis is true. There isn't enough evidence to suggest a difference is due to anything but chance. 
3. **Statistical vs. Practical Significance**: Statistical significance does not imply practical importance. Evaluate with power, effect size, and confidence intervals.  
   - Differences that are statistically but not practically significant may be due to a large sample size.  
   - If a difference is practically significant but not statistically significant, collect more data.
4. **Data Dredging**: Avoid fishing for significance (data snooping). This can lead to publication bias against negative results.
5. **Good Statistics from Bad Data**: Biased or non-random data compromises conclusions. Experimental design determines what inferences can be made and what statistical methods can be used.


## Linear Combination of Group Means

- An ANOVA only allows pairwise comparisons of means and does not account for structure within the groups. For example, you might want to compare an average of means to a single mean or to the average of other means. 
- To begin, use the ANOVA framework as an initial screening device to test for any overall differences in means to determine whether further testing is necessary.
   
### Linear Contrasts

- A **linear combination** of group means is defined as:
  $$
  \gamma = C_1\mu_1 + C_2\mu_2 + \dots + C_I\mu_I
  $$
  where $\gamma$ is the parameter representing the linear combination, and $C_i$ are coefficients that sum to zero, making the combination a **contrast**.
- Use $g$ and $\bar{x}$ to estimate $\gamma$ and $\mu$.
- The standard error of $g$, denoted $SE(g)$, is calculated as:
  $$
  SE(g) = S_p \sqrt{\frac{C_1^2}{n_1} + \frac{C_2^2}{n_2} + \dots + \frac{C_I^2}{n_I}}
  $$
  where $S_p$ is the pooled standard deviation.  
  Even when comparing only two groups (i.e. the other coefficients / terms under the square root are zero), the pooled standard deviation is used under the assumption of equal variances from all groups.
- The $t$-statistic for testing contrasts is:
  $$
  t_{\alpha, df} = \frac{g - \gamma}{SE(g)}
  $$
  where $g$ is the observed linear combination, $\gamma$ is the hypothesized value (e.g. $\gamma = 0$), and $df$ are the degrees of freedom associated with the pooled standard deviation.


## Steps for a Linear Contrast Test

1. **Summary Statistics**: Obtain group means, sample sizes, and the pooled standard deviation from the ANOVA model (e.g. $RMSE$).
2. **Specify Coefficients**: Choose $C_i$ such that their sum equals zero.
3. **Estimate the Contrast**: Compute the linear combination $g$ using the group means and coefficients.
4. **Calculate Standard Error**: $SE(g)$  
5. **Construct Confidence Intervals**: $CI = g \pm t_{\alpha, df} \cdot SE(g)$  
6. **Perform the Test**: Calculate the $t$-statistic.

### Simultaneous Inferences
- When testing multiple contrasts or pairwise comparisons, the likelihood of a **Type I error** increases. Adjustments are needed to the significance level or p-value to maintain the overall error rate.
- Note the distinction between:
  - **Individual confidence level**: The probability that a single interval captures the parameter ($1 - \alpha$).
  - **Familywise confidence level**: The probability that all intervals simultaneously capture their parameters is less than $1 - \alpha$, leading to compound uncertainty.

### Common Applications of Linear Contrasts
1. Comparing averages of group means, e.g., \( \text{Average of groups 1 and 2 vs. group 3} \).
2. Comparing rates in studies, e.g. dietary interventions in rodents.
3. Testing specific hypotheses about combinations of group means.


---
left off here


## Some Post-Hoc Procedures
These test for all pairwise difference in means:
Bonferroni adjustment
Tukey’s honestly signficiant difference (HSD)
Ryan-Eilliot-Gabriel-Welsch Q-procedure (REGWQ)
Tests for pairwise differences from a control:  Dunnett’s procedure
Tests for all possible differences:  Scheffé’s method uses an F-distribution.


## Dunnett’s Procedure
Only compares treatment to control (reference group)
Difference in each sample mean to control mean using d-statistic
D = d(k-1,N-k) * √(2MSE/nharmonic)
dfk-1,n-k, where k-1 is df from betweenSS and n-k is df from withinSS


## Bonferroni Adjustment
Overall type 1 error rate divided by the number of pairwise tests = new significance level (4 groups choose 2 = 6 pairs -> 0.05/6 -> significance level = 0.0083)
Very conservative. It has a smaller type 1 error rate than expected. It doesn’t tend to reject as often as it should.


## Tukey’s Honestly Significant Difference (HSD) procedure
Based on the studentized range statistic
q = 𝑋 ̅largestGrp – 𝑋 ̅smallestGrp / √(MSE*1/n) - when groups have same n 
Obtains simultaneous confidence intervals for each pair of populations means (𝑋 ̅i – 𝑋 ̅j) ± q-critical value * √(MSE/n)
q-critical value = qalpha,(k, n-k)
Tukey-Kramer procedure for unequal sample sizes use: 2ninj / (ni + nj) (SAS does this)


## REGWQ Procedure
Algorithm-based
Advantages: SAS recommends this to keep the type I error rate at the nominal level and has good power
Method:  Arrange sample means in descending order. Reject that the means are the same if the difference in the means is greater than a q-critical value (studentized range). Adjust p-value down for number of comparisons.


## Even if null is true, we can still end up rejecting the null by chance if too many tests are done!
## Think about the experimental design when deciding the appropriate analysis.
## After testing for group differences with ANOVA if the F-statistic is:
- Not significant, stop
- Is significant, rather than proceed to post-hoc battery of tests, think about these: 
  - Is there inherent structure related to the levels of a factor?   - Is it more appropriate to test one mean against other combinations of means or other linear combinations of mean?
  - The structure of the data are important for further testing and may not lead to multiple pairwise comparisons.
  - For planned comparisons, the number of significant tests is kept small, because we have predictions built into the study of specific combinations that we are interested in testing.
  - Unplanned post-hoc comparisons can be done when we don’t have specific predictions about which groups may be different than other groups.

## Reporting Results
Discuss the research question, design and expectations of group differences.
Explain results of exploratory data analysis and any remedies for violations of assumptions (e.g. did we choose to do a non-parametric test).
Report the overall F-statistic, its degrees of freedom and the p-value.
Report effect size (sum of squared regression / sum of squared total), tells us if we have a large enough practical effect that matches statistical significance.
Results and rationale for any post-hoc tests. Describe if we are doing planned comparisons and/or pairwise comparisons.
Conclusion in the context of the problem.
Discuss any weaknesses in the conclusions due to experimental design.


::: {#contrastExample layout-ncol=2}

![](images/notes_7_1_exHandicapContrast_1.png){}
![](images/notes_7_2_exHandicapContrast_2.png){}

![](images/notes_7_3_exHandicapContrast_3.png){}
![](images/notes_7_4_exHandicapContrast_4.png){}

![](images/notes_7_5_exHandicapContrast_5.png){}
![](images/notes_7_6_exHandicapContrast_6.png){}

![](images/notes_7_7_exHandicapContrast_7.png){}
![](images/notes_7_8_theoryOfBonferroni_1.png){}

![](images/notes_7_9_exMultipleComparison_1.png){}
![](images/notes_7_10_exMultipleComparison_2.png){}

![](images/notes_7_11_exMultipleComparison_3.png){}
![](images/notes_7_12_exMultipleComparison_4.png){}

![](images/notes_7_13_exMultipleComparison_5.png){}
:::

