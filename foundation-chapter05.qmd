---
title: "Alternatives to the T-Tools"
---

## Objectives
- Identify when analysis methods based on the t-tools are inappropriate for a dataset.
- Understand the principles behind rank-sum, signed-rank, and permutation tests.
- Learn how to appropriately apply and interpret rank-sum, signed-rank, and permutation tests.


## Nonparametric Methods
- Nonparametric methods provide a solution when assumptions of the t-test cannot be met, such as:
  - Severe skewness in data.
  - Large differences in variances between samples.
  - Small sample sizes that preclude assumptions about the population.


## Censored Data
- Censored data occurs when the exact value of an observation is unknown, often due to exceeding a measurement limit (e.g. students taking longer than the maximum allowed time to complete a test).
- Rank-based tests, such as the rank-sum test, rely on rank information, making them robust to censored observations.


## Permutation Test
- A permutation test serves as a nonparametric alternative to the two-sample t-test, as it does not assume normality.
- **Assumptions**:
  - The null hypothesis is true, and random shuffling of data is consistent with it.
  - The null distribution is built through repeated permutations of the data.
- **Procedure**:
  1. Combine $n + m$ observations from the two treatments.
  2. Permute these observations randomly between the treatments.
  3. Compute the test statistic (e.g., mean, median, or ratio) for each permutation.
  4. Compare the observed test statistic to the distribution of permuted test statistics.
- **Applications**:
  - Ideal for non-normal data or datasets with ties (e.g. the Challenger O-ring study).
  - Useful for a wide variety of parameters (e.g. mean, median, ratio).
  - Not suitable when observations have an inherent order.


## Wilcoxon Rank-Sum Test
- **Purpose**:
  - A distribution-free method for comparing two independent samples.
  - Particularly useful for small sample sizes, where normality assumptions cannot be assessed.
  - Resistant to outliers and capable of handling censored observations.
- **Hypothesis**:
  - $H_0$: The medians of the two groups are equal.
- **Procedure**:
  1. Combine observations from both groups and rank them:
     - Ties are assigned the average rank.
  2. Calculate the test statistic:
     - The sum of ranks for one group (conventionally the smaller group for ease of computation).
  3. Compute the p-value:
     - **Exact Method**:
       - Evaluate all permutations of ranks to generate the distribution of all possible rank sums.
       - Calculate the proportion of rank sums for a group greater than or equal to the observed rank sum (e.g., the number of rank sums greater than or equal to the observed value divided by the total number of permutations).  
       - This is equivalent to a permutation test on the rank sum statistic rather than the difference of means.
       - **Limitation**: Computationally impractical for large sample sizes.
     - **Normal Approximation**:
       - The rank sum statistic approximates a normal distribution for larger sample sizes, especially with few ties.
       - Apply a continuity correction to adjust for the discrete nature of rank sums by approximating their area (represented as bars) with the area under a continuous curve (e.g. the normal distribution), improving the accuracy of p-value calculations:
         - For a left-sided test, add a small adjustment.
         - For a right-sided test, subtract a small adjustment.
- **Confidence Intervals**:
  - Use Hodges-Lehmann estimation.


### Normal Approximation with Continuity Correction
![Sampling distribution of the rank-sum statistic under the null hypothesis.](images/display_4_6.png){width=6in fig-align="left"}   
![Illustration of the continuity correction for approximating p-values.](images/display_continuityCorrection.png){width=5in fig-align="left"}   
Source: @ramsey2012statistical.

- $Z = \frac{T - \text{Mean}(T)}{\text{SD}(T)}$
- $T$: Rank sum statistic.  
- $\bar{R}$: Average of all the ranks (both groups).  
- $s_R$ – Standard deviations of all the ranks (both groups).  
- $\text{Mean}(T)$ and $\text{SD}(T)$: Theoretical mean and standard deviation of the rank sum statistic under $H_0$.  
- **p-value**: Proportion of values from a standard normal distribution more extreme than the observed Z-statistic ($Z$).


## Alternatives to the Paired t-Test

### Wilcoxon Signed-Rank Test
- **Hypothesis**:
  - $H_0$: Mean difference between paired observations is zero.
  - For a one-sided test, carefully consider the direction of the test based on the sign of the differences.  
- **Procedure**:
  1. Compute differences for each pair.
  2. Rank *absolute* differences and sum positive ranks.
  3. Compute p-values using:
     - **Exact Test**: Evaluate all possible permutations of ranks (computationally intensive for large $n$).
     - Normal approximation:
       - $\text{Mean}(S) = \frac{n(n+1)}{4}$
       - $\text{SD}(S) = \sqrt{\frac{n(n+1)(2n+1)}{24}}$
       - $Z = \frac{S - \text{Mean}(S)}{\text{SD}(S)}$
       - **$p$-Value**: Derived from software or Z-tables. 
- **Notes**:
  - Resistant to outliers while preserving the relative magnitude of the differences, unlike the simpler sign test.
  
::: {layout-ncol=2}  
![Handwritten Example: Wilcoxon Signed-Rank Test Procedure.](images/notes_5_1.png)  
:::

### Sign Test
- **Purpose**:
  - Simple alternative to the paired t-test.
  - Tests for median difference.
  - Not a powerful test, so unlikely to detect a difference.
- **Procedure**:
  - Count positive differences after taking the differences between paired observations ($K$).
  - $H_0$: $K = \frac{n}{2}$
  - Use a normal approximation:
    - $Z = \frac{K - 0.5 - \frac{n}{2}}{\sqrt{\frac{n}{4}}}$
    - Observed (w. continuity correction) – expected / st. dev.
    - Where K is the observed positives, 0.5 is continuity correction, n/2 is half of the observations = our expected number of positives, over the standard deviation
    - Don’t know why st. dev. is over 4?
    
### Sign Test
- **Purpose**:
  - A simple alternative to the paired t-test.
  - Tests for a median difference between paired observations.
  - Not a powerful test, so it may fail to detect small or moderate differences.
- **Procedure**:
  1. Compute the differences between paired observations.
  2. Count the number of positive differences ($K$).
  3. **Hypothesis**:
     - $H_0$: $K = \frac{n}{2}$ (half the observations are expected to be positive under the null hypothesis).
  4. Use a normal approximation for large $n$:
     - $Z = \frac{K - 0.5 - \frac{n}{2}}{\sqrt{\frac{n}{4}}}$
       - The numerator represents the observed number of positives ($K$) with a continuity correction ($-0.5$) to adjust for the discrete nature of $K$.
       - The denominator, $\sqrt{\frac{n}{4}}$, is the standard deviation under the null hypothesis.

    
## Levene’s (Median) Test of Equal Spread
- **Purpose**:
  - Alternative to the F-test for non-normal distributions.
  - Visual test is still best.
- **Hypothesis**:
  - $H_0$: Distributions have equal spread.
- **Procedure**:
  - Compute absolute of each observation minus the group median.
  - Perform a two-sample t-test on the deviations.
  - F-test looks at the variance.
  - In SAS, called Brown Forsythe Test -> proc glm.
  - In SAS, Levene’s test is the abs diff of the obs from the mean of its group. This can also be called in proc glm.

## Levene’s (Median) Test of Equal Spread
- **Purpose**:
  - Robust alternative to the F-test for assessing equality of spread (variances) in non-normal distributions.
  - A visual inspection (e.g. boxplots) is often still the best initial approach.
- **Hypothesis**:
  - $H_0$: The distributions have equal spread.
  - $H_A$: The distributions have different spreads.
- **Procedure**:
  1. For each observation, calculate the **absolute deviation**:
     - Absolute deviation = $| \text{observation} - \text{group median} |$.
  2. Perform a two-sample t-test on the calculated absolute deviations for each group.
  3. Interpret the results:
     - Reject $H_0$ if the p-value is below the significance threshold, indicating unequal spread.
- **Notes**:
  - In SAS:
    - The Brown-Forsythe Test (a variation of Levene's test) can be implemented using `proc glm`.
    - Levene’s test can also be performed by computing the absolute deviations of observations from the group mean or median and running a t-test on these deviations.


## Code Examples

### Signed-Rank and Sign Tests in SAS
```{sas eval=FALSE}
/* Sign Test and Signed Rank Test */

/* paired density of nerve cell count
between 2 sites in each horse's intestine */

data horse;
input horse site1 site2;
datalines;
6 14.2 16.4
4 17 19
8 37.4 37.6
5 11.2 6.6
7 24.2 14.4
9 35.2 24.4
3 35.2 23.2
1 50.6 38
2 39.2 18.6
;

proc print data = horse;
run;

* paired t-test;
/* normality might be suspect because 
sample size is small */
proc ttest data = horse;
paired site1*site2;
run;

/* H0: median difference between site1 and site2 is zero
Ha: median difference not zero (2-sided)
or median difference between site1 and site2 >0 (1-sided) */
* signed rank test (sign and magnitude of differences);

* copy the dataset and make a diff column;
data horse2;
set horse;
diff = site1 - site2;
run;

* look at the new dataset;
proc print data = horse2;
run;

/* proc univariate does a paired t-test,
a sign test and a signed rank test by default */
proc univariate data = horse2;
var diff;
run;


/* Conclusion: There is strong evidence that the median difference of nerve density between site 1 and site 2 is greater than zero (Wilcoxon signed-rank test, one-sided p-value of 0.0294.) In other words, there is strong evidence to suggest that the median density of nerve cells is greater at site 1 than site 2. */

```

### Signed-Rank Test in R
```{r eval=FALSE}
wilcox.test(horse$site1, horse$site2, paired = true)

```

### Levene's Test in SAS
```{sas eval = FALSE}
/* Test Prep Example */
data exam;
input score type $;
datalines;
37 New
49 New
55 New
77 New
23 Trad
31 Trad
46 Trad
;

/* Levene's Test / Brown Forsythe Test */
proc glm data = exam;
class type;
model score = type;
means type / hovtest = bf; *hov = homogeneity of variance bf = brown forsythe;
run;

* demo of what the Brown Forsythe test does;
* find the diffs between observation and group median;

data medianDiff;
input diff type $;
datalines;
15 New
3 New
3 New
25 New
8 Trad
0 Trad
15 Trad
;
* do a t-test on the diffs should equal glm result;
proc ttest data = medianDiff;
class type;
var diff;
run;

```


## References
