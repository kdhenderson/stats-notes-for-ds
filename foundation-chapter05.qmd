---
title: "Alternatives to the T-Tools"
---

## Objectives

- Recognize when the assumptions of the *t*-tools are violated or when these tools are inappropriate.
- Understand the logic and implementation of rank-based and permutation-based alternatives.
- Apply and interpret the results of nonparametric tests, including the rank-sum test, signed-rank test, and permutation test.


## Nonparametric Methods

Nonparametric methods provide a solution when assumptions of the *t*-test cannot be met, such as:

- Severe skewness in the data.
- Large differences in variances between groups.
- Small sample sizes that preclude assumptions about the population distribution.


## Censored Data

Censored data occurs when the exact value of an observation is unknown, often due to exceeding a measurement threshold (e.g., students taking longer than the maximum allowed time to complete a test).

Rank-based tests, such as the rank-sum test, rely on the ordering of data rather than specific values, making them robust to censored observations.

## Permutation Test

A permutation test is a flexible, nonparametric alternative to the two-sample *t*-test.

**Assumptions**:

- The null hypothesis is true, and all permutations (random shufflings) of the data are equally likely under the null.
- The test does **not** assume normality.
- The null distribution is generated by repeatedly permuting the observed data.

**Procedure**:

1. Combine all $n + m$ observations from the two groups.
2. Randomly reassign labels to simulate permutation under $H_0$.
3. Compute a test statistic (e.g., mean, median, or ratio) for each permutation.
4. Compare the observed test statistic to the permutation distribution.

**Applications**:

- Suitable for small or non-normal datasets, especially when there are ties.
- Effective for a wide range of statistics including means, medians, and ratios.
- Not appropriate when the data have an inherent order that must be preserved.
  

## Wilcoxon Rank-Sum Test

**Purpose**:

- A distribution-free method for comparing two independent samples.
- Particularly useful with small samples, where normality assumptions cannot be assessed.
- Resistant to outliers.
- Capable of handling censored observations.

**Hypothesis**:

- $H_0$: The two populations have equal medians.

**Procedure**:

1. Combine all observations and rank them (assign average ranks for ties).
2. Compute the rank sum for one group (typically the smaller group, for ease of computation).
   - This rank sum serves as the test statistic.
3. Compute the *p*-value:
   - **Exact Method**:
     - Evaluate all possible permutations of ranks under $H_0$ to generate the exact distribution of rank sums.
     - Compute the proportion of permutations with rank sums as or more extreme than the observed value.
       - The number of rank sums greater than or equal to the observed value divided by the total number of permutations
     - Equivalent to a permutation test on the rank sum statistic, rather than the difference in means.
     - Not computationally feasible for large $n$.
   - **Normal Approximation**:
     - For larger samples (with few ties), the rank sum statistic approximates a normal distribution.
     - Compute a *Z*-statistic using:
       $$
       Z = \frac{T - \text{Mean}(T)}{\text{SD}(T)}
       $$
       Where:
       - $T$: The observed rank sum.
       - $\text{Mean}(T) = n_1 \bar{R}$, with $\bar{R}$ the average rank of all combined observations.
       - $\text{SD}(T) = s_R \sqrt{ \frac{n_1 n_2}{n_1 + n_2} }$, where $s_R$ is the standard deviation of all ranks.
     - Apply a **continuity correction** to improve *p*-value accuracy:
       - Add 0.5 to $T$ for a **left-tailed** test.
       - Subtract 0.5 from $T$ for a **right-tailed** test.
     - This correction improves the match between the discrete statistic and the continuous normal curve.

**Confidence Intervals**:

- Use the **Hodges–Lehmann estimator** to construct a confidence interval for the difference in medians.

### Visualizing the Continuity Correction

When the rank sum distribution is approximated by a normal curve, a continuity correction adjusts for the fact that $T$ is discrete.

**Conceptually**:

- The rank sum statistic creates a histogram-like distribution (discrete bars).
- Exact *p*-values are based on shaded bar areas beyond a cutoff.
- The normal approximation uses a smooth curve instead.
- The continuity correction shifts the normal cutoff to the center of the bar, improving the approximation.

![**How continuity correction improves normal approximation.**  
Illustration of continuity correction in a rank-based test. The gray bars show the exact (discrete) distribution of the test statistic. The black curve represents the normal approximation. The dashed vertical line at 7 is the unadjusted threshold; the dotted red line at 7.5 shows the continuity-corrected threshold, which more accurately aligns the area under the normal curve (red shaded) with the area of the histogram bars.](images/fch05_continuity_correction.png){fig-title=""}


## Alternatives to the Paired t-Test

### Wilcoxon Signed-Rank Test
- **Hypothesis**:
  - $H_0$: Mean difference between paired observations is zero.
  - For a one-sided test, carefully consider the direction of the test based on the sign of the differences.  
- **Procedure**:
  1. Compute differences for each pair.
  2. Rank *absolute* differences and sum positive ranks.
  3. Compute p-values using:
     - **Exact Test**: Evaluate all possible permutations of ranks (computationally intensive for large $n$).
     - Normal approximation:
       - $\text{Mean}(S) = \frac{n(n+1)}{4}$
       - $\text{SD}(S) = \sqrt{\frac{n(n+1)(2n+1)}{24}}$
       - $Z = \frac{S - \text{Mean}(S)}{\text{SD}(S)}$
       - **$p$-Value**: Derived from software or Z-tables. 
- **Notes**:
  - Resistant to outliers while preserving the relative magnitude of the differences, unlike the simpler sign test.
  
::: {layout-ncol=2}  
![Handwritten Example: Wilcoxon Signed-Rank Test Procedure.](images/notes_5_1.png)  
:::

### Sign Test
- **Purpose**:
  - Simple alternative to the paired t-test.
  - Tests for median difference.
  - Not a powerful test, so unlikely to detect a difference.
- **Procedure**:
  - Count positive differences after taking the differences between paired observations ($K$).
  - $H_0$: $K = \frac{n}{2}$
  - Use a normal approximation:
    - $Z = \frac{K - 0.5 - \frac{n}{2}}{\sqrt{\frac{n}{4}}}$
    - Observed (w. continuity correction) – expected / st. dev.
    - Where K is the observed positives, 0.5 is continuity correction, n/2 is half of the observations = our expected number of positives, over the standard deviation
    - Don’t know why st. dev. is over 4?
    
### Sign Test
- **Purpose**:
  - A simple alternative to the paired t-test.
  - Tests for a median difference between paired observations.
  - Not a powerful test, so it may fail to detect small or moderate differences.
- **Procedure**:
  1. Compute the differences between paired observations.
  2. Count the number of positive differences ($K$).
  3. **Hypothesis**:
     - $H_0$: $K = \frac{n}{2}$ (half the observations are expected to be positive under the null hypothesis).
  4. Use a normal approximation for large $n$:
     - $Z = \frac{K - 0.5 - \frac{n}{2}}{\sqrt{\frac{n}{4}}}$
       - The numerator represents the observed number of positives ($K$) with a continuity correction ($-0.5$) to adjust for the discrete nature of $K$.
       - The denominator, $\sqrt{\frac{n}{4}}$, is the standard deviation under the null hypothesis.

    
## Levene’s (Median) Test of Equal Spread
- **Purpose**:
  - Alternative to the F-test for non-normal distributions.
  - Visual test is still best.
- **Hypothesis**:
  - $H_0$: Distributions have equal spread.
- **Procedure**:
  - Compute absolute of each observation minus the group median.
  - Perform a two-sample t-test on the deviations.
  - F-test looks at the variance.
  - In SAS, called Brown Forsythe Test -> proc glm.
  - In SAS, Levene’s test is the abs diff of the obs from the mean of its group. This can also be called in proc glm.

## Levene’s (Median) Test of Equal Spread
- **Purpose**:
  - Robust alternative to the F-test for assessing equality of spread (variances) in non-normal distributions.
  - A visual inspection (e.g. boxplots) is often still the best initial approach.
- **Hypothesis**:
  - $H_0$: The distributions have equal spread.
  - $H_A$: The distributions have different spreads.
- **Procedure**:
  1. For each observation, calculate the **absolute deviation**:
     - Absolute deviation = $| \text{observation} - \text{group median} |$.
  2. Perform a two-sample t-test on the calculated absolute deviations for each group.
  3. Interpret the results:
     - Reject $H_0$ if the p-value is below the significance threshold, indicating unequal spread.
- **Notes**:
  - In SAS:
    - The Brown-Forsythe Test (a variation of Levene's test) can be implemented using `proc glm`.
    - Levene’s test can also be performed by computing the absolute deviations of observations from the group mean or median and running a t-test on these deviations.


## Code Examples

### Signed-Rank and Sign Tests in SAS
```{sas eval=FALSE}
/* Sign Test and Signed Rank Test */

/* paired density of nerve cell count
between 2 sites in each horse's intestine */

data horse;
input horse site1 site2;
datalines;
6 14.2 16.4
4 17 19
8 37.4 37.6
5 11.2 6.6
7 24.2 14.4
9 35.2 24.4
3 35.2 23.2
1 50.6 38
2 39.2 18.6
;

proc print data = horse;
run;

* paired t-test;
/* normality might be suspect because 
sample size is small */
proc ttest data = horse;
paired site1*site2;
run;

/* H0: median difference between site1 and site2 is zero
Ha: median difference not zero (2-sided)
or median difference between site1 and site2 >0 (1-sided) */
* signed rank test (sign and magnitude of differences);

* copy the dataset and make a diff column;
data horse2;
set horse;
diff = site1 - site2;
run;

* look at the new dataset;
proc print data = horse2;
run;

/* proc univariate does a paired t-test,
a sign test and a signed rank test by default */
proc univariate data = horse2;
var diff;
run;


/* Conclusion: There is strong evidence that the median difference of nerve density between site 1 and site 2 is greater than zero (Wilcoxon signed-rank test, one-sided p-value of 0.0294.) In other words, there is strong evidence to suggest that the median density of nerve cells is greater at site 1 than site 2. */

```

### Signed-Rank Test in R
```{r eval=FALSE}
wilcox.test(horse$site1, horse$site2, paired = true)

```

### Levene's Test in SAS
```{sas eval = FALSE}
/* Test Prep Example */
data exam;
input score type $;
datalines;
37 New
49 New
55 New
77 New
23 Trad
31 Trad
46 Trad
;

/* Levene's Test / Brown Forsythe Test */
proc glm data = exam;
class type;
model score = type;
means type / hovtest = bf; *hov = homogeneity of variance bf = brown forsythe;
run;

* demo of what the Brown Forsythe test does;
* find the diffs between observation and group median;

data medianDiff;
input diff type $;
datalines;
15 New
3 New
3 New
25 New
8 Trad
0 Trad
15 Trad
;
* do a t-test on the diffs should equal glm result;
proc ttest data = medianDiff;
class type;
var diff;
run;

```


## References
