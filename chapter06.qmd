---
title: "Comparisons Among Several Samples"
---

## Objectives
- Learn to use ANOVA tests for comparing means among three or more groups.
- Understand how to examine model assumptions for validity.
- Calculate the sample size necessary to detect a particular effect size in ANOVA.
- Make statistical inferences for multiple samples and interpret results in context.
- Apply the extra sum of squares principle to create and interpret ANOVA tables.
- Use full and reduced models to test different combinations of group means.
- Understand the Kruskal-Wallis test as a non-parametric alternative to ANOVA.
- Differentiate between random and fixed effects.

## ANOVA: Analysis of Variance
- **Purpose**: Test equality of means from more than two populations by comparing variability within groups to variability between groups.
- **Assumptions**:
  - All populations have normal distributions (reasonable symmetry in samples).
  - Population standard deviations are equal (to ensure differences in means aren't confounded by differences in variability).
  - Independence within (achieved automatically with random samples) and between samples.
- **Hypotheses**:
  - $H_0$: All population means are equal.
  - $H_A$: At least one population mean differs from another.
- ANOVA is a preliminary test; subsequent post-hoc tests identify which means differ.

![Equal Means vs. Separate Means Models](images/notes_6_1.jpg)  
*Figure 1: Comparison of equal means and separate means models, illustrating residual differences.*  

![ANOVA Table](images/notes_6_2.jpg) 
*Figure 2: ANOVA table showing degrees of freedom, sum of squares, mean squares, $F$-statistic, and $p$-value.*  

![Detailed ANOVA Table Overview](images/notes_6_3.png) 
*Figure 3: Detailed breakdown of ANOVA table components.*  

## ANOVA: 6-step hypothesis test
1. **Define Hypotheses**:
   - $H_0: \mu_1 = \mu_2 = \mu_3 = \dots$ (Equal means model).
   - $H_A$: At least one pair of means is different.
   - Null assumes data come from the same distribution (grand mean); alternative assumes different distributions (separate means).
   - Models are compared by finding the sum of squared residuals. A good fitting model will have smaller residuals (observed - predicted).  
2. **Get Critical Value**:
   - From an $F$-distribution.
   - Degrees of freedom: $df_1$ (model) and $df_2$ (error).
   - Calculate quantiles in R using `qf(alpha, df1, df2)`. Use $1-\alpha$ for a R-tailed test.  
3. **Calculate $F$-Statistic** (F in SAS ANOVA table):
   - Formula:  
     $F = \frac{\text{MS between}}{\text{MS within}} = \frac{\frac{\text{extra SS}}{\text{extra df}}}{\text{MSE}} = \frac{\text{Variation explained by the full model}}{\text{Variation left to be explained}}$.
   - Where:
     - $\text{MS between} = \frac{\text{extra SS}}{\text{extra df}}$
     - $\text{MS within} = \text{MSE} = \frac{\text{Error SS}}{\text{Error df}}$
4. **Determine p-value**:
   - Compare $F$-statistic to the critical value.
5. **Decision**:
   - Reject $H_0$ if $p$-value < $\alpha$; otherwise, fail to reject.
6. **Interpretation**:
   - Rejecting $H_0$ indicates evidence that at least one pair of group means is different.

![SAS Output Table](notes_6_4.jpg)  
*Figure 4: SAS output showing $F$-statistic, $p$-value, and $R^2$ metrics.*  

![R-Squared and Variance Explained](notes_6_5.jpg)  
*Figure 5: Illustration of $R^2$, showing the proportion of total variance explained by the model.*  

## SAS code for ANOVA
```{sas eval=FALSE}
* Generalized Linear Model: Extends analysis to multiple groups (e.g. ANOVA for 3+ groups);
proc glm data = dataSet;
class group;
model responseVar = groupingVar; * Fits an ANOVA;
run;
```

## R code for ANOVA
```{r eval=FALSE}
# aov = analysis of variance
# numerical response ~ factor groupings
fit = aov(responseVar ~ groupingVar, data = dataSet)
summary(fit)
```


## Key Metrics in ANOVA

### $R^2$: Coefficient of Determination
- $R^2 = \frac{\text{Variation Explained by Full Model}}{\text{Total Variation}} = \frac{\text{Extra Sum of Squares}}{\text{Total Sum of Squares}}$. 
- Represents the percentage of total variance explained by group membership.
- Example: $R^2$ of 0.75 indicates 75% of the response variation is explained by group differences.
- $R$: Correlation coefficient

### RMSE: Root Mean Square Error
- $\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\text{Unexplained Variation}}$
- Quantifies the amount of unexplained variation in the model.

### Coefficient of Variation (CV)
$\text{CV} = \frac{\text{RMSE}}{\text{Grand Mean}} \times 100$
- Measures relative standard deviation as a percentage of the mean.


## ANOVA Assumptions and Robustness
- **Normality**:
  - Check with histograms, boxplots, and Q-Q plots.
  - ANOVA is robust to slight violations of normality, especially with large sample sizes.
- **Equal Standard Deviations**:
  - This assumption is crucial for the validity of ANOVA results.
  - ANOVA is less robust to violations of this assumption compared to $t$-tests.
  - Confidence intervals depend on this assumption being met.
  - Confidence intervals are widest when the group with the largest standard deviation also has the largest sample size.
- **Independence**:
  - Ensure independence of observations both within and between groups.  


## Welch’s ANOVA
- Still assumes normality.
- Adjusts for unequal standard deviations.
- Degrees of freedom are lowered.

## Kruskal-Wallis Test
- Is a non-parametric alternative to an ANOVA on the difference of medians. 
- Can be used when the assumptions aren’t met for the ANOVA or Welch’s ANOVA, in the case of significant deviations from normality or small sample sizes.
- Good for non-symmetric distributions.
- Is basically an ANOVA after transformation to ranks.
- P-values are from a chi-square distribution.


## Kruskal-Wallis Test
- Non-parametric alternative for ANOVA.
- Tests medians instead of means.
- **Assumptions**:
  - Does not require normality, making it useful for non-symmetric distributions or small sample sizes.  
  - Robust to unequal variances.
- $p$-values follow a chi-square distribution.


## Power Analysis for ANOVA – SAS code
```{sas eval=FALSE}
proc power;
onewayanova test-overall;
groupmeans
```

## Random (vs. Fixed) Effects
- Observations are a random sample from a large population of possible levels.
- Levels of observations are meant to be representative of the population of things you could sample (even though you can/may not be sampling every possible level).
- Desired inferences are on the (whole) population of levels (more than those in the study).
- Statistically, to avoid increasing the probabilities of type 1 and 2 error, the model needs to include variance in the full model (residual variance, variance of each observation from the overall mean) and error associated with random effects. There is more error associated with random effects model.
- Inferences in a fixed effects model are limited to the specific levels in the study.

## Writing Up Results
- ANOVA tells us if the between group variability is larger than the within group variability, that there is evidence that means are different.
- F-test doesn’t provide answer to the QOI (only tells us at least a pair of means is different, not which or how). Other tests are required.
- What to include in a write-up:
  - What is the question/problem, treatment groups and context.
  - How was the data gathered, with sample sizes and treatments.
  - Results of assumption check, relying on the graphics.
  - Descriptive statistics for each group.
  - Effect size, statistic (F in this case), df, p-value.
  - Residual diagnostics, information about transformations, other tests.
  - Decision and interpretation of it in the context of the problem.

