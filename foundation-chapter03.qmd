---
title: "Data Screening, Assumptions, and Transformations"
---

## Objectives

- Review key elements of experimental design that support valid inference.  
- Understand conditions and assumptions required for *t*-tests.  
- Identify and handle non-normality, unequal variance, and outliers.  
- Apply and interpret log transformations in skewed data.  
- Distinguish between robustness and resistance in statistical tools.  
- Use appropriate visual tools to assess assumptions and variance.


## Experimental Design

- **Randomization**: Reduces potential bias by ensuring treatment groups are comparable.  
- **Placebo**: Controls for confounding variables by ensuring that only the treatment effect---the variable being tested---differs between groups.
- **Blinding**: Minimizes bias in outcomes by preventing subjects or researchers from knowing the treatment assignments.


## Conditions for Null Hypothesis Significance Testing (NHST)

1. Random sampling  
2. Independent observations  
3. Representative of the population: The sample reflects the population of interest.  
4. Quantitative data  
5. Nearly normal distribution  
6. Equal standard deviations for two-sample tests  
   - Also called *homoscedasticity*, meaning the groups have the same shape and spread.


## Paired *t*-Test

- Used when the assumption of independence is violated due to pairing.  
- Compares the difference between paired observations using a one-sample *t*-test.  
- Common in before-and-after studies or matched-subject designs.


## Tools for Checking Normality

1. **Boxplot**  
   - Visualizes the five-number summary.  
   - Highlights symmetry, skewness, and tail behavior.  
   - Useful for comparing groups side by side.  
2. **Dotplot**  
   - Displays individual data points.  
   - Easy to construct and interpret for small to moderate sample sizes.  
3. **Histogram**  
   - Shows the distribution's shape and symmetry.  
   - Useful for identifying skewness or multiple modes.  
4. **Normal Quantile (QQ) Plot**  
   - Plots theoretical normal values (X-axis) against observed data (Y-axis).  
   - Points that align closely along a straight line suggest normality.  
   - Sensitive to departures from normality, especially in the tails.


## Robustness

- A procedure is **robust** if its results remain valid despite minor violations of assumptions.  
- Example: A 95% confidence interval should still capture the true parameter 95% of the time, even if the data are not perfectly normal.


### Moderate Robustness in *t*-Tools
- **Sample size effects**:  
  - Larger samples tolerate greater departures from normality.  
  - Exception: Heavy-tailed distributions (i.e., many large outliers) can still distort results.
- **Two-sample *t*-tests**:  
  - Problems arise when the groups have different shapes or skewness, or when standard deviations are unequal.  
  - The worst-case scenario occurs when the group with the **smaller sample size** also has the **larger standard deviation**.  
    - In this case, the sample may fail to accurately represent the population's variability.


## Independence

- **Definition**: Observations are independent if knowing one value provides no information about another.  
  - Independence must be built into the experimental design.
- **Cluster effects**:  
  - Arise when data are grouped in natural subunits (e.g., littermates, classrooms).  
  - Violates independence unless each cluster is treated as a single observational unit or analyzed appropriately.
- **Serial effects**:  
  - Occur when measurements are taken over time (e.g., time series data).  
  - Nearby values may be correlated, violating independence.


## Outliers

- **Definition**: Observations that fall far from the central tendency of the data (e.g., the group average).
- **Effects**:  
  - Can create long-tailed distributions.  
  - *t*-statistics are sensitive to outliers and can be distorted by extreme values.

### Dealing with Outliers
- Do not remove outliers unless they result from data entry or measurement error.  
- Run analyses with and without outliers and compare the results.  
- Report both versions to provide transparency.

---

## Resistance
- A procedure is **resistant** if it remains stable when small parts of the data change.
  - Example: Median is resistant, while the mean is not.
- t-tools are based on means and are not resistant to outliers or long tails.


## Log Transformation (Natural Log)
- **When to use**:
  - Ratio of largest to smallest value > 10.
  - Skewed data.
  - Group with larger mean also have the larger variance.
- **Effects**:
  - Corrects non-normality and non-constant variance.
  - Requires back-transformation to interpret median and CIs on the original scale.

### Other Transformations
- Square root
- Inverse
- Reciprocal
- **Note**: These transformations are harder to back-transform than log transformations.

  
## Log Transformations: Propositions (Logarithmic Properties)
1. Normal distribution: The mean equals the median in a normal distribution.
2. Monotonicity: The log function is monotonically increasing, meaning log(median x) = median(log(x)).
3. Log differences:
   - $\log(a) - \log(b) = \log\left(\frac{a}{b}\right)$
4. Exponentiation: $e^{\log(x)} = x$


## t-Test Interpretation (Log-Transformed Data)
- $\text{mean}(\log x) - \text{mean}(\log y) = \gamma$
- The distribution is approximately normal, so the mean and median are equal:  
  $\text{median}(\log x) - \text{median}(\log y) = \gamma$
- The logarithmic function is monotonically increasing:  
  $\log(\text{median}(x)) - \log(\text{median}(y)) = \gamma$
- Exponentiation gives:  
  $e^{\log(\text{median}(x) / \text{median}(y))} = e^\gamma$
- Therefore,  
  $\text{median}(x) / \text{median}(y) = e^\gamma$
- **Interpretation**: The median of $x$ is estimated to be $e^\gamma$ times the median of $y$.


## Inequality of Variance
- **Visual evidence** should be used as primary evidence for detecting unequal variances.
- **F-test**: Tests for equal variances but is sensitive to normality violations.  
  - $H_0$: population variances are equal
  - $H_a$: population variances are not equal
- Use hypothesis tests for equality of variance with caution.


## General Rules of Thumb
- Equal sample sizes and large samples: t-tools are robust.
- Different standard deviations:
  - Equal sample sizes: t-tools are valid with large samples.
  - Unequal sample sizes: t-tools are not valid.


## Welchâ€™s t-Test
- Adjusted for unequal standard deviations.
- Adjusts degrees of freedom using the Satterthwaite approximation.
- Still assumes normality.


## Non-Normal Distributions
- Long-tailed distributions:
  - Wider CIs than expected (e.g. $> (1-\alpha) \%$), leading to fewer rejections of the null hypothesis.
  - Fewer rejections can increase the true capture rate of $\mu$ to $> (1-\alpha) \%$, resulting in rejection rates $< \alpha \%$.  

![](images/display_3_4.png){width=6in fig-align="left"}  
Source: @ramsey2012statistical.

- When sample sizes and standard deviations both differ, CIs can become either too narrow or too wide.  

![](images/display_3_5.png){width=6in fig-align="left"}  
Source: @ramsey2012statistical.


## References